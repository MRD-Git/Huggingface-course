{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88759d5",
   "metadata": {},
   "source": [
    "# The 🤗 Datasets library\n",
    "## [Introduction](https://huggingface.co/course/chapter5/1?fw=pt)\n",
    "\n",
    "In [Chapter 3](https://huggingface.co/course/chapter3) you got your first taste of the 🤗 Datasets library and saw that there were three main steps when it came to fine-tuning a model:\n",
    "- Load a dataset from the Hugging Face Hub.\n",
    "- Preprocess the data with `Dataset.map()`.\n",
    "- Load and compute metrics.\n",
    "\n",
    "But this is just scratching the surface of what 🤗 Datasets can do! In this chapter, we will take a deep dive into the library. Along the way, we'll find answers to the following questions:\n",
    "- What do you do when your dataset is not on the Hub?\n",
    "- How can you slice and dice a dataset? (And what if you *really* need to use Pandas?)\n",
    "- What do you do when your dataset is huge and will melt your laptop's RAM?\n",
    "- What the heck are \"memory mapping\" and Apache Arrow?\n",
    "- How can you create your own dataset and push it to the Hub?\n",
    "\n",
    "The techniques you learn here will prepare you for the advanced tokenization and fine-tuning tasks in [Chapter 6](https://huggingface.co/course/chapter6) and [Chapter 7](https://huggingface.co/course/chapter7) — so grab a coffee and let's get started!\n",
    "\n",
    "## [What if my dataset isn't on the Hub?](https://huggingface.co/course/chapter5/2?fw=pt)\n",
    "\n",
    "You know how to use the Hugging Face Hub to download datasets, but you'll often find yourself working with data that is stored either on your laptop or on a remote server. In this section we'll show you how 🤗 Datasets can be used to load datasets that aren't available on the Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ea568e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthias/opt/anaconda3/envs/hf/lib/python3.8/site-packages/IPython/core/display.py:717: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/HyQgpJTkRdE\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/HyQgpJTkRdE\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17588bfc",
   "metadata": {},
   "source": [
    "### Working with local and remote datasets\n",
    "🤗 Datasets provides loading scripts to handle the loading of local and remote datasets. It supports several common data formats, such as:\n",
    "\n",
    "| Data format | Loading script | Example\n",
    "| ---- | ------- | ---- |\n",
    "| CSV & TSV | `csv` | `load_dataset(\"csv\", data_files=\"my_file.csv\")` |\n",
    "| Text files | `text` | `load_dataset(\"text\", data_files=\"my_file.txt\")` |\n",
    "| JSON & JSON Lines | `json` | `load_dataset(\"json\", data_files=\"my_file.jsonl\")` |\n",
    "| Pickled DataFrames | `pandas` | `load_dataset(\"pandas\", data_files=\"my_dataframe.pkl\")` |\n",
    "\n",
    "As shown in the table, for each data format we just need to specify the type of loading script in the `load_dataset()` function, along with a `data_files` argument that specifies the path to one or more files. Let's start by loading a dataset from local files; later we'll see how to do the same with remote files.\n",
    "\n",
    "### Loading a local dataset\n",
    "\n",
    "For this example we'll use the [SQuAD-it](https://github.com/crux82/squad-it/) dataset, which is a large-scale dataset for question answering in Italian.\n",
    "\n",
    "The training and test splits are hosted on GitHub, so we can download them with a simple `wget` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b31dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following commands to download the data files and move them to the \"data\" folder need to run only once\n",
    "#!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz\n",
    "#!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz\n",
    "#!mv SQuAD_it-train.json.gz data\n",
    "#!mv SQuAD_it-test.json.gz data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd33c988",
   "metadata": {},
   "source": [
    "This will download two compressed files called *SQuAD_it-train.json.gz* and *SQuAD_it-test.json.gz*, which we can decompress with the Linux `gzip` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87d412eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following command needs to run only once\n",
    "#!gzip -dkv data/SQuAD_it-*.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462b7b2",
   "metadata": {},
   "source": [
    "We can see that the compressed files have been replaced with *SQuAD_it-train.json* and *SQuAD_it-test.json*, and that the data is stored in the JSON format.\n",
    "> <font color=\"darkgreen\">✎ If you're wondering why there's a `!` character in the above shell commands, that's because we're running them within a Jupyter notebook. Simply remove the prefix if you want to download and unzip the dataset within a terminal.</font>\n",
    "\n",
    "To load a JSON file with the `load_dataset()` function, we just need to know if we're dealing with ordinary JSON (similar to a nested dictionary) or JSON Lines (line-separated JSON). Like many question answering datasets, SQuAD-it uses the nested format, with all the text stored in a `data` field. This means we can load the dataset by specifying the `field` argument as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1366eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1bbfd74a7c0a2c55\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/default-1bbfd74a7c0a2c55/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028de6a264104aa6ad6203107431b62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=\"data/SQuAD_it-train.json\", field=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbf9bb",
   "metadata": {},
   "source": [
    "By default, loading local files creates a `DatasetDict` object with a `train` split. We can see this by inspecting the `squad_it_dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc3089fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 442\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_it_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3f738",
   "metadata": {},
   "source": [
    "This shows us the number of rows and the column names associated with the training set. We can view one of the examples by indexing into the `train` split as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "326aad8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Terremoto del Sichuan del 2008',\n",
       " 'paragraphs': [{'context': \"Il terremoto del Sichuan del 2008 o il terremoto del Gran Sichuan, misurato a 8.0 Ms e 7.9 Mw, e si è verificato alle 02:28:01 PM China Standard Time all' epicentro (06:28:01 UTC) il 12 maggio nella provincia del Sichuan, ha ucciso 69.197 persone e lasciato 18.222 dispersi.\",\n",
       "   'qas': [{'answers': [{'answer_start': 29, 'text': '2008'}],\n",
       "     'id': '56cdca7862d2951400fa6826',\n",
       "     'question': 'In quale anno si è verificato il terremoto nel Sichuan?'},\n",
       "    {'answers': [{'answer_start': 232, 'text': '69.197'}],\n",
       "     'id': '56cdca7862d2951400fa6828',\n",
       "     'question': 'Quante persone sono state uccise come risultato?'},\n",
       "    {'answers': [{'answer_start': 29, 'text': '2008'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c0',\n",
       "     'question': 'Quale anno ha avuto luogo il terremoto del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 78, 'text': '8.0 Ms e 7.9 Mw'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c1',\n",
       "     'question': 'Che cosa ha fatto la misura di sisma?'},\n",
       "    {'answers': [{'answer_start': 183, 'text': '12 maggio'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c2',\n",
       "     'question': 'Che giorno si è verificato il terremoto?'},\n",
       "    {'answers': [{'answer_start': 118,\n",
       "       'text': '02:28:01 PM China Standard Time'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c3',\n",
       "     'question': 'Che ora del giorno è accaduto il terremoto?'},\n",
       "    {'answers': [{'answer_start': 232, 'text': '69.197'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c4',\n",
       "     'question': 'Quante persone sono morte?'}]},\n",
       "  {'context': 'E\\' noto anche come terremoto di Wenchuan (Cinese:????; pinyin: Wènchu? n dà dìzhèn; letteralmente:\"Grande terremoto di Wenchuan\"), dopo l\\' ubicazione dell\\' epicentro del terremoto, Wenchuan County, Sichuan. L\\' epicentro era di 80 chilometri (50 miglia) ad ovest nord-ovest di Chengdu, capoluogo di provincia, con una profondità focale di 19 km (12 miglia). Il terremoto ha colpito anche i paesi vicini e lontani da Pechino e Shanghai-1.500 km (930 mi) e 1.700 km (1.060 mi) di distanza, dove gli edifici adibiti a uffici hanno oscillato con il tremore. Forti scosse di assestamento, un po\\' superiori alla magnitudo 6, hanno continuato a colpire l\\' area anche mesi dopo il sisma principale, causando nuove vittime e danni.',\n",
       "   'qas': [{'answers': [{'answer_start': 415, 'text': 'Pechino e Shanghai'}],\n",
       "     'id': '56cdcb2c62d2951400fa6830',\n",
       "     'question': 'Quali città lontane in altri paesi potrebbero sentire il terremoto?'},\n",
       "    {'answers': [{'answer_start': 338, 'text': '19 km'}],\n",
       "     'id': '56cdcb2c62d2951400fa6833',\n",
       "     'question': 'Qual è stata la profondità focale del terremoto?'},\n",
       "    {'answers': [{'answer_start': 659, 'text': 'mesi dopo'}],\n",
       "     'id': '56cdcb2c62d2951400fa6834',\n",
       "     'question': 'Quanto tempo dopo il terremoto si sono sentite le scosse di assestamento?'},\n",
       "    {'answers': [{'answer_start': 181, 'text': 'Wenchuan County, Sichuan'}],\n",
       "     'id': '56d4fb6f2ccc5a1400d833d5',\n",
       "     'question': \"Dov' era l' epicentro del terremoto?\"},\n",
       "    {'answers': [{'answer_start': 227, 'text': '80 chilometri'}],\n",
       "     'id': '56d4fb6f2ccc5a1400d833d6',\n",
       "     'question': 'Quanto lontano era da Chengdu?'},\n",
       "    {'answers': [{'answer_start': 338, 'text': '19 km'}],\n",
       "     'id': '56d4fb6f2ccc5a1400d833d7',\n",
       "     'question': 'Qual era la profondità focale del sisma?'}]},\n",
       "  {'context': \"I dati ufficiali (al 21 luglio 2008 ore 12:00 CST) hanno dichiarato che 69.197 sono stati confermati morti, di cui 68.636 nella provincia del Sichuan e 374.176 feriti, di cui 18.222 scomparsi. Il terremoto ha lasciato circa 4,8 milioni di senzatetto, anche se il numero potrebbe raggiungere gli 11 milioni. Circa 15 milioni di persone vivevano nell' area colpita. E' stato il terremoto più mortale per colpire la Cina dopo il terremoto di Tangshan 1976, che ha ucciso almeno 240.000 persone, e il più forte del paese dal terremoto di Chayu 1950, che ha registrato a 8,5 sulla scala di magnitudo Richter. E' il 21° terremoto più morto di tutti i tempi. Il 6 novembre 2008, il governo centrale ha annunciato che avrebbe speso 1 trilione di RMB (circa 146,5 miliardi di dollari USA) nei prossimi tre anni per ricostruire le aree devastate dal terremoto, come parte del programma cinese di stimolo economico.\",\n",
       "   'qas': [{'answers': [{'answer_start': 72, 'text': '69.197'}],\n",
       "     'id': '56cdcbb762d2951400fa683a',\n",
       "     'question': 'Quante persone sono state confermate morte?'},\n",
       "    {'answers': [{'answer_start': 115, 'text': '68.636'}],\n",
       "     'id': '56cdcbb762d2951400fa683b',\n",
       "     'question': 'Quanti morti sono stati confermati solo nella provincia del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 224, 'text': '4,8 milioni'}],\n",
       "     'id': '56cdcbb762d2951400fa683c',\n",
       "     'question': 'Quante persone sono rimaste senza tetto a causa del terremoto?'},\n",
       "    {'answers': [{'answer_start': 313, 'text': '15 milioni'}],\n",
       "     'id': '56cdcbb762d2951400fa683d',\n",
       "     'question': 'Quante persone hanno vissuto nella zona colpita?'},\n",
       "    {'answers': [{'answer_start': 724, 'text': '1 trilione di RMB'}],\n",
       "     'id': '56cdcbb762d2951400fa683e',\n",
       "     'question': 'Quanto denaro è stato destinato alla ricostruzione di aree devastate?'},\n",
       "    {'answers': [{'answer_start': 115, 'text': '68.636'}],\n",
       "     'id': '56d4fca52ccc5a1400d833de',\n",
       "     'question': 'Quante persone sono morte nella provincia del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 152, 'text': '374.176'}],\n",
       "     'id': '56d4fca52ccc5a1400d833df',\n",
       "     'question': 'Quanti sono stati feriti nel Sichuan?'},\n",
       "    {'answers': [{'answer_start': 175, 'text': '18.222'}],\n",
       "     'id': '56d4fca52ccc5a1400d833e0',\n",
       "     'question': 'Quante persone sono elencate come scomparse?'},\n",
       "    {'answers': [{'answer_start': 224, 'text': '4,8 milioni'}],\n",
       "     'id': '56d4fca52ccc5a1400d833e1',\n",
       "     'question': 'Quante persone sono senzatetto a causa del terremoto?'},\n",
       "    {'answers': [{'answer_start': 295, 'text': '11 milioni'}],\n",
       "     'id': '56d4fca52ccc5a1400d833e2',\n",
       "     'question': 'Quanto potrebbe arrivare il numero dei senzatetto?'}]},\n",
       "  {'context': \"Il terremoto ha avuto una magnitudine di 8,0 Ms e 7,9 Mw. L' epicentro è stato in Wenchuan County, Ngawa Tibetano e Prefettura Autonoma di Qiang, 80 km ad ovest / nord-ovest del capoluogo di provincia di Chengdu, con il suo tremore principale che si verifica alle 14:28:01.42 China Standard Time (06:28:01.42 UTC), il 12 maggio 2008 della durata di circa 2 minuti, nel terremoto quasi l' 80% degli edifici sono stati distrutti.\",\n",
       "   'qas': [{'answers': [{'answer_start': 355, 'text': '2 minuti'}],\n",
       "     'id': '56cdcc5562d2951400fa6847',\n",
       "     'question': 'Quanto tempo è durato il terremoto?'},\n",
       "    {'answers': [{'answer_start': 388, 'text': '80%'}],\n",
       "     'id': '56cdcc5562d2951400fa6848',\n",
       "     'question': 'Quale percentuale di edifici è stata distrutta?'},\n",
       "    {'answers': [{'answer_start': 41, 'text': '8,0 Ms e 7,9 Mw'}],\n",
       "     'id': '56d4fe332ccc5a1400d833e8',\n",
       "     'question': 'Qual era la magnitudo del terremoto?'},\n",
       "    {'answers': [{'answer_start': 355, 'text': '2 minuti'}],\n",
       "     'id': '56d4fe332ccc5a1400d833eb',\n",
       "     'question': 'Quanto tempo è durato il tremore principale?'},\n",
       "    {'answers': [{'answer_start': 379, 'text': \"quasi l' 80%\"}],\n",
       "     'id': '56d4fe332ccc5a1400d833ec',\n",
       "     'question': 'Quale percentuale di edifici è stata distrutta durante il sisma?'}]},\n",
       "  {'context': \"Secondo uno studio della China Earthquake Administration (CEA), il terremoto si è verificato lungo la faglia Longmenshan, una struttura di spinta lungo il confine della piastra Indo-Australiana e placca eurasiatica. Le attività sismiche si sono concentrate sulla sua frattura media (nota come frattura Yingxiu-Beichuan). La rottura è durata quasi 120 sec, con la maggior parte dell' energia rilasciata nei primi 80 sec. Partendo da Wenchuan, la rottura si propagò ad una velocità media di 3,1 chilometri al secondo 49° verso nord-est, rompendosi per un totale di circa 300 km. Lo spostamento massimo ammontava a 9 metri. Il fuoco era più profondo di 10 km.\",\n",
       "   'qas': [{'answers': [{'answer_start': 347, 'text': '120 sec'}],\n",
       "     'id': '56cdccd962d2951400fa6850',\n",
       "     'question': 'Quanto tempo ha durato la rottura?'},\n",
       "    {'answers': [{'answer_start': 650, 'text': '10 km'}],\n",
       "     'id': '56cdccd962d2951400fa6852',\n",
       "     'question': 'Quanto è stato profondo il centro del terremoto?'},\n",
       "    {'answers': [{'answer_start': 293, 'text': 'frattura Yingxiu-Beichuan'}],\n",
       "     'id': '56d5005d2ccc5a1400d833f4',\n",
       "     'question': 'Su quale frattura ha messo a fuoco il terremoto?'},\n",
       "    {'answers': [{'answer_start': 612, 'text': '9 metri'}],\n",
       "     'id': '56d5005d2ccc5a1400d833f6',\n",
       "     'question': 'Qual è stato lo sfollamento più causato dal terremoto?'}]},\n",
       "  {'context': 'Yazhou Zhoukan, con sede in Malesia, ha condotto un\\' intervista con l\\' ex ricercatore presso il China Seismological Bureau Geng Qingguo (??), in cui Geng ha sostenuto che un rapporto scritto riservato è stato inviato all\\' Ufficio sismologico di Stato il 30 aprile 2008, avvertendo circa il possibile verificarsi di un terremoto significativo nella regione della prefettura di Ngawa del Sichuan intorno all\\' 8 maggio, con una gamma di 10 giorni prima o dopo il terremoto. Il Geng, pur riconoscendo che la predizione del terremoto era ampiamente considerata problematica dalla comunità scientifica, credeva che \"più grande è il terremoto, più facile è prevedere\". Geng aveva a lungo tentato di stabilire una correlazione tra il verificarsi di siccità e terremoti; Premier Zhou Enlai ha riferito che ha preso interesse nel lavoro di Geng. La teoria di correlazione siccità-terra terremoto di Geng è stata pubblicata per la prima volta nel 1972, e ha detto di aver pronosticato con successo i terremoti di Haicheng 1975 e 1976 Tangshan. Lo stesso articolo di Yazhou Zhoukan ha sottolineato le difficoltà intrinseche associate alla previsione dei terremoti.',\n",
       "   'qas': [{'answers': [{'answer_start': 936, 'text': '1972'}],\n",
       "     'id': '56cdce0b62d2951400fa685b',\n",
       "     'question': 'Quando è stata rilasciata la teoria di correlazione siccità-terra terremoto di Geng?'},\n",
       "    {'answers': [{'answer_start': 394, 'text': \"intorno all' 8 maggio\"}],\n",
       "     'id': '56d67a8d1c8504140094714f',\n",
       "     'question': 'Qual era il tempo previsto per il terremoto?'},\n",
       "    {'answers': [{'answer_start': 741, 'text': 'siccità'}],\n",
       "     'id': '56d67a8d1c85041400947150',\n",
       "     'question': 'Che cosa ha cercato Geng a lungo di stabilire come rapporto con i terremoti?'}]},\n",
       "  {'context': 'In uno studio dell\\' USGS (United States Geological Survey) i modelli preliminari di rottura del terremoto hanno indicato uno spostamento fino a 9 metri lungo un guasto lungo circa 240 km di lunghezza e 20 km di profondità. Il terremoto ha generato deformazioni della superficie superiori a 3 metri e ha aumentato lo stress (e la probabilità che si verifichino eventi futuri) alle estremità nord-orientale e sud-occidentale del guasto. Il 20 maggio, il sismologo dell\\' USGS Tom Parsons ha avvertito che c\\' è \"alto rischio\" di una grave scossa di assestamento M>7 nelle prossime settimane o mesi.',\n",
       "   'qas': [{'answers': [{'answer_start': 137, 'text': 'fino a 9 metri'}],\n",
       "     'id': '56cdcebe62d2951400fa6862',\n",
       "     'question': 'Quanto è stato grande lo spostamento?'},\n",
       "    {'answers': [{'answer_start': 473, 'text': 'Tom Parsons'}],\n",
       "     'id': '56cdcebe62d2951400fa6866',\n",
       "     'question': \"Chi ha prima messo in guardia da possibili attività sismiche nell' area?\"},\n",
       "    {'answers': [{'answer_start': 144, 'text': '9 metri'}],\n",
       "     'id': '56d5027a9d1b871400ae05e1',\n",
       "     'question': \"Che cosa ha mostrato il Geological Survey degli Stati Uniti come l' entità dello spostamento?\"},\n",
       "    {'answers': [{'answer_start': 202, 'text': '20 km di profondità'}],\n",
       "     'id': '56d5027a9d1b871400ae05e3',\n",
       "     'question': 'Quanto è profondo il guasto?'},\n",
       "    {'answers': [{'answer_start': 508, 'text': 'alto rischio'}],\n",
       "     'id': '56d5027a9d1b871400ae05e5',\n",
       "     'question': 'Che cosa ha considerato Tom Parsons come il fattore di rischio per forti terremoti futuri?'}]},\n",
       "  {'context': 'Sismologo giapponese Yuji Yagi Yuji Yagi presso l\\' Università di Tsukuba ha detto che il terremoto si è verificato in due fasi:\"Il 155 miglia Longmenshan Fault tore in due sezioni, il primo uno strappo di circa sette metri, seguita da un secondo che ha tosato quattro metri\". I suoi dati hanno anche mostrato che il terremoto è durato circa due minuti e ha rilasciato 30 volte l\\' energia del grande terremoto di Hanshin del 1995 in Giappone, che ha ucciso oltre 6.000 persone. Egli ha sottolineato che la scarsità dell\\' epicentro e la densità di popolazione hanno notevolmente aumentato la gravità del terremoto. Teruyuki Kato, un sismologo dell\\' Università di Tokyo, ha detto che le onde sismiche del terremoto hanno percorso una lunga distanza senza perdere il loro potere a causa della fermezza del terreno nella Cina centrale.',\n",
       "   'qas': [{'answers': [{'answer_start': 115, 'text': 'in due fasi'}],\n",
       "     'id': '56d504539d1b871400ae05eb',\n",
       "     'question': 'Come ha fatto Yuji Yagi a dire che il terremoto è successo?'},\n",
       "    {'answers': [{'answer_start': 142, 'text': 'Longmenshan Fault'}],\n",
       "     'id': '56d504539d1b871400ae05ec',\n",
       "     'question': 'Che errore si è verificato in due luoghi?'},\n",
       "    {'answers': [{'answer_start': 368, 'text': '30 volte'}],\n",
       "     'id': '56d504539d1b871400ae05ee',\n",
       "     'question': 'Quanta più energia di quella prodotta dal terremoto del 1995 in Giappone?'},\n",
       "    {'answers': [{'answer_start': 789, 'text': 'fermezza del terreno'}],\n",
       "     'id': '56d504539d1b871400ae05ef',\n",
       "     'question': 'Perché le onde sismiche hanno viaggiato finora?'}]},\n",
       "  {'context': 'Tra 64 e 104 scosse di assestamento importanti, di magnitudo compresa tra 4,0 e 6,1, sono state registrate entro 72 ore dal sisma principale. Secondo i conteggi ufficiali cinesi,\"alle ore 12:00 CST, 6 novembre 2008 c\\' erano state 42.719 scariche post-shock totali, di cui 246 variavano da 4,0 SM a 4,9 SM, 34 da 5,0 MS a 5,9 MS, e 8 da 6,0 Ms a 6,4 MS; l\\' urto post-shock più forte misurato 6,4 MS.\" L\\' ultima scossa post-shock superiore a M6 si è verificato il 5 agosto.',\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Tra 64 e 104'}],\n",
       "     'id': '56cdd08862d2951400fa6894',\n",
       "     'question': 'Quante sono state le scosse di assestamento?'},\n",
       "    {'answers': [{'answer_start': 107,\n",
       "       'text': 'entro 72 ore dal sisma principale'}],\n",
       "     'id': '56cdd08862d2951400fa6896',\n",
       "     'question': 'Quando sono state registrate le scosse di assestamento?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Tra 64 e 104'}],\n",
       "     'id': '56d505f99d1b871400ae05f5',\n",
       "     'question': 'Quante sono state le scosse di assestamento entro 72 ore?'},\n",
       "    {'answers': [{'answer_start': 230, 'text': '42.719'}],\n",
       "     'id': '56d505f99d1b871400ae05f6',\n",
       "     'question': 'Che cosa dicono i cinesi è il numero totale di shock dopo il terremoto?'},\n",
       "    {'answers': [{'answer_start': 272, 'text': '246'}],\n",
       "     'id': '56d505f99d1b871400ae05f8',\n",
       "     'question': 'In quale data si sono verificate le scosse di assestamento più recenti superiori a 6 SM?'}]},\n",
       "  {'context': '(Il terremoto della sig. ra 6.1 del 30 agosto 2008 nel Sichuan meridionale non faceva parte di questa serie perché è stato causato da una diversa colpa.',\n",
       "   'qas': [{'answers': [{'answer_start': 55, 'text': 'Sichuan meridionale'}],\n",
       "     'id': '56cdd10962d2951400fa68a0',\n",
       "     'question': 'Dove si è verificato il terremoto?'},\n",
       "    {'answers': [{'answer_start': 55, 'text': 'Sichuan meridionale'}],\n",
       "     'id': '56cdd10962d2951400fa68a2',\n",
       "     'question': \"Dov' era il terremoto del 30 agosto 2008?\"},\n",
       "    {'answers': [{'answer_start': 20, 'text': 'sig'}],\n",
       "     'id': '56d507269d1b871400ae05ff',\n",
       "     'question': 'Qual era la grandezza del terremoto del Sichuan meridionale?'}]},\n",
       "  {'context': 'La mappa dell\\' intensità sismica pubblicata dal CEA dopo aver rilevato 500.000 km2 dell\\' area colpita mostra una liedu massima di XI sulla scala di intensità sismica cinese (CSIS), descritta come \"molto distruttiva\" sulla scala macrosismica europea (EMS) da cui il CSIS ha tratto riferimento. (USGS, utilizzando la scala di intensità Mercalli modificata (CC), collocava anche l\\' intensità massima a XI,\"molto disastrosa\". Due strisce sud-ovest-nord-est di liedu XI sono centrate intorno a Yingxiu, Wenchuan (la città più vicina all\\' epicentro del terremoto principale) e Beichuan (la città ripetutamente colpita da forti scosse di assestamento tra cui una che registra MS 6.1 il 1 agosto 2008), entrambe nella provincia del Sichuan, occupando un totale di 2.419 km2. La zona Yingxiu liedu-XI è lunga circa 66 km e larga 20 km lungo Wenchuan-Dujiangyan-Pengzhou; la zona Beichuan liedu-XI è lunga circa 82 km e larga 15 km lungo An County-Beichuan-Pingwu. L\\' area con liedu X (comparabile a X su EMS,\"distruttivo\" e X su MM,\"disastroso\") ha una superficie di 3.144 km2.',\n",
       "   'qas': [{'answers': [{'answer_start': 48, 'text': 'CEA'}],\n",
       "     'id': '56cdd21562d2951400fa68b0',\n",
       "     'question': \"Chi ha pubblicato la mappa dell' intensità dei terremoti?\"},\n",
       "    {'answers': [{'answer_start': 130, 'text': 'XI'}],\n",
       "     'id': '56cdd21562d2951400fa68b2',\n",
       "     'question': 'A quale intensità è stata scalata?'},\n",
       "    {'answers': [{'answer_start': 489, 'text': 'Yingxiu, Wenchuan'}],\n",
       "     'id': '56d5098a9d1b871400ae0609',\n",
       "     'question': \"Quale città era più vicina all' epicentro principale?\"}]},\n",
       "  {'context': \"Il sistema Longmen Shan Fault System si trova al confine orientale dell' altopiano tibetano e contiene diversi difetti. Questo terremoto ha rotto almeno due strutture imbricate in Longmen Shan Fault System, vale a dire il Fault Beichuan e il Guanxian-Anxian Fault. Nell' area epicentrale, lo slittamento medio in Fault Beichuan era di circa 3,5 metri (11 ft) verticale, di 3,5 metri (11 ft) orizzontale parallelo al guasto, e di 4,8 metri (16 ft) orizzontale-pendicolare al guasto. Nell' area di circa 30 chilometri (19 miglia) a nord-est dell' epicentro, lo scivolamento superficiale su Beichuan Fault è stato quasi esclusivamente dextral strike-slip fino a circa 3 metri, mentre lo scivolamento medio in Guanxian-Anxian Fault è stato di circa 2 metri verticali (6 ft 7 in) e 2,3 metri (7 ft 7 in) orizzontali. il confine orientale dell' altopiano tibetano.\",\n",
       "   'qas': [{'answers': [{'answer_start': 665, 'text': '3 metri'}],\n",
       "     'id': '56cdd4d762d2951400fa68cd',\n",
       "     'question': 'Quanto è stato grande lo slip 30 km a nord-est del guasto?'},\n",
       "    {'answers': [{'answer_start': 745, 'text': '2 metri'}],\n",
       "     'id': '56cdd4d762d2951400fa68ce',\n",
       "     'question': 'Qual è stato lo slittamento verticale media sul Guanxian-Anxian errore?'},\n",
       "    {'answers': [{'answer_start': 777, 'text': '2,3 metri'}],\n",
       "     'id': '56cdd4d762d2951400fa68cf',\n",
       "     'question': 'Che cosa è stato lo slittamento orizzontale media sul Guanxian-Anxian errore?'},\n",
       "    {'answers': [{'answer_start': 73, 'text': 'altopiano tibetano'}],\n",
       "     'id': '56cdd4d762d2951400fa68d0',\n",
       "     'question': 'Dove si trova il guasto dello shan Longmen?'},\n",
       "    {'answers': [{'answer_start': 3,\n",
       "       'text': 'sistema Longmen Shan Fault System'}],\n",
       "     'id': '56d516439d1b871400ae0611',\n",
       "     'question': 'Dove sono i guasti Beichuan e Guanxian-Ansia?'},\n",
       "    {'answers': [{'answer_start': 341, 'text': '3,5 metri'}],\n",
       "     'id': '56d516439d1b871400ae0612',\n",
       "     'question': 'Qual è stato lo slittamento verticale medio nel difetto di Beichaun?'},\n",
       "    {'answers': [{'answer_start': 341, 'text': '3,5 metri'}],\n",
       "     'id': '56d516439d1b871400ae0613',\n",
       "     'question': \"Qual è stato lo slittamento orizzontale nel Fault Beichuan all' epicentro?\"},\n",
       "    {'answers': [{'answer_start': 429, 'text': '4,8 metri'}],\n",
       "     'id': '56d516439d1b871400ae0614',\n",
       "     'question': 'Qual è stato lo slittamento orizzontale perpendicolare al guasto?'}]},\n",
       "  {'context': 'Gli edifici per uffici nel distretto finanziario di Shanghai, tra cui la Jin Mao Tower e la Hong Kong New World Tower, sono stati evacuati. Un receptionist al Tibet Hotel di Chengdu ha detto che le cose erano \"calme\" dopo che l\\' hotel ha evacuato i suoi ospiti. Nel frattempo, i lavoratori di uno stabilimento Ford nel Sichuan sono stati evacuati per circa 10 minuti. L\\' aeroporto internazionale di Chengdu Shuangliu è stato chiuso e la torre di controllo e il controllo radar regionale sono stati evacuati. Un volo di SilkAir è stato deviato e atterrato a Kunming. Cathay Pacific ha ritardato entrambe le tratte del suo quadruplo quotidiano Hong Kong a Londra a causa di questa perturbazione dei servizi di traffico aereo. Chengdu Shuangliu Aeroporto riaperto più tardi la sera del 12 maggio, offrendo un servizio limitato come l\\' aeroporto ha cominciato ad essere utilizzato come una zona di sosta per le operazioni di soccorso.',\n",
       "   'qas': [{'answers': [{'answer_start': 210, 'text': 'calm'}],\n",
       "     'id': '56cdd63a62d2951400fa68d7',\n",
       "     'question': \"Come ha descritto un receptionist l' atmosfera dopo l' evacuazione?\"},\n",
       "    {'answers': [{'answer_start': 357, 'text': '10 minuti'}],\n",
       "     'id': '56cdd63a62d2951400fa68d8',\n",
       "     'question': 'Per quanto tempo sono stati evacuati i lavoratori di Ford Plant?'},\n",
       "    {'answers': [{'answer_start': 371,\n",
       "       'text': 'aeroporto internazionale di Chengdu Shuangliu'}],\n",
       "     'id': '56cdd63a62d2951400fa68d9',\n",
       "     'question': 'Quale aeroporto è stato chiuso?'},\n",
       "    {'answers': [{'answer_start': 783, 'text': '12 maggio'}],\n",
       "     'id': '56cdd63a62d2951400fa68da',\n",
       "     'question': \"Quando è stato riaperto l' aeroporto?\"},\n",
       "    {'answers': [{'answer_start': 907, 'text': 'operazioni di soccorso'}],\n",
       "     'id': '56d5185a9d1b871400ae061d',\n",
       "     'question': \"A cosa servivano l' aeroporto per fare tappa?\"}]},\n",
       "  {'context': \"Reporter a Chengdu hanno detto che hanno visto crepe sulle pareti di alcuni edifici residenziali nelle zone del centro, ma nessun edificio è crollato. Molti uffici di Pechino torri ufficio sono stati evacuati, tra cui l' edificio che ospita gli uffici dei media per gli organizzatori delle Olimpiadi estive 2008. Nessuna delle sedi olimpiche sono state danneggiate. Nel frattempo, un treno cargo che trasportava 13 cisterne a benzina deragliato nella contea di Hui, Gansu, e prese fuoco dopo che la ferrovia era stata distorta.\",\n",
       "   'qas': [{'answers': [{'answer_start': 9, 'text': 'a Chengdu'}],\n",
       "     'id': '56cddec762d2951400fa692c',\n",
       "     'question': 'Dove hanno detto i giornalisti che hanno visto crepe sulle pareti di alcuni edifici?'},\n",
       "    {'answers': [{'answer_start': 167, 'text': 'Pechino'}],\n",
       "     'id': '56cddec762d2951400fa692d',\n",
       "     'question': 'Dove sono state evacuate le torri degli uffici?'},\n",
       "    {'answers': [{'answer_start': 47, 'text': 'crepe sulle pareti'}],\n",
       "     'id': '56d519a82593cc1400307a6b',\n",
       "     'question': 'Cosa è stato riportato in Chengdu?'}]},\n",
       "  {'context': \"Tutte le autostrade in Wenchuan, e altri in tutta la provincia, sono stati danneggiati, con conseguente ritardo di arrivo delle truppe di soccorso. Nella contea di Beichuan, l' 80% degli edifici è crollato secondo Xinhua News. Nella città di Shifang, il crollo di due impianti chimici ha portato alla fuoriuscita di circa 80 tonnellate di ammoniaca liquida, con centinaia di persone segnalate sepolte. Nella città di Dujiangyan, a sud-est dell' epicentro, un' intera scuola è crollata con 900 studenti sepolti e meno di 60 sopravvissuti. La Juyuan Middle School, dove sono stati sepolti molti adolescenti, è stata scavata da civili e gru. Dujiangyan è la sede del Dujiangyan Irrigation System, un antico progetto di deviazione dell' acqua che è ancora in uso ed è un patrimonio mondiale dell' UNESCO. La famosa bocca di pesce del progetto è stata incrinata, ma non gravemente danneggiata altrimenti.\",\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Tutte le autostrade'}],\n",
       "     'id': '56cddf9e62d2951400fa6934',\n",
       "     'question': 'Quante autostrade che conducono a Wenchuan sono state danneggiate?'},\n",
       "    {'answers': [{'answer_start': 177, 'text': '80%'}],\n",
       "     'id': '56cddf9e62d2951400fa6936',\n",
       "     'question': \"Quale percentuale dell' edificio è crollata a Beichuan?\"},\n",
       "    {'answers': [{'answer_start': 417, 'text': 'Dujiangyan'}],\n",
       "     'id': '56cddf9e62d2951400fa6937',\n",
       "     'question': 'Dove sono crollati due impianti chimici?'},\n",
       "    {'answers': [{'answer_start': 520, 'text': '60'}],\n",
       "     'id': '56cddf9e62d2951400fa6938',\n",
       "     'question': 'Quanti studenti su 900 nella scuola sono sopravvissuti al crollo?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Tutte le autostrade'}],\n",
       "     'id': '56d51b832593cc1400307a75',\n",
       "     'question': 'Quali autostrade di Wenchuan sono state danneggiate?'},\n",
       "    {'answers': [{'answer_start': 177, 'text': '80%'}],\n",
       "     'id': '56d51b832593cc1400307a77',\n",
       "     'question': 'Quanti edifici di Beichuan sono crollati?'},\n",
       "    {'answers': [{'answer_start': 264, 'text': 'due impianti chimici'}],\n",
       "     'id': '56d51b832593cc1400307a78',\n",
       "     'question': 'Quale ammoniaca liquida fuoriuscita a Shifang?'},\n",
       "    {'answers': [{'answer_start': 512, 'text': 'meno di 60'}],\n",
       "     'id': '56d51b832593cc1400307a79',\n",
       "     'question': 'Quanti dei 900 studenti sepolti in un crollo scolastico Dujiangyan sono sopravvissuti?'}]},\n",
       "  {'context': 'Sia la borsa valori di Shanghai che la Shenzhen Stock Exchange hanno sospeso il commercio di società con sede nella Cina sudoccidentale. Il rame è aumentato a causa delle speculazioni che la produzione nel sud-ovest della Cina potrebbe essere influenzata, e i prezzi del petrolio è sceso a fronte di speculazioni che la domanda dalla Cina sarebbe scesa.',\n",
       "   'qas': [{'answers': [{'answer_start': 116, 'text': 'Cina sudoccidentale'}],\n",
       "     'id': '56cddfff62d2951400fa693f',\n",
       "     'question': 'Dove si sono basati gli scambi?'},\n",
       "    {'answers': [{'answer_start': 140, 'text': 'rame'}],\n",
       "     'id': '56cddfff62d2951400fa6940',\n",
       "     'question': 'Quale metallo è aumentato di valore?'},\n",
       "    {'answers': [{'answer_start': 275, 'text': 'olio'}],\n",
       "     'id': '56cddfff62d2951400fa6941',\n",
       "     'question': 'Quale risorsa naturale è diminuita di valore?'},\n",
       "    {'answers': [{'answer_start': 116, 'text': 'Cina sudoccidentale'}],\n",
       "     'id': '56d51d272593cc1400307a80',\n",
       "     'question': 'Dove si trovavano le società che avevano sospeso il loro commercio di azioni?'},\n",
       "    {'answers': [{'answer_start': 140, 'text': 'rame'}],\n",
       "     'id': '56d51d272593cc1400307a81',\n",
       "     'question': 'Quale metallo è aumentato a causa della speculazione?'},\n",
       "    {'answers': [{'answer_start': 39, 'text': 'Shenzhen Stock Exchange'}],\n",
       "     'id': '56d51d272593cc1400307a83',\n",
       "     'question': 'Oltre alla borsa valori di Shanghai, quale altra borsa sospesa negoziazione di titoli azionari sud-ovest della Cina?'}]},\n",
       "  {'context': \"Immediatamente dopo l' evento sismico, le telecomunicazioni mobili e terrestri sono state tagliate verso l' area colpita e quella circostante, con tutte le capacità internet tagliate anche verso l' area del Sichuan. Elementi di telecomunicazioni sono stati ripristinati dal governo pezzo per pezzo nel corso dei prossimi mesi come la situazione nella provincia del Sichuan gradualmente migliorata. Alla fine, una manciata di importanti siti web di notizie e media sono stati resi accessibili online nella regione, anche se con pagine web drammaticamente ridotte.\",\n",
       "   'qas': [{'answers': [{'answer_start': 165, 'text': 'internet'}],\n",
       "     'id': '56cde07662d2951400fa6947',\n",
       "     'question': \"Quali capacità sono state tagliate all' intera area del Sichuan?\"},\n",
       "    {'answers': [{'answer_start': 321, 'text': 'mesi'}],\n",
       "     'id': '56cde07662d2951400fa6948',\n",
       "     'question': 'Quanto tempo ci è voluto per ripristinare queste capacità?'},\n",
       "    {'answers': [{'answer_start': 42, 'text': 'telecomunicazioni'}],\n",
       "     'id': '56d51ea52593cc1400307a89',\n",
       "     'question': 'Cosa è stato tagliato dopo il terremoto?'},\n",
       "    {'answers': [{'answer_start': 436, 'text': 'siti web di notizie e media'}],\n",
       "     'id': '56d51ea52593cc1400307a8c',\n",
       "     'question': \"Quali servizi internet sono diminuiti nell' area?\"}]},\n",
       "  {'context': \"China Mobile ha avuto più di 2.300 stazioni base sospese a causa di interruzione dell' alimentazione o grave congestione del traffico delle telecomunicazioni. Metà delle comunicazioni wireless sono andate perse nella provincia del Sichuan. Il servizio di China Unicom a Wenchuan e in quattro contee vicine è stato interrotto, con più di 700 torri sospese.\",\n",
       "   'qas': [{'answers': [{'answer_start': 29, 'text': '2.300'}],\n",
       "     'id': '56cde11f62d2951400fa694c',\n",
       "     'question': 'Quante stazioni base sono state sospese?'},\n",
       "    {'answers': [{'answer_start': 29, 'text': '2.300'}],\n",
       "     'id': '56d5202a2593cc1400307a93',\n",
       "     'question': 'Quante stazioni base China Mobile hanno smesso di funzionare?'},\n",
       "    {'answers': [{'answer_start': 109, 'text': 'congestione del traffico'}],\n",
       "     'id': '56d5202a2593cc1400307a94',\n",
       "     'question': \"Oltre all' interruzione dell' alimentazione, cosa ha causato la sospensione delle telecomunicazioni?\"},\n",
       "    {'answers': [{'answer_start': 159, 'text': 'Metà'}],\n",
       "     'id': '56d5202a2593cc1400307a95',\n",
       "     'question': 'Quante comunicazioni wireless sono fallite nel Sichuan?'},\n",
       "    {'answers': [{'answer_start': 255, 'text': 'China Unicom'}],\n",
       "     'id': '56d5202a2593cc1400307a96',\n",
       "     'question': 'Chi servizio a Wenchuan è stato interrotto?'},\n",
       "    {'answers': [{'answer_start': 337, 'text': '700'}],\n",
       "     'id': '56d5202a2593cc1400307a97',\n",
       "     'question': 'Quante torri di China Unicom sono state tagliate?'}]},\n",
       "  {'context': \"Inizialmente, i funzionari non erano in grado di contattare la Wolong National Nature Reserve, sede di circa 280 panda giganti. Tuttavia, il Ministero degli Esteri in seguito ha detto che un gruppo di 31 turisti britannici che visitano la riserva Wolong Panda nella zona colpita dal terremoto ha restituito sicuro e indenne a Chengdu. Tuttavia, il benessere di un numero ancora maggiore di panda nelle vicine riserve del panda è rimasto sconosciuto. Cinque guardie di sicurezza della riserva sono state uccise dal terremoto. Sei panda sono fuggiti dopo che i loro recinti sono stati danneggiati. Entro il 20 maggio, due panda presso la riserva sono stati trovati per essere feriti, mentre la ricerca è continuata per altri due panda adulti che è andato perduto dopo il terremoto. Al 28 maggio 2008 mancava ancora un panda. Il panda mancante è stato poi trovato morto sotto le macerie di un recinto. Mao Mao Mao Mao, nove anni, madre di cinque anni nel centro di allevamento, è stata scoperta lunedì, il suo corpo schiacciato da un muro nel suo recinto. I detentori di panda e altri lavoratori hanno messo i suoi resti in una piccola cassa di legno e l' hanno seppellita fuori dal centro di allevamento.\",\n",
       "   'qas': [{'answers': [{'answer_start': 103, 'text': 'circa 280'}],\n",
       "     'id': '56cde1f462d2951400fa695f',\n",
       "     'question': 'Quanti panda vivono nella riserva?'},\n",
       "    {'answers': [{'answer_start': 201, 'text': '31'}],\n",
       "     'id': '56cde1f462d2951400fa6960',\n",
       "     'question': 'Quanti visitatori britannici della Riserva hanno lasciato illeso?'},\n",
       "    {'answers': [{'answer_start': 109, 'text': '2'}],\n",
       "     'id': '56cde1f462d2951400fa6961',\n",
       "     'question': 'Quanti panda sono stati feriti?'},\n",
       "    {'answers': [{'answer_start': 63,\n",
       "       'text': 'Wolong National Nature Reserve'}],\n",
       "     'id': '56d521ee2593cc1400307a9d',\n",
       "     'question': 'Quale centro naturalistico è stato tagliato?'},\n",
       "    {'answers': [{'answer_start': 525, 'text': 'Sei'}],\n",
       "     'id': '56d521ee2593cc1400307a9f',\n",
       "     'question': 'Quanti panda sono fuggiti dalla riserva?'},\n",
       "    {'answers': [{'answer_start': 450, 'text': 'cinque'}],\n",
       "     'id': '56d521ee2593cc1400307aa0',\n",
       "     'question': 'Quante guardie di sicurezza sono morte nella riserva?'},\n",
       "    {'answers': [{'answer_start': 899, 'text': 'Mao Mao Mao'}],\n",
       "     'id': '56d521ee2593cc1400307aa1',\n",
       "     'question': 'Quale famoso panda è stato ucciso sotto le macerie?'}]},\n",
       "  {'context': \"La centrale idroelettrica Zipingpu (semplificata cinese:????; tradizionale cinese:??????) situata a 20 km ad est dell' epicentro è stata danneggiata. Da una recente ispezione è emerso che il danno era meno grave di quanto inizialmente temuto e resta strutturalmente stabile e sicuro. Il serbatoio di Tulong a monte rischia di crollare. Circa 2.000 soldati sono stati assegnati a Zipingpu, cercando di liberare la pressione attraverso lo sfioratore. In totale sono state segnalate 391 dighe, per la maggior parte di piccole dimensioni, danneggiate dal sisma.\",\n",
       "   'qas': [{'answers': [{'answer_start': 342, 'text': '2.000'}],\n",
       "     'id': '56cde29b62d2951400fa696b',\n",
       "     'question': 'Quante truppe sono state assegnate a Zipingpu?'},\n",
       "    {'answers': [{'answer_start': 480, 'text': '391'}],\n",
       "     'id': '56cde29b62d2951400fa696c',\n",
       "     'question': 'Quante dighe sono state danneggiate?'},\n",
       "    {'answers': [{'answer_start': 100, 'text': '20 km'}],\n",
       "     'id': '56d523bd2593cc1400307aa8',\n",
       "     'question': \"Quanto era vicina all' epicentro la centrale elettrica?\"},\n",
       "    {'answers': [{'answer_start': 201, 'text': 'meno grave'}],\n",
       "     'id': '56d523bd2593cc1400307aa9',\n",
       "     'question': 'Che cosa è emerso da una recente ispezione sui danni alla centrale?'},\n",
       "    {'answers': [{'answer_start': 480, 'text': '391'}],\n",
       "     'id': '56d523bd2593cc1400307aab',\n",
       "     'question': 'Qual è il numero totale di dighe danneggiate?'}]},\n",
       "  {'context': \"Secondo i funzionari di Stato cinesi, il terremoto ha causato 69.180 morti conosciute tra cui 68.636 nella provincia del Sichuan; 18.498 persone sono elencate come scomparse, e 374.176 feriti, ma queste cifre possono ulteriormente aumentare con l' arrivo di più rapporti.\",\n",
       "   'qas': [{'answers': [{'answer_start': 94, 'text': '68.636'}],\n",
       "     'id': '56cde34662d2951400fa6973',\n",
       "     'question': 'Quanti decessi sono stati segnalati solo nella provincia del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 130, 'text': '18.498'}],\n",
       "     'id': '56cde34662d2951400fa6974',\n",
       "     'question': \"Quante persone sono state inserite nell' elenco come scomparse?\"},\n",
       "    {'answers': [{'answer_start': 177, 'text': '374.176'}],\n",
       "     'id': '56cde34662d2951400fa6975',\n",
       "     'question': 'Quante persone sono rimaste ferite?'},\n",
       "    {'answers': [{'answer_start': 94, 'text': '68.636'}],\n",
       "     'id': '56d525192593cc1400307ab1',\n",
       "     'question': 'Quanti morti nel Sichuan?'},\n",
       "    {'answers': [{'answer_start': 62, 'text': '69.180'}],\n",
       "     'id': '56d525192593cc1400307ab2',\n",
       "     'question': 'Qual è il conteggio totale dei morti noti causati dal terremoto?'},\n",
       "    {'answers': [{'answer_start': 130, 'text': '18.498'}],\n",
       "     'id': '56d525192593cc1400307ab3',\n",
       "     'question': 'Qual è il numero di persone scomparse?'},\n",
       "    {'answers': [{'answer_start': 177, 'text': '374.176'}],\n",
       "     'id': '56d525192593cc1400307ab4',\n",
       "     'question': 'Quante persone sono rimaste ferite?'}]},\n",
       "  {'context': \"Una squadra di soccorso ha riportato solo 2.300 sopravvissuti della città di Yingxiu nella contea di Wenchuan, su una popolazione totale di circa 9.000 abitanti. Da 3.000 a 5.000 persone sono state uccise nella sola contea di Beichuan, nel Sichuan; nello stesso luogo, 10.000 persone sono rimaste ferite e l' 80% degli edifici sono stati distrutti. L' antica sede della contea di Beichuan è stata abbandonata e conservata come parte del Beichuan Earthquake Museum. Otto scuole sono state abbattute nel Dujiangyan. Un cinquantaseienne è stato ucciso a Dujiangyan durante un tentativo di salvataggio sulla Lingyanshan Ropeway, dove a causa del terremoto 11 turisti taiwanesi erano rimasti intrappolati all' interno di funivie dal 13 maggio. Un ragazzo di 4 anni di nome Zhu Shaowei (cinese tradizionale:???; cinese semplificato:???; pinyin: Zh? Shàowéi) è stato ucciso anche a Mianzhu City quando una casa è crollata su di lui e un altro è stato segnalato perduto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 42, 'text': '2.300'}],\n",
       "     'id': '56ceb9c4aab44d1400b8892b',\n",
       "     'question': 'Quanti sopravvissuti ci sono stati da Yingxiu?'},\n",
       "    {'answers': [{'answer_start': 146, 'text': '9.000'}],\n",
       "     'id': '56ceb9c4aab44d1400b8892d',\n",
       "     'question': 'Quante persone in totale vivevano a Yingxiu?'},\n",
       "    {'answers': [{'answer_start': 162, 'text': 'Da 3.000 a 5.000'}],\n",
       "     'id': '56ceb9c4aab44d1400b8892e',\n",
       "     'question': 'Quante persone sono state uccise nella contea di Beichuan?'},\n",
       "    {'answers': [{'answer_start': 269, 'text': '10.000'}],\n",
       "     'id': '56ceb9c4aab44d1400b8892f',\n",
       "     'question': 'Quante persone sono rimaste ferite nella contea di Beichuan?'},\n",
       "    {'answers': [{'answer_start': 42, 'text': '2.300'}],\n",
       "     'id': '56d5307f2593cc1400307abb',\n",
       "     'question': \"Quanti sopravvissuti c' erano nella città di Yingxiu?\"},\n",
       "    {'answers': [{'answer_start': 140, 'text': 'circa 9.000'}],\n",
       "     'id': '56d5307f2593cc1400307abc',\n",
       "     'question': 'Qual era la popolazione precedente di Yingxiu?'},\n",
       "    {'answers': [{'answer_start': 162, 'text': 'Da 3.000 a 5.000'}],\n",
       "     'id': '56d5307f2593cc1400307abd',\n",
       "     'question': 'Quanti residenti sono stati uccisi nella contea di Beichuan?'},\n",
       "    {'answers': [{'answer_start': 269, 'text': '10.000'}],\n",
       "     'id': '56d5307f2593cc1400307abe',\n",
       "     'question': 'Quanto è stato grande il numero di feriti nella contea di Beichuan?'},\n",
       "    {'answers': [{'answer_start': 465, 'text': 'Otto scuole'}],\n",
       "     'id': '56d5307f2593cc1400307abf',\n",
       "     'question': 'Qual è il numero di scuole crollate in Dujiangyan?'}]},\n",
       "  {'context': 'Gli esperti sottolineano che il terremoto ha colpito un\\' area in gran parte trascurata e non toccata dall\\' ascesa economica della Cina. L\\' assistenza sanitaria è carente nelle zone interne come il Sichuan, il che mette in evidenza il crescente divario tra gli abitanti urbani prosperi e le popolazioni rurali in difficoltà. Vice Ministro della Sanità Gao Qiang ha detto ai giornalisti a Pechino che il \"sistema sanitario pubblico in Cina è insufficiente\".',\n",
       "   'qas': [{'answers': [{'answer_start': 351, 'text': 'Gao Qiang'}],\n",
       "     'id': '56ceba72aab44d1400b88936',\n",
       "     'question': 'Chi era il Vice Ministro della Salute?'},\n",
       "    {'answers': [{'answer_start': 176, 'text': 'zone interne'}],\n",
       "     'id': '56d5324d2593cc1400307ac6',\n",
       "     'question': \"Dove è povera l' assistenza sanitaria in Cina?\"},\n",
       "    {'answers': [{'answer_start': 440, 'text': 'insufficiente'}],\n",
       "     'id': '56d5324d2593cc1400307ac7',\n",
       "     'question': 'Che cosa ha chiamato il Vice Ministro della Salute il sistema sanitario pubblico in Cina?'}]},\n",
       "  {'context': 'In termini di feriti scolastici, migliaia di bambini sono morti a causa di costruzioni scadenti. A Mianyang City, sette scuole sono crollate, seppellendo almeno 1.700 persone. Almeno 7.000 edifici scolastici in tutta la provincia sono crollati. Altri 700 studenti sono stati sepolti in una scuola di Hanwang. Alla scuola elementare Juyuan sono morti almeno 600 studenti e personale. Fino a 1.300 bambini e insegnanti sono morti alla Beichuan Middle School.',\n",
       "   'qas': [{'answers': [{'answer_start': 33, 'text': 'migliaia'}],\n",
       "     'id': '56cebae8aab44d1400b8893d',\n",
       "     'question': 'Quanti bambini sono morti a causa di costruzioni scadenti?'},\n",
       "    {'answers': [{'answer_start': 114, 'text': 'sette'}],\n",
       "     'id': '56cebae8aab44d1400b8893e',\n",
       "     'question': 'Quante scuole sono crollate a Mianyang City?'},\n",
       "    {'answers': [{'answer_start': 161, 'text': '1.700'}],\n",
       "     'id': '56cebae8aab44d1400b8893f',\n",
       "     'question': 'Quante persone sono state sepolte nelle scuole crollate?'},\n",
       "    {'answers': [{'answer_start': 183, 'text': '7.000'}],\n",
       "     'id': '56cebae8aab44d1400b88940',\n",
       "     'question': 'Quanti edifici scolastici sono crollati in provincia?'},\n",
       "    {'answers': [{'answer_start': 163, 'text': '700'}],\n",
       "     'id': '56cebae8aab44d1400b88941',\n",
       "     'question': 'Quanti studenti sono stati sepolti in una scuola di Hanwang?'},\n",
       "    {'answers': [{'answer_start': 114, 'text': 'sette'}],\n",
       "     'id': '56d533a52593cc1400307ad0',\n",
       "     'question': 'Quante scuole sono crollate a Mianyang City?'},\n",
       "    {'answers': [{'answer_start': 183, 'text': '7.000'}],\n",
       "     'id': '56d533a52593cc1400307ad1',\n",
       "     'question': 'Quanti edifici scolastici sono caduti in tutta la provincia?'},\n",
       "    {'answers': [{'answer_start': 357, 'text': '600'}],\n",
       "     'id': '56d533a52593cc1400307ad2',\n",
       "     'question': 'Quanti sono stati uccisi alla scuola elementare di Juyuan?'}]},\n",
       "  {'context': \"I dettagli delle vittime scolastiche sono stati oggetto di indagini non governative dal dicembre 2008 da parte di volontari, tra cui l' artista e architetto Ai Weiwei, che dal marzo 2009 ha costantemente pubblicato aggiornamenti sul suo blog. Il conteggio ufficiale degli studenti uccisi nel terremoto è stato rilasciato solo il 7 maggio 2009, quasi un anno dopo il terremoto. Secondo l' agenzia di stampa statale Xinhua, il terremoto ha ucciso 5.335 studenti e lasciato altri 546 bambini disabili. All' indomani del terremoto, il governo cinese ha dichiarato che i genitori che avevano perso i loro soli figli avrebbero ricevuto cure gratuite da cliniche di fertilità per invertire vasectomie e legature tubarie condotte dalle autorità di pianificazione familiare.\",\n",
       "   'qas': [{'answers': [{'answer_start': 88, 'text': 'dicembre 2008'}],\n",
       "     'id': '56cebb71aab44d1400b88951',\n",
       "     'question': \"Quando si è svolta un' indagine in seguito a incidenti scolastici?\"},\n",
       "    {'answers': [{'answer_start': 329, 'text': '7 maggio 2009'}],\n",
       "     'id': '56cebb71aab44d1400b88952',\n",
       "     'question': 'Quando è stato rilasciato il conteggio ufficiale degli studenti uccisi nel terremoto?'},\n",
       "    {'answers': [{'answer_start': 445, 'text': '5.335'}],\n",
       "     'id': '56cebb71aab44d1400b88953',\n",
       "     'question': 'Quanti studenti sono stati uccisi a Xinhua?'},\n",
       "    {'answers': [{'answer_start': 477, 'text': '546'}],\n",
       "     'id': '56cebb71aab44d1400b88954',\n",
       "     'question': 'Quanti studenti sono stati disabili a Xinhua?'},\n",
       "    {'answers': [{'answer_start': 329, 'text': '7 maggio 2009'}],\n",
       "     'id': '56d5357b2593cc1400307ad9',\n",
       "     'question': 'Qual è stata la data in cui è stato rilasciato il numero ufficiale degli studenti uccisi nel terremoto?'},\n",
       "    {'answers': [{'answer_start': 157, 'text': 'Ai Weiwei'}],\n",
       "     'id': '56d5357b2593cc1400307ada',\n",
       "     'question': 'Chi ha tenuto un blog sui decessi scolastici?'},\n",
       "    {'answers': [{'answer_start': 445, 'text': '5.335'}],\n",
       "     'id': '56d5357b2593cc1400307adb',\n",
       "     'question': 'Qual è il numero totale di bambini che hanno perso la scuola?'},\n",
       "    {'answers': [{'answer_start': 477, 'text': '546'}],\n",
       "     'id': '56d5357b2593cc1400307adc',\n",
       "     'question': 'Quanti bambini sono disabili?'},\n",
       "    {'answers': [{'answer_start': 647, 'text': 'cliniche di fertilità'}],\n",
       "     'id': '56d5357b2593cc1400307add',\n",
       "     'question': 'Dove ha deciso il governo cinese che i genitori che avevano perso i figli potessero farsi curare gratuitamente?'}]},\n",
       "  {'context': \"Il terremoto ha lasciato almeno 5 milioni di persone senza alloggio, anche se il numero potrebbe raggiungere gli 11 milioni. Milioni di animali da allevamento e una notevole quantità di agricoltura sono stati distrutti, tra cui 12,5 milioni di animali, principalmente uccelli. Nella provincia del Sichuan sono morti un milione di suini su un totale di 60 milioni. Catastrophe modeling firm AIR Worldwide ha riportato stime ufficiali delle perdite degli assicuratori pari a 1 miliardo di dollari USA dal terremoto; i danni totali stimati superano i 20 miliardi di dollari USA. Valorizza Chengdu, all' epoca con una popolazione urbana di 4,5 milioni di persone, a circa 115 miliardi di dollari, con solo una piccola parte coperta da assicurazioni.\",\n",
       "   'qas': [{'answers': [{'answer_start': 32, 'text': '5 milioni'}],\n",
       "     'id': '56cebbdeaab44d1400b88959',\n",
       "     'question': 'Quante persone sono rimaste senza alloggio?'},\n",
       "    {'answers': [{'answer_start': 113, 'text': '11 milioni'}],\n",
       "     'id': '56cebbdeaab44d1400b8895a',\n",
       "     'question': 'Quante persone potrebbero essere potenzialmente senza alloggio?'},\n",
       "    {'answers': [{'answer_start': 228, 'text': '12,5 milioni'}],\n",
       "     'id': '56cebbdeaab44d1400b8895b',\n",
       "     'question': 'Quanti animali sono stati uccisi?'},\n",
       "    {'answers': [{'answer_start': 113, 'text': '11 milioni'}],\n",
       "     'id': '56d5372f2593cc1400307ae4',\n",
       "     'question': 'Quante persone potrebbero effettivamente essere senzatetto?'},\n",
       "    {'answers': [{'answer_start': 228, 'text': '12,5 milioni di animali'}],\n",
       "     'id': '56d5372f2593cc1400307ae5',\n",
       "     'question': 'Quanto bestiame è andato perduto?'},\n",
       "    {'answers': [{'answer_start': 316, 'text': 'un milione'}],\n",
       "     'id': '56d5372f2593cc1400307ae6',\n",
       "     'question': 'Quanti maiali sono morti a causa del terremoto nel Sichuan?'}]},\n",
       "  {'context': 'Reginald DesRoches, professore di ingegneria civile e ambientale presso la Georgia Tech, ha sottolineato che i danni massicci di proprietà e case nella zona sismica sono dovuti al fatto che la Cina ha creato un adeguato codice di progettazione sismica solo dopo il devastante terremoto di Tangshan del 1976. DesRoches ha detto:\"Se gli edifici fossero più vecchi e costruiti prima di quel terremoto del 1976, è probabile che non siano stati costruiti per un\\' adeguata forza sismica\".',\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Reginald DesRoches'}],\n",
       "     'id': '56cebcb4aab44d1400b88963',\n",
       "     'question': 'Chi era professore di ingegneria civile e ambientale alla Georgia Tech?'},\n",
       "    {'answers': [{'answer_start': 20,\n",
       "       'text': 'professore di ingegneria civile e ambientale'}],\n",
       "     'id': '56d538bc2593cc1400307aed',\n",
       "     'question': 'Qual è la professione di Reginald DesRoches?'},\n",
       "    {'answers': [{'answer_start': 302, 'text': '1976'}],\n",
       "     'id': '56d538bc2593cc1400307aee',\n",
       "     'question': \"Quando la Cina ha creato un codice di progettazione sismica per l' edilizia?\"},\n",
       "    {'answers': [{'answer_start': 276, 'text': 'terremoto di Tangshan'}],\n",
       "     'id': '56d538bc2593cc1400307aef',\n",
       "     'question': \"Che catastrofe li ha spinti a fare un codice di progettazione dell' edificio /.?\"}]},\n",
       "  {'context': \"Nei giorni successivi al disastro, un team internazionale di ingegneri è stato inviato nella regione per effettuare un' indagine preliminare dettagliata sugli edifici danneggiati. I loro risultati mostrano una varietà di ragioni per cui molte costruzioni non sono riuscite a resistere al terremoto.\",\n",
       "   'qas': []},\n",
       "  {'context': 'Le notizie di cronaca indicano che i villaggi rurali più poveri sono stati colpiti più duramente. Swaminathan Krishnan, assistente professore di ingegneria civile e geofisica presso il California Institute of Technology ha dichiarato:\"Il terremoto si è verificato nella parte rurale della Cina. Probabilmente, molti degli edifici sono stati appena costruiti; non sono stati progettati, per così dire. Swaminathan Krishnan ha aggiunto:\"In Cina ci sono norme edilizie molto forti, che si occupano di terremoto e problemi di progettazione sismica.',\n",
       "   'qas': [{'answers': [{'answer_start': 98, 'text': 'Swaminathan Krishnan'}],\n",
       "     'id': '56cebd8aaab44d1400b88978',\n",
       "     'question': 'Chi era professore assistente di ingegneria civile e geofisica presso il California Institute of Technology?'},\n",
       "    {'answers': [{'answer_start': 270, 'text': 'parte rurale'}],\n",
       "     'id': '56d53bf82593cc1400307afd',\n",
       "     'question': 'In quale parte della Cina si è verificato il terremoto?'}]},\n",
       "  {'context': 'Anche con le cinque città più grandi del Sichuan che subiscono solo danni di modesta entità a causa del terremoto, alcune stime della perdita economica superano i 75 miliardi di dollari, rendendo il terremoto uno dei disastri naturali più costosi della storia cinese.',\n",
       "   'qas': [{'answers': [{'answer_start': 163,\n",
       "       'text': '75 miliardi di dollari'}],\n",
       "     'id': '56cebdd0aab44d1400b8897f',\n",
       "     'question': 'Qual è la stima della perdita economica del terremoto?'},\n",
       "    {'answers': [{'answer_start': 163, 'text': '75 miliardi di dollari'}],\n",
       "     'id': '56d53d9a2593cc1400307b08',\n",
       "     'question': 'Qual è la stima delle perdite economiche?'},\n",
       "    {'answers': [{'answer_start': 253, 'text': 'storia cinese'}],\n",
       "     'id': '56d53d9a2593cc1400307b09',\n",
       "     'question': 'Chi è questo uno dei disastri più costosi della storia di?'},\n",
       "    {'answers': [{'answer_start': 13, 'text': 'cinque città più grandi'}],\n",
       "     'id': '56d53d9a2593cc1400307b0a',\n",
       "     'question': 'Quali città del Sichuan hanno subito danni minori?'}]},\n",
       "  {'context': \"Forti scosse di assestamento hanno continuato a colpire anche mesi dopo il terremoto principale. Il 25 maggio, una scossa di assestamento di 6.0 Mw (6.4 Ms secondo CEA) ha colpito a nord-est dell' epicentro del terremoto originale, nella contea di Qingchuan, Sichuan, causando otto morti, 1000 feriti e distruggendo migliaia di edifici. Il 27 maggio, due scosse di assestamento, una 5.2 Mw nella contea di Qingchuan e una 5.7 Mw nella contea di Ningqiang, Shaanxi, hanno portato al crollo di oltre 420.000 case e feriti 63 persone. La stessa area ha sofferto due scosse di assestamento più di 5,6 e 6,0 Ms (5,8 e 5,5 Mw, rispettivamente, secondo USGS) il 23 luglio, con conseguente 1 decesso, 6 feriti gravi, crollo di centinaia di case e danni chilometri di autostrade. Pingwu County e Beichuan County, Sichuan, anche a nord-est di Wenchuan e vicino all' epicentro di un terremoto della sig. ra 7.2 nel 1976, subì un terremoto di 6.1 Ms aftershock (5.7 Mw secondo l' USGS) il 1 agosto 1; ha causato 2 morti, 345 feriti, crollo di 707 case, danni a oltre 1.000 case, e bloccato 25 chilometri (16 mi) di strade di campagna.\",\n",
       "   'qas': [{'answers': [{'answer_start': 141, 'text': '6.0 Mw'}],\n",
       "     'id': '56d540072593cc1400307b0f',\n",
       "     'question': 'Quanto è stata forte la scossa di assestamento del 25 maggio nella contea di Qingchuan?'},\n",
       "    {'answers': [{'answer_start': 289, 'text': '1000'}],\n",
       "     'id': '56d540072593cc1400307b10',\n",
       "     'question': 'Quante persone sono rimaste ferite durante la scossa di assestamento del 25 maggio?'},\n",
       "    {'answers': [{'answer_start': 520, 'text': '63'}],\n",
       "     'id': '56d540072593cc1400307b12',\n",
       "     'question': 'Durante il 27 maggio scosse di assestamento, quante persone sono rimaste ferite?'},\n",
       "    {'answers': [{'answer_start': 248, 'text': 'Qingchuan, Sichuan'}],\n",
       "     'id': '56d540072593cc1400307b13',\n",
       "     'question': \"Dov' è stata la scossa di assestamento del 5 agosto che ha causato ampie frane di collina?\"}]},\n",
       "  {'context': 'Vice governatore esecutivo Wei Hong Wei ha confermato il 21 novembre 2008 che più di 90.000 persone in totale erano morti o dispersi nel terremoto. Ha dichiarato che 200.000 case sono state ricostruite e 685.000 sono in fase di ricostruzione, ma 1,94 milioni di famiglie sono ancora prive di ricovero permanente. Sono state ricostruite 1.300 scuole, con il trasferimento iniziale di 25 città, tra cui Beichuan e Wenchuan, due delle aree più devastate. Il governo ha speso 441 miliardi di dollari per gli sforzi di soccorso e ricostruzione.',\n",
       "   'qas': [{'answers': [{'answer_start': 27, 'text': 'Wei Hong'}],\n",
       "     'id': '56cebef6aab44d1400b88997',\n",
       "     'question': 'Chi era il vice governatore esecutivo?'},\n",
       "    {'answers': [{'answer_start': 166, 'text': '200.000'}],\n",
       "     'id': '56cebef6aab44d1400b88999',\n",
       "     'question': 'Quante case sono state ricostruite?'},\n",
       "    {'answers': [{'answer_start': 336, 'text': '1.300'}],\n",
       "     'id': '56cebef6aab44d1400b8899b',\n",
       "     'question': 'Quante scuole sono state ricostruite?'},\n",
       "    {'answers': [{'answer_start': 27, 'text': 'Wei Hong'}],\n",
       "     'id': '56d548552593cc1400307b19',\n",
       "     'question': 'Chi ha parlato dei morti e dei dispersi il 21 novembre 2008?'},\n",
       "    {'answers': [{'answer_start': 85, 'text': '90.000'}],\n",
       "     'id': '56d548552593cc1400307b1a',\n",
       "     'question': 'Quante persone hanno detto Wei Hong che erano morte o mancanti?'},\n",
       "    {'answers': [{'answer_start': 166, 'text': '200.000'}],\n",
       "     'id': '56d548552593cc1400307b1b',\n",
       "     'question': 'Quante case sono state ricostruite?'},\n",
       "    {'answers': [{'answer_start': 204, 'text': '685.000'}],\n",
       "     'id': '56d548552593cc1400307b1c',\n",
       "     'question': 'Quante case erano ancora in costruzione?'}]},\n",
       "  {'context': \"Il segretario generale e presidente Hu Jintao ha annunciato che la risposta alle catastrofi sarà rapida. A soli 90 minuti dal terremoto, il premier Wen Jiabao, che ha una formazione accademica in geomeccanica, ha volato nella zona del terremoto per sorvegliare i lavori di salvataggio. Poco dopo, il Ministero della Salute ha detto che aveva inviato dieci squadre mediche di emergenza a Wenchuan County. Lo stesso giorno, il comando militare della regione militare di Chengdu ha inviato 50.000 soldati e polizia armata per aiutare con il lavoro di soccorso in caso di catastrofe nella contea di Wenchuan. Tuttavia, a causa del terreno accidentato e della vicinanza dell' epicentro del sisma, i soldati hanno avuto molte difficoltà ad ottenere aiuto nelle regioni rurali della provincia.\",\n",
       "   'qas': [{'answers': [{'answer_start': 137,\n",
       "       'text': 'il premier Wen Jiabao'}],\n",
       "     'id': '56cebf6aaab44d1400b889a1',\n",
       "     'question': \"Chi ha volato nella zona sismica 90 minuti dopo l' urto?\"},\n",
       "    {'answers': [{'answer_start': 196, 'text': 'geomeccanica'}],\n",
       "     'id': '56cebf6aaab44d1400b889a2',\n",
       "     'question': \"In cosa c' era il background di Premier Wen Jiabao?\"},\n",
       "    {'answers': [{'answer_start': 261, 'text': 'i lavori di salvataggio'}],\n",
       "     'id': '56cebf6aaab44d1400b889a3',\n",
       "     'question': 'Che cosa ha supervisionato Jiabao nella regione?'},\n",
       "    {'answers': [{'answer_start': 487, 'text': '50.000'}],\n",
       "     'id': '56cebf6aaab44d1400b889a4',\n",
       "     'question': 'Quante truppe sono state inviate dai militari Chengdu?'},\n",
       "    {'answers': [{'answer_start': 350, 'text': 'dieci'}],\n",
       "     'id': '56d54a582593cc1400307b25',\n",
       "     'question': 'Quante squadre mediche sono state inviate nella contea di Wenchuan?'},\n",
       "    {'answers': [{'answer_start': 487, 'text': '50.000'}],\n",
       "     'id': '56d54a582593cc1400307b26',\n",
       "     'question': 'Quante truppe sono state inviate nella zona per operazioni di soccorso?'}]},\n",
       "  {'context': 'La Commissione nazionale di soccorso in caso di catastrofe ha avviato un \"piano di emergenza di II livello\", che copre la categoria più grave di catastrofi naturali. Il piano è salito al livello I alle 22:15 CST, 12 maggio.',\n",
       "   'qas': [{'answers': [{'answer_start': 197,\n",
       "       'text': 'alle 22:15 CST, 12 maggio'}],\n",
       "     'id': '56cebfcaaab44d1400b889ab',\n",
       "     'question': 'Quando è salito il piano al livello I?'},\n",
       "    {'answers': [{'answer_start': 132, 'text': 'più grave'}],\n",
       "     'id': '56d54bc82593cc1400307b2e',\n",
       "     'question': \"Quale classe di catastrofi è un' emergenza di livello II?\"},\n",
       "    {'answers': [{'answer_start': 3,\n",
       "       'text': 'Commissione nazionale di soccorso in caso di catastrofe'}],\n",
       "     'id': '56d54bc82593cc1400307b30',\n",
       "     'question': 'Quale dipartimento ha avviato il piano di emergenza?'}]},\n",
       "  {'context': \"Un' équipe di soccorso in caso di terremoto di 184 persone (composta da 12 persone dell' Ufficio sismologico di Stato, 150 del Comando dell' Area militare di Pechino e 22 dell' Ospedale Generale della Polizia Armata) ha lasciato Pechino dall' aeroporto di Nanyuan alla fine del 12 maggio in due aerei da trasporto militare per raggiungere la contea di Wenchuan.\",\n",
       "   'qas': [{'answers': [{'answer_start': 47, 'text': '184'}],\n",
       "     'id': '56cec033aab44d1400b889af',\n",
       "     'question': 'Quante persone erano nel team di soccorso in caso di terremoto?'},\n",
       "    {'answers': [{'answer_start': 72, 'text': '12'}],\n",
       "     'id': '56cec033aab44d1400b889b0',\n",
       "     'question': \"Quante squadre di soccorso provenivano dall' Ufficio sismologico di Stato?\"},\n",
       "    {'answers': [{'answer_start': 119, 'text': '150'}],\n",
       "     'id': '56cec033aab44d1400b889b1',\n",
       "     'question': 'Quanti membri della squadra erano militari?'},\n",
       "    {'answers': [{'answer_start': 168, 'text': '22'}],\n",
       "     'id': '56cec033aab44d1400b889b2',\n",
       "     'question': 'Quanti membri della squadra provenivano dalla polizia?'},\n",
       "    {'answers': [{'answer_start': 47, 'text': '184'}],\n",
       "     'id': '56d5d41b1c85041400946e0d',\n",
       "     'question': 'Quante persone costituivano la squadra di soccorso?'},\n",
       "    {'answers': [{'answer_start': 119, 'text': '150'}],\n",
       "     'id': '56d5d41b1c85041400946e0e',\n",
       "     'question': \"Quanti soldati provenivano dall' esercito di Pechino?\"},\n",
       "    {'answers': [{'answer_start': 177,\n",
       "       'text': 'Ospedale Generale della Polizia Armata'}],\n",
       "     'id': '56d5d41b1c85041400946e0f',\n",
       "     'question': 'Da dove provengono 22 della squadra di soccorso?'}]},\n",
       "  {'context': 'Nel China Digital Times un articolo riporta un\\' analisi approfondita da parte di un presunto ingegnere edile cinese conosciuto online come \"Book Blade\" (??), che ha dichiarato: un\\' analisi approfondita da parte di un presunto ingegnere edile cinese.',\n",
       "   'qas': [{'answers': [{'answer_start': 140, 'text': 'Book Blade'}],\n",
       "     'id': '56cec11faab44d1400b889c8',\n",
       "     'question': \"Dov' è stato riportato un articolo sullo scandalo?\"},\n",
       "    {'answers': [{'answer_start': 4, 'text': 'China Digital Times'}],\n",
       "     'id': '56d64d231c85041400947089',\n",
       "     'question': 'Qual è stato il nome della persona che ha pubblicato un rapporto nel China Digital Times?'}]},\n",
       "  {'context': 'In occasione della Festa dei bambini, il 1° giugno 2008, molti genitori si sono recati sulle macerie delle scuole per piangere i loro figli. I bambini sopravvissuti, che vivevano per lo più in centri di soccorso, hanno compiuto cerimonie che hanno segnato il giorno speciale, ma anche riconosciuto il terremoto.',\n",
       "   'qas': [{'answers': [{'answer_start': 19, 'text': 'Festa dei bambini'}],\n",
       "     'id': '56cec174aab44d1400b889cb',\n",
       "     'question': 'Che cosa è stato chiamato 1 giugno 2008?'}]},\n",
       "  {'context': \"Le imprese statali centrali hanno donato complessivamente più di 48,6 milioni di dollari. China National Petroleum Corp e Sinopec ha donato 10 milioni di yuan ciascuno per l' area del disastro.\",\n",
       "   'qas': [{'answers': [{'answer_start': 140, 'text': '10 milioni di yuan'}],\n",
       "     'id': '56cec1ffaab44d1400b889de',\n",
       "     'question': 'Quanto ha donato China National Petroleum Corp e Sinopec?'},\n",
       "    {'answers': [{'answer_start': 65, 'text': '48,6 milioni'}],\n",
       "     'id': '56d6647b1c850414009470ed',\n",
       "     'question': 'Quanto hanno donato le imprese statali centrali?'},\n",
       "    {'answers': [{'answer_start': 140, 'text': '10 milioni di yuan ciascuno'}],\n",
       "     'id': '56d6647b1c850414009470ee',\n",
       "     'question': 'Quanto ha donato China National Petroleum e Sinopec?'}]},\n",
       "  {'context': \"Il 16 maggio la Cina ha dichiarato di aver ricevuto anche 457 milioni di dollari in donazioni di denaro e beni per gli sforzi di salvataggio finora compiuti, compresi 83 milioni di dollari provenienti da 19 paesi e quattro organizzazioni internazionali. L' Arabia Saudita è stata il principale donatore di aiuti alla Cina, fornendo quasi 40.000.000 di euro in assistenza finanziaria e altri 8.000.000 di euro di materiale di soccorso.\",\n",
       "   'qas': [{'answers': [{'answer_start': 58,\n",
       "       'text': '457 milioni di dollari'}],\n",
       "     'id': '56cec2a1aab44d1400b889e1',\n",
       "     'question': 'Quanto ha ricevuto la Cina in denaro e beni donati?'},\n",
       "    {'answers': [{'answer_start': 204, 'text': '19 paesi'}],\n",
       "     'id': '56cec2a1aab44d1400b889e2',\n",
       "     'question': 'Quanti paesi hanno donato?'},\n",
       "    {'answers': [{'answer_start': 215, 'text': 'quattro'}],\n",
       "     'id': '56cec2a1aab44d1400b889e3',\n",
       "     'question': 'Quante organizzazioni internazionali hanno donato?'},\n",
       "    {'answers': [{'answer_start': 257, 'text': 'Arabia Saudita'}],\n",
       "     'id': '56cec2a1aab44d1400b889e4',\n",
       "     'question': 'Quale paese è stato il maggiore donatore di aiuti alla Cina?'},\n",
       "    {'answers': [{'answer_start': 167, 'text': '83 milioni'}],\n",
       "     'id': '56d6696d1c850414009470fb',\n",
       "     'question': 'Quanto denaro è stato donato da fonti straniere?'},\n",
       "    {'answers': [{'answer_start': 257, 'text': 'Arabia Saudita'}],\n",
       "     'id': '56d6696d1c850414009470fc',\n",
       "     'question': 'Quale paese è stato il maggiore donatore di aiuti alla Cina?'},\n",
       "    {'answers': [{'answer_start': 215, 'text': 'quattro'}],\n",
       "     'id': '56d6696d1c850414009470fe',\n",
       "     'question': 'Quante organizzazioni internazionali hanno fatto donazioni?'}]},\n",
       "  {'context': 'Nel 2008, il Consiglio di Stato ha stabilito un piano di sostegno alla controparte????????? Il piano è quello di organizzare 19 province orientali e centrali e municipalitie per aiutare 18 contee, su \"una provincia a una contea interessata\" base. Il piano ha una durata di 3 anni, e costa non meno dell\\' uno per cento del bilancio della provincia o del comune. un piano di sostegno di contropartita.',\n",
       "   'qas': [{'answers': [{'answer_start': 273, 'text': '3 anni'}],\n",
       "     'id': '56d66f3e1c85041400947117',\n",
       "     'question': 'Quanto dura il piano?'},\n",
       "    {'answers': [{'answer_start': 304, 'text': 'uno per cento'}],\n",
       "     'id': '56d66f3e1c85041400947118',\n",
       "     'question': 'Qual è il costo per il bilancio della provincia?'}]},\n",
       "  {'context': 'Un articolo in Science suggerisce che la costruzione e il riempimento della diga di Zipingpu potrebbe aver innescato il terremoto. L\\' ingegnere capo del Sichuan Geology and Mineral Bureau ha detto che lo spostamento improvviso di una grande quantità d\\' acqua nella regione avrebbe potuto allentare la tensione tra i due lati del guasto, permettendo loro di allontanarsi, e avrebbe potuto aumentare la pressione diretta su di esso, causando una violenta rottura. L\\' effetto è stato \"25 volte più\" dello stress naturale del movimento tettonico di un anno. Il governo aveva ignorato gli avvertimenti relativi a tanti progetti di dighe su larga scala in un\\' area sismicamente attiva. Ai ricercatori è stato negato l\\' accesso ai dati sismologici e geologici per esaminare ulteriormente la causa del terremoto.',\n",
       "   'qas': [{'answers': [{'answer_start': 554, 'text': 'Il governo'}],\n",
       "     'id': '56d677f31c85041400947145',\n",
       "     'question': 'Chi ha ignorato gli avvertimenti sulle dighe nella zona?'},\n",
       "    {'answers': [{'answer_start': 713,\n",
       "       'text': 'accesso ai dati sismologici e geologici'}],\n",
       "     'id': '56d677f31c85041400947147',\n",
       "     'question': 'Che cosa sono stati negati ai ricercatori?'}]},\n",
       "  {'context': 'Il terremoto ha inoltre offerto ai ricercatori l\\' opportunità di aggiornare i dati per modellare le previsioni future. Utilizzando i dati dell\\' osservatorio geomagnetico Intermagnet Lanzhou, i geologi Lazo Pekevski della Ss. Cyril e Methodius University di Skopje in Macedonia e Strachimir Mavrodiev dell\\' Accademia bulgara delle Scienze hanno cercato di stabilire un \"metodo di previsione temporale\" attraverso la raccolta di statistiche sul geomagnetismo con potenziale gravitazionale delle maree. Utilizzando questo metodo, si diceva che avessero previsto il tempo del terremoto del Sichuan del 2008 con una precisione di ± 1 giorno. Lo stesso studio, tuttavia, riconosce la limitazione dei modelli di previsione dei terremoti e non menziona che la localizzazione del sisma potrebbe essere accuratamente prevista.',\n",
       "   'qas': [{'answers': [{'answer_start': 559,\n",
       "       'text': 'il tempo del terremoto del Sichuan del 2008'}],\n",
       "     'id': '56cec484aab44d1400b88a09',\n",
       "     'question': 'Cosa prevedevano i professori?'},\n",
       "    {'answers': [{'answer_start': 427, 'text': 'statistiche'}],\n",
       "     'id': '56d675ed1c8504140094713d',\n",
       "     'question': 'Cosa hanno raccolto per usare questo metodo?'}]},\n",
       "  {'context': 'In una conferenza stampa tenuta dall\\' Ufficio informazioni del Consiglio di Stato il giorno dopo il terremoto, il geologo Zhang Xiaodong, vice direttore del CEA Seismic Monitoring Network Center, ha ribadito che la previsione del terremoto era un problema globale, nel senso che non esistono metodi comprovati, e che nessuna notifica di previsione è stata ricevuta prima del terremoto. Il sismologo Gary Gibson dell\\' Università di Monash University in Australia ha detto a Deutsche Presse-Agentur che anche lui non vedeva nulla che potesse essere considerato come aver \"previsto\" l\\' accadimento del terremoto.',\n",
       "   'qas': [{'answers': [{'answer_start': 279,\n",
       "       'text': 'non esistono metodi comprovati'}],\n",
       "     'id': '56d674591c85041400947133',\n",
       "     'question': 'Che cosa credono molti geologi nella previsione dei terremoti?'},\n",
       "    {'answers': [{'answer_start': 317,\n",
       "       'text': 'nessuna notifica di previsione'}],\n",
       "     'id': '56d674591c85041400947135',\n",
       "     'question': 'Cosa è stato ricevuto prima del terremoto?'}]},\n",
       "  {'context': \"Nel 2002, il geologo cinese Chen Xuezhong ha pubblicato uno studio di analisi del rischio sismico in cui è giunto alla conclusione che a partire dal 2003, l' attenzione dovrebbe essere prestata alla possibilità di un terremoto con una magnitudo superiore a 7,0 che si verifica nella regione del Sichuan. Ha basato il suo studio sulla correlazione statistica. Che il Sichuan è un' area sismicamente attiva è stata discussa per anni prima del terremoto, anche se pochi studi indicano una data e un' ora specifiche.\",\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Nel 2002'}],\n",
       "     'id': '56cec548aab44d1400b88a13',\n",
       "     'question': \"Quando è stata pubblicata l' analisi del rischio sismico?\"},\n",
       "    {'answers': [{'answer_start': 28, 'text': 'Chen Xuezhong'}],\n",
       "     'id': '56cec548aab44d1400b88a14',\n",
       "     'question': \"Chi ha pubblicato l' analisi del rischio sismico?\"},\n",
       "    {'answers': [{'answer_start': 28, 'text': 'Chen Xuezhong'}],\n",
       "     'id': '56d672d21c85041400947129',\n",
       "     'question': 'Chi ha pubblicato uno studio di analisi del rischio sismico?'},\n",
       "    {'answers': [{'answer_start': 4, 'text': '2002'}],\n",
       "     'id': '56d672d21c8504140094712a',\n",
       "     'question': 'In quale anno Chen Xuezhong ha pubblicato uno studio sul terremoto?'}]},\n",
       "  {'context': 'Il terremoto è stato il peggiore a colpire l\\' area del Sichuan in oltre 30 anni. A seguito del terremoto, esperti e il pubblico in generale hanno chiesto informazioni per sapere se il terremoto avrebbe potuto essere previsto in anticipo e se lo studio delle statistiche relative al terremoto avrebbe potuto portare a una migliore previsione dei terremoti in futuro. La predizione del terremoto non è ancora una scienza consolidata; non c\\' era consenso all\\' interno della comunità scientifica sul fatto che la \"previsione\" del terremoto sia possibile.',\n",
       "   'qas': [{'answers': [{'answer_start': 66, 'text': 'oltre 30 anni'}],\n",
       "     'id': '56cec5d1aab44d1400b88a23',\n",
       "     'question': 'Da quanto tempo si è verificato un terremoto di simile entità?'},\n",
       "    {'answers': [{'answer_start': 72, 'text': '30 anni'}],\n",
       "     'id': '56d6713f1c8504140094711f',\n",
       "     'question': \"Da quanto tempo da quando l' area del Sichuan ha subito un grave terremoto?\"},\n",
       "    {'answers': [{'answer_start': 258, 'text': 'statistiche'}],\n",
       "     'id': '56d6713f1c85041400947122',\n",
       "     'question': 'La gente voleva sapere se lo studio di quale matematica poteva produrre previsioni migliori?'}]},\n",
       "  {'context': 'Molte squadre di soccorso, tra cui quella del Taipei Fire Department di Taiwan, sono state segnalate pronte ad unirsi allo sforzo di salvataggio nel Sichuan già mercoledì. Tuttavia, la Croce Rossa Società della Cina ha detto che (il 13 maggio)\"è stato scomodo attualmente a causa del problema del traffico alle zone più colpite più vicino all\\' epicentro\". La Società della Croce Rossa Cinese ha anche dichiarato che le zone disastrate hanno bisogno di tende, forniture mediche, acqua potabile e cibo; tuttavia ha raccomandato di donare denaro invece di altri oggetti, in quanto non era stato possibile raggiungere strade completamente danneggiate o luoghi che sono stati bloccati da frane. Le frane minacciavano continuamente il progresso di un gruppo di ricerca e salvataggio di 80 uomini, ognuno dei quali trasportava circa 40 kg di materiale di soccorso, provenienti da una brigata motorizzata di fanteria sotto il comandante Yang Wenyao, mentre cercavano di raggiungere il villaggio etnicamente tibetano di Sier ad un\\' altezza di 4000 m sul livello del mare nella contea di Pingwu.',\n",
       "   'qas': [{'answers': [{'answer_start': 683, 'text': 'frane'}],\n",
       "     'id': '56d5db271c85041400946e42',\n",
       "     'question': 'Quale problema ha continuato ad impedire alle squadre di soccorso di raggiungere le zone colpite?'}]},\n",
       "  {'context': \"Le piogge e gli smottamenti persistenti nella contea di Wenchuan e nella zona vicina hanno gravemente influenzato gli sforzi di salvataggio. All' inizio delle operazioni di soccorso, il 12 maggio, sono stati impiegati 20 elicotteri per la fornitura di cibo, acqua e aiuti d' emergenza, nonché per l' evacuazione dei feriti e la ricognizione delle aree colpite dal terremoto. A partire dalle 17:37 CST del 13 maggio, un totale di oltre 15.600 soldati e riservisti della milizia della regione militare di Chengdu si erano uniti alla forza di soccorso nelle zone gravemente colpite. Un comandante ha riferito da Yingxiu Town, Wenchuan, che sono stati trovati circa 3.000 sopravvissuti, mentre lo stato degli altri abitanti (circa 9.000) è rimasto poco chiaro. I 1.300 soccorritori raggiunsero l' epicentro e 300 truppe pioniere raggiunsero la sede di Wenchuan a circa 23:30 CST. Entro le 12:17 CST, 14 maggio 2008, la comunicazione nella sede di Wenchuan è stata in parte ripresa. Il pomeriggio del 14 maggio, 15 operazioni speciali 15 truppe, insieme con le forniture di soccorso e attrezzature di comunicazione, paracadutati in inaccessibile Mao County, a nord-est di Wenchuan.\",\n",
       "   'qas': [{'answers': [{'answer_start': 218, 'text': '20'}],\n",
       "     'id': '56cec79caab44d1400b88a34',\n",
       "     'question': 'Quanti elicotteri sono stati impiegati?'},\n",
       "    {'answers': [{'answer_start': 435, 'text': '15.600'}],\n",
       "     'id': '56cec79caab44d1400b88a35',\n",
       "     'question': 'Quanti riservisti delle milizie si sono uniti agli sforzi di salvataggio?'},\n",
       "    {'answers': [{'answer_start': 656, 'text': 'circa 3.000'}],\n",
       "     'id': '56cec79caab44d1400b88a36',\n",
       "     'question': 'Quanti sopravvissuti sono stati trovati?'},\n",
       "    {'answers': [{'answer_start': 435, 'text': '15'}],\n",
       "     'id': '56cec79caab44d1400b88a37',\n",
       "     'question': 'Quante truppe paracadute nella contea di Mao?'},\n",
       "    {'answers': [{'answer_start': 218, 'text': '20'}],\n",
       "     'id': '56d5ecf21c85041400946e5b',\n",
       "     'question': 'Quanti elicotteri sono stati inviati per fornire aiuti alle zone colpite?'},\n",
       "    {'answers': [{'answer_start': 435, 'text': '15.600'}],\n",
       "     'id': '56d5ecf21c85041400946e5c',\n",
       "     'question': 'Entro il 13 maggio, quante truppe erano state aggiunte agli sforzi di salvataggio?'},\n",
       "    {'answers': [{'answer_start': 656, 'text': 'circa 3.000'}],\n",
       "     'id': '56d5ecf21c85041400946e5d',\n",
       "     'question': 'Come sono state segnalate le persone sopravvissute nella città di Yingxiu?'},\n",
       "    {'answers': [{'answer_start': 721, 'text': 'circa 9.000'}],\n",
       "     'id': '56d5ecf21c85041400946e5e',\n",
       "     'question': 'Quante persone a Yingxiu erano ancora sconosciute?'}]},\n",
       "  {'context': \"Il 15 maggio, il premier Wen Jiabao ha ordinato lo spiegamento di altri 90 elicotteri, di cui 60 forniti dal PLAAF e 30 forniti dall' industria dell' aviazione civile, portando così il numero totale di aeromobili impiegati nelle operazioni di soccorso dall' aviazione civile, dall' esercito e dall' aviazione civile a oltre 150, il che ha portato alla più grande operazione di non combattimento nella storia dell' Esercito popolare di liberazione.\",\n",
       "   'qas': [{'answers': [{'answer_start': 94, 'text': '60'}],\n",
       "     'id': '56cec801aab44d1400b88a3e',\n",
       "     'question': 'Quanti elicotteri sono stati forniti dal PLAAF?'},\n",
       "    {'answers': [{'answer_start': 117, 'text': '30'}],\n",
       "     'id': '56cec801aab44d1400b88a3f',\n",
       "     'question': \"Quanti elicotteri sarebbero stati forniti dall' industria dell' aviazione civile?\"},\n",
       "    {'answers': [{'answer_start': 318, 'text': 'oltre 150'}],\n",
       "     'id': '56cec801aab44d1400b88a40',\n",
       "     'question': \"Quanti aerei c' erano in totale?\"},\n",
       "    {'answers': [{'answer_start': 318, 'text': 'oltre 150'}],\n",
       "     'id': '56d60cd01c85041400946eea',\n",
       "     'question': \"Qual è il numero totale di aeromobili utilizzati nell' operazione di soccorso?\"},\n",
       "    {'answers': [{'answer_start': 94, 'text': '60'}],\n",
       "     'id': '56d60cd01c85041400946eec',\n",
       "     'question': 'Quanti elicotteri provenivano dal PLAAF?'},\n",
       "    {'answers': [{'answer_start': 134,\n",
       "       'text': \"industria dell' aviazione civile\"}],\n",
       "     'id': '56d60cd01c85041400946eed',\n",
       "     'question': 'Chi ha fornito gli altri 30 elicotteri?'}]},\n",
       "  {'context': \"Pechino ha accettato l' aiuto della Fondazione Tzu Chi di Taiwan alla fine del 13 maggio. Tzu Chi è stata la prima forza al di fuori della Repubblica Popolare Cinese a partecipare allo sforzo di salvataggio. La Cina ha dichiarato di voler accettare con gratitudine l' aiuto internazionale per far fronte al terremoto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 36, 'text': 'Fondazione Tzu Chi'}],\n",
       "     'id': '56cec88baab44d1400b88a45',\n",
       "     'question': 'Quale Fondazione ha voluto aiutare Pechino?'},\n",
       "    {'answers': [{'answer_start': 58, 'text': 'Taiwan'}],\n",
       "     'id': '56cec88baab44d1400b88a46',\n",
       "     'question': \"Dov' era la fondazione?\"},\n",
       "    {'answers': [{'answer_start': 36, 'text': 'Fondazione Tzu Chi'}],\n",
       "     'id': '56d60ddf1c85041400946ef5',\n",
       "     'question': \"Qual è stato il primo gruppo di fuori della Cina a partecipare all' operazione di soccorso?\"},\n",
       "    {'answers': [{'answer_start': 268, 'text': 'aiuto internazionale'}],\n",
       "     'id': '56d60ddf1c85041400946ef6',\n",
       "     'question': 'Che cosa ha detto la Cina di accettare?'}]},\n",
       "  {'context': \"Un volo merci charter diretto è stato effettuato dalla China Airlines da Taiwan Taoyuan International Airport all' aeroporto internazionale di Chengdu Shuangliu, che ha inviato circa 100 tonnellate di forniture di soccorso donate dalla Fondazione Tzu Chi e dalla Croce Rossa di Taiwan alle zone colpite. È stata chiesta l' approvazione delle autorità cinesi della Cina continentale e il volo charter è partito da Taipei alle 17:00 CST, il 15 maggio e è arrivato a Chengdu entro le 20:30 CST. Una squadra di soccorso della Croce Rossa di Taiwan avrebbe dovuto partire da Taipei con un volo charter diretto di Mandarin Airlines verso Chengdu alle 15:00 CST del 16 maggio.\",\n",
       "   'qas': [{'answers': [{'answer_start': 55, 'text': 'China Airlines'}],\n",
       "     'id': '56cec8e2aab44d1400b88a55',\n",
       "     'question': 'Chi ha effettuato un volo cargo charter diretto?'},\n",
       "    {'answers': [{'answer_start': 439, 'text': '15 maggio'}],\n",
       "     'id': '56cec8e2aab44d1400b88a57',\n",
       "     'question': 'Quale data di partenza del volo cargo?'},\n",
       "    {'answers': [{'answer_start': 659, 'text': '16 maggio'}],\n",
       "     'id': '56cec8e2aab44d1400b88a58',\n",
       "     'question': 'Quando è partita una squadra di soccorso?'},\n",
       "    {'answers': [{'answer_start': 73,\n",
       "       'text': 'Taiwan Taoyuan International Airport'}],\n",
       "     'id': '56d613011c85041400946efd',\n",
       "     'question': 'Da quale aeroporto parte il volo charter?'},\n",
       "    {'answers': [{'answer_start': 143, 'text': 'Chengdu'}],\n",
       "     'id': '56d613011c85041400946efe',\n",
       "     'question': 'Dove è avvenuto il volo charter da Taiwan?'},\n",
       "    {'answers': [{'answer_start': 496, 'text': 'squadra di soccorso'}],\n",
       "     'id': '56d613011c85041400946eff',\n",
       "     'question': 'Che cosa ha lasciato il team della Croce Rossa a Taipei il 16 maggio Chengdu?'}]},\n",
       "  {'context': \"Il 16 maggio, i gruppi di soccorso provenienti da Corea del Sud, Giappone, Singapore, Russia e Taiwan sono arrivati per unirsi allo sforzo di salvataggio. Gli Stati Uniti hanno condiviso con le autorità cinesi alcune delle sue immagini satellitari delle zone colpite dal terremoto. Durante il fine settimana, gli Stati Uniti hanno inviato in Cina due forniture di trasporto dell' aeronautica militare C-17 degli Stati Uniti, tra cui tende e generatori. Xinhua ha riferito 135.000 truppe cinesi e medici sono stati coinvolti nello sforzo di salvataggio in 58 contee e città. immagini satellitari delle aree colpite dal terremoto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 472, 'text': '135.000'}],\n",
       "     'id': '56cec9e1aab44d1400b88a63',\n",
       "     'question': 'Quante truppe cinesi sono state coinvolte negli sforzi di salvataggio?'},\n",
       "    {'answers': [{'answer_start': 3, 'text': '16 maggio'}],\n",
       "     'id': '56cec9e1aab44d1400b88a65',\n",
       "     'question': 'Quando sono arrivati in Cina gruppi provenienti dalla Corea del Sud, dal Giappone e da altri paesi?'},\n",
       "    {'answers': [{'answer_start': 227, 'text': 'immagini satellitari'}],\n",
       "     'id': '56d61a451c85041400946f10',\n",
       "     'question': 'Che cosa ha condiviso gli Stati Uniti con la Cina?'},\n",
       "    {'answers': [{'answer_start': 433, 'text': 'tende e generatori'}],\n",
       "     'id': '56d61a451c85041400946f11',\n",
       "     'question': \"Cosa è stato incluso nelle forniture dell' aeronautica militare C-17?\"},\n",
       "    {'answers': [{'answer_start': 472, 'text': '135.000'}],\n",
       "     'id': '56d61a451c85041400946f13',\n",
       "     'question': 'Quante truppe e medici cinesi sono stati coinvolti negli sforzi di soccorso?'}]},\n",
       "  {'context': \"Internet è stato ampiamente utilizzato per trasmettere informazioni a sostegno degli sforzi di salvataggio e recupero. Ad esempio, l' agenzia di stampa ufficiale Xinhua ha istituito un centro online di richiesta di soccorso per trovare gli angoli ciechi del disaster recovery. Dopo aver saputo che gli elicotteri di soccorso avevano avuto difficoltà ad atterrare nell' area dell' epicentro di Wenchuan, uno studente ha proposto un punto di atterraggio online ed è stato scelto come primo touchdown per gli elicotteri[non in citazione dato]. I volontari hanno anche creato diversi siti web per aiutare a memorizzare le informazioni di contatto per le vittime e gli sfollati. Il 31 maggio, un elicottero di salvataggio che trasportava sopravvissuti al terremoto e membri dell' equipaggio si è schiantato a causa della nebbia e delle turbolenze nella contea di Wenchuan. Nessuno è sopravvissuto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Internet'}],\n",
       "     'id': '56ceccc7aab44d1400b88a7d',\n",
       "     'question': 'Che cosa è stato ampiamente utilizzato per trasmettere informazioni a sostegno degli sforzi di salvataggio e recupero?'},\n",
       "    {'answers': [{'answer_start': 228,\n",
       "       'text': 'trovare gli angoli ciechi del disaster recovery'}],\n",
       "     'id': '56ceccc7aab44d1400b88a7f',\n",
       "     'question': 'Qual era lo scopo di questo centro di richiesta di soccorso online?'},\n",
       "    {'answers': [{'answer_start': 393, 'text': 'Wenchuan'}],\n",
       "     'id': '56ceccc7aab44d1400b88a80',\n",
       "     'question': 'Dove hanno avuto difficoltà di atterraggio gli elicotteri di soccorso?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Internet'}],\n",
       "     'id': '56d61c4e1c85041400946f1a',\n",
       "     'question': 'Che cosa è stato utilizzato come aiuto alle comunicazioni negli sforzi di soccorso?'},\n",
       "    {'answers': [{'answer_start': 403, 'text': 'uno studente'}],\n",
       "     'id': '56d61c4e1c85041400946f1c',\n",
       "     'question': \"Quale persona ha suggerito un atterraggio per elicotteri vicino all' epicentro?\"},\n",
       "    {'answers': [{'answer_start': 618, 'text': 'informazioni di contatto'}],\n",
       "     'id': '56d61c4e1c85041400946f1d',\n",
       "     'question': 'Che tipo di informazioni sono state create sui siti web da archiviare?'}]},\n",
       "  {'context': \"Il 12 maggio 2009, la Cina ha celebrato il primo anniversario del terremoto con un momento di silenzio mentre le persone in tutta la nazione ricordavano i morti. Il governo ha anche aperto l' accesso alle rovine sigillate della sede della contea del Beichuan per tre giorni, dopo di che sarà congelato in tempo come un museo reliquia terremoto di stato, per ricordare alla gente del disastro terribile. Ci sono stati anche diversi concerti in tutto il paese per raccogliere fondi per i sopravvissuti al terremoto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 80,\n",
       "       'text': 'un momento di silenzio'}],\n",
       "     'id': '56cecd53aab44d1400b88a88',\n",
       "     'question': \"Cosa è stato fatto per l' anniversario?\"},\n",
       "    {'answers': [{'answer_start': 263, 'text': 'tre giorni'}],\n",
       "     'id': '56cecd53aab44d1400b88a8a',\n",
       "     'question': 'Per quanto tempo è stato aperto?'},\n",
       "    {'answers': [{'answer_start': 80, 'text': 'un momento di silenzio'}],\n",
       "     'id': '56d66b221c85041400947103',\n",
       "     'question': 'Che cosa ha fatto la Cina per celebrare il primo anniversario del terremoto?'},\n",
       "    {'answers': [{'answer_start': 423, 'text': 'diversi concerti'}],\n",
       "     'id': '56d66b221c85041400947105',\n",
       "     'question': 'Che tipo di evento è stato dato per raccogliere fondi per i sopravvissuti al terremoto?'}]},\n",
       "  {'context': 'A seguito del terremoto, le donazioni sono state effettuate da persone provenienti da tutta la Cina continentale, con cabine allestite nelle scuole, presso le banche e nelle vicinanze di distributori di benzina. La gente ha anche donato sangue, con conseguente secondo Xinhua lungo line-up Xinhua nella maggior parte delle principali città cinesi. Molti donato attraverso messaggi di testo sui telefoni cellulari per i conti istituiti da China Unicom e China Mobile 16 maggio, il governo cinese aveva stanziato un totale di 772 milioni di dollari per il terremoto di soccorso finora, in forte aumento da $ 159 milioni di dollari dal 14 maggio sangue.',\n",
       "   'qas': [{'answers': [{'answer_start': 230, 'text': 'donato sangue'}],\n",
       "     'id': '56d666041c850414009470f1',\n",
       "     'question': 'Che cosa ha causato le lunghe linee nella maggior parte delle grandi città?'},\n",
       "    {'answers': [{'answer_start': 118, 'text': 'cabine'}],\n",
       "     'id': '56d666041c850414009470f2',\n",
       "     'question': 'Quali sono state le premesse cinesi per raccogliere donazioni?'},\n",
       "    {'answers': [{'answer_start': 524, 'text': '772 milioni di dollari'}],\n",
       "     'id': '56d666041c850414009470f4',\n",
       "     'question': 'Quanto aveva designato il governo cinese entro il 16 maggio?'}]},\n",
       "  {'context': 'La Società Croce Rossa della Cina ha volato 557 tende e 2.500 trapunte del valore di 788.000 yuan (113.000 dollari USA) nella contea di Wenchuan. La Fondazione Amity ha già iniziato i lavori di soccorso nella regione e ha stanziato 143.000 USD per i soccorsi in caso di catastrofe. Il ministero degli Affari civili del Sichuan ha dichiarato di aver fornito 30.000 tende per i senzatetto rimasti senza tetto.',\n",
       "   'qas': [{'answers': [{'answer_start': 44, 'text': '557'}],\n",
       "     'id': '56cece5caab44d1400b88a9b',\n",
       "     'question': 'Quante tende sono state volate nella regione?'},\n",
       "    {'answers': [{'answer_start': 56, 'text': '2.500'}],\n",
       "     'id': '56cece5caab44d1400b88a9c',\n",
       "     'question': 'Quanti trapunte sono state volate nella regione?'},\n",
       "    {'answers': [{'answer_start': 85, 'text': '788.000 yuan'}],\n",
       "     'id': '56cece5caab44d1400b88a9d',\n",
       "     'question': 'Quanto valevano entrambe le forniture?'},\n",
       "    {'answers': [{'answer_start': 357, 'text': '30.000'}],\n",
       "     'id': '56cece5caab44d1400b88a9f',\n",
       "     'question': 'Quante tende ha fornito il ministero del Sichuan ai senzatetto?'},\n",
       "    {'answers': [{'answer_start': 357, 'text': '30.000'}],\n",
       "     'id': '56d663b11c850414009470e5',\n",
       "     'question': 'Quante tende ha fornito il Ministero degli Affari del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 146, 'text': 'La Fondazione Amity'}],\n",
       "     'id': '56d663b11c850414009470e7',\n",
       "     'question': 'Quali fondamenta avevano già iniziato i lavori di soccorso nella zona?'}]},\n",
       "  {'context': 'Il governo centrale stima che oltre 7.000 aule scolastiche non adeguatamente attrezzate siano crollate in seguito al terremoto. Da allora i cittadini cinesi hanno inventato una frase di cattura:\"tofu-dregs schoolhouses\" (Cinese:?????), per fingere sia la qualità che la quantità di queste costruzioni inferiori che hanno ucciso così tanti bambini in età scolare. A causa della politica del figlio unico, molte famiglie hanno perso l\\' unico figlio quando le scuole della regione sono crollate durante il terremoto. Di conseguenza, i funzionari provinciali e locali del Sichuan hanno abolito la restrizione per le famiglie il cui unico bambino è stato ucciso o gravemente ferito in seguito al disastro. I cosiddetti \"bambini illegali\" di età inferiore ai 18 anni possono essere registrati come sostituti legali dei loro fratelli morti; se il bambino morto fosse illegale, non si applicherebbero ulteriori sanzioni pecuniarie. Il rimborso non sarebbe tuttavia offerto per le ammende già riscosse.',\n",
       "   'qas': [{'answers': [{'answer_start': 36, 'text': '7.000'}],\n",
       "     'id': '56cecf68aab44d1400b88ab7',\n",
       "     'question': 'Quante aule scolastiche sono crollate nel terremoto?'},\n",
       "    {'answers': [{'answer_start': 195, 'text': 'tofu-dregs schoolhouses'}],\n",
       "     'id': '56cecf68aab44d1400b88ab8',\n",
       "     'question': \"Quale frase d' insieme è stata inventata a seguito del crollo delle scuole?\"},\n",
       "    {'answers': [{'answer_start': 195, 'text': 'tofu-dregs schoolhouses'}],\n",
       "     'id': '56d64a821c85041400947077',\n",
       "     'question': 'Che cosa ha iniziato la cittadinanza a chiamare questo tipo di scuole?'}]},\n",
       "  {'context': 'La sera del 18 maggio, il CCTV-1 ha ospitato un programma speciale di quattro ore chiamato The Giving of Love (cinese semplificato:???; cinese tradizionale:????), ospitato da regolari del Gala di Capodanno CCTV e dall\\' ancora di copertura 24 ore su 24 Bai Yansong. Vi hanno partecipato una vasta gamma di personaggi dello spettacolo, letterari, commerciali e politici provenienti dalla Cina continentale, Hong Kong, Singapore e Taiwan. Le donazioni della serata sono ammontate a 1,5 miliardi di yuan cinese (~208 milioni di dollari USA). Tra le donazioni, la TVCC ha dato il maggior contributo aziendale a ¥50 milioni. Quasi contemporaneamente a Taiwan, un programma tematico simile era in onda ospitato dal presidente in carica Ma Ying-jeou. A giugno, l\\' attore di Hong Kong Jackie Chan, che ha donato 1,57 milioni di dollari alle vittime, ha realizzato un video musicale insieme ad altri artisti intitolato \"Promise\"; la canzone è stata composta da Andy Lau. L\\' Artistes 512 Fund Raising Campaign, una maratona di raccolta fondi della durata di 8 ore, si è tenuta il 1° giugno a Hong Kong, alla quale hanno partecipato circa 200 musicisti e celebrità della Sinosfera. A Singapore, MediaCorp Channel 8 ha ospitato un programma dal vivo?? programma di quattro ore chiamato Il dono dell\\' amore.',\n",
       "   'qas': [{'answers': [{'answer_start': 252, 'text': 'Bai Yansong'}],\n",
       "     'id': '56cecff4aab44d1400b88abe',\n",
       "     'question': 'Quanto erano grandi le donazioni del programma?'},\n",
       "    {'answers': [{'answer_start': 803, 'text': '1,57 milioni di dollari'}],\n",
       "     'id': '56cecff4aab44d1400b88abf',\n",
       "     'question': 'Quanto ha donato Jackie Chan per sostenere?'},\n",
       "    {'answers': [{'answer_start': 1273, 'text': \"Il dono dell' amore\"}],\n",
       "     'id': '56cecff4aab44d1400b88ac1',\n",
       "     'question': 'Qual era il programma che CCTV-1 ha ospitato?'},\n",
       "    {'answers': [{'answer_start': 91, 'text': 'The Giving of Love'}],\n",
       "     'id': '56d6477c1c85041400947065',\n",
       "     'question': 'Quali sono state le donazioni totali per il programma?'},\n",
       "    {'answers': [{'answer_start': 26, 'text': 'CCTV'}],\n",
       "     'id': '56d6477c1c85041400947066',\n",
       "     'question': 'Quale azienda ha dato il massimo?'},\n",
       "    {'answers': [{'answer_start': 803, 'text': '1,57 milioni'}],\n",
       "     'id': '56d6477c1c85041400947067',\n",
       "     'question': \"Quanto ha donato l' attore Jackie Chan?\"}]},\n",
       "  {'context': 'Gli sforzi di salvataggio compiuti dal governo cinese sono stati elogiati dai media occidentali, soprattutto in confronto al blocco degli aiuti stranieri da parte del Myanmar durante il ciclone Nargis, nonché ai precedenti risultati della Cina durante il terremoto di Tangshan del 1976. L\\' apertura della Cina durante la copertura mediatica del terremoto del Sichuan ha portato un professore presso l\\' Università di Pechino a dire:\"Questa è la prima volta[che] i media cinesi sono stati all\\' altezza degli standard internazionali\". Los Angeles Times ha elogiato la copertura mediatica della Cina del terremoto di essere \"democratico\".',\n",
       "   'qas': [{'answers': [{'answer_start': 138, 'text': 'aiuti stranieri'}],\n",
       "     'id': '56d61fc11c85041400946f24',\n",
       "     'question': 'Che cosa ha fatto blocco Myanmar dopo Cyclone Nargis?'},\n",
       "    {'answers': [{'answer_start': 532, 'text': 'Los Angeles Times'}],\n",
       "     'id': '56d61fc11c85041400946f26',\n",
       "     'question': 'Chi ha elogiato la copertura mediatica cinese come democratica?'}]},\n",
       "  {'context': 'A causa del terremoto di magnitudo 7,9 e delle numerose forti scosse di assestamento, molti fiumi sono stati bloccati da grandi frane, che hanno portato alla formazione di \"laghi di sisma\" dietro le ostruzioni; queste enormi quantità d\\' acqua si stavano accumulando ad un ritmo molto elevato dietro le dighe naturali di frane e si temeva che le ostruzioni sarebbero infine crollate sotto il peso della massa d\\' acqua sempre crescente, potenzialmente mettendo a repentaglio la vita di milioni di persone. Al 27 maggio 2008,34 laghi si erano formati a causa del terremoto che bloccava i detriti e arginava i fiumi, e si stimava che 28 di essi fossero ancora potenzialmente pericolosi per la popolazione locale. Gli interi villaggi hanno dovuto essere evacuati a causa delle conseguenti inondazioni.',\n",
       "   'qas': [{'answers': [{'answer_start': 522, 'text': '34'}],\n",
       "     'id': '56cedd7daab44d1400b88b50',\n",
       "     'question': 'Quanti laghi di tremito si sono formati?'},\n",
       "    {'answers': [{'answer_start': 630, 'text': '28'}],\n",
       "     'id': '56cedd7daab44d1400b88b51',\n",
       "     'question': 'Quanti laghi costituivano un pericolo per le persone?'},\n",
       "    {'answers': [{'answer_start': 121, 'text': 'grandi frane'}],\n",
       "     'id': '56d624261c85041400946f2d',\n",
       "     'question': 'Che cosa ha bloccato molti dei fiumi della zona?'},\n",
       "    {'answers': [{'answer_start': 522, 'text': '34'}],\n",
       "     'id': '56d624261c85041400946f2f',\n",
       "     'question': 'A partire dal 27 maggio quanti laghi sismici si erano formati dietro i detriti di frane?'},\n",
       "    {'answers': [{'answer_start': 713, 'text': 'interi villaggi'}],\n",
       "     'id': '56d624261c85041400946f30',\n",
       "     'question': 'Che cosa doveva essere evacuato a causa di un potenziale allagamento?'}]},\n",
       "  {'context': \"Il più precario di questi ciarlatani era quello che si trovava nel terreno estremamente difficile del Monte Tangjia nella contea di Beichuan, Sichuan, accessibile solo a piedi o in aereo; un elicottero di sollevamento pesante Mi-26T appartenente alla China Flying Dragon Special Aviation Company è stato utilizzato per portare pesanti trattori movimento terra nella zona colpita. Questa operazione è stata accoppiata con il lavoro svolto da elicotteri PLAAF Mi-17 portando in corpi di ingegneria PLA, specialisti di esplosivi e altro personale per unire 1.200 soldati che sono arrivati sul posto a piedi. Cinque tonnellate di combustibile per azionare il macchinario sono state trasportate in aria fino al sito, dove è stata costruita una saracinesca per consentire lo scarico sicuro dell' acqua di strozzatura. A valle, più di 200.000 persone sono state evacuate dal Mianyang entro il 1 giugno in previsione dello scoppio della diga.\",\n",
       "   'qas': [{'answers': [{'answer_start': 102,\n",
       "       'text': 'Monte Tangjia nella contea di Beichuan, Sichuan'}],\n",
       "     'id': '56ceddf6aab44d1400b88b67',\n",
       "     'question': 'Dove si trovava il lago più precario?'},\n",
       "    {'answers': [{'answer_start': 335, 'text': 'trattori'}],\n",
       "     'id': '56ceddf6aab44d1400b88b69',\n",
       "     'question': 'Quali macchine sono state trasportate in aereo?'},\n",
       "    {'answers': [{'answer_start': 828, 'text': '200.000'}],\n",
       "     'id': '56ceddf6aab44d1400b88b6b',\n",
       "     'question': 'Quante persone sono state evacuate a valle?'},\n",
       "    {'answers': [{'answer_start': 912, 'text': 'lo scoppio della diga'}],\n",
       "     'id': '56d62b0f1c85041400946f5e',\n",
       "     'question': \"Qual è stata la paura che ha causato l' evacuazione di 200.000 persone dal Mianyang?\"},\n",
       "    {'answers': [{'answer_start': 102, 'text': 'Monte Tangjia'}],\n",
       "     'id': '56d62b0f1c85041400946f5f',\n",
       "     'question': 'Dove si trovava il peggio dei laghi sismici?'},\n",
       "    {'answers': [{'answer_start': 122, 'text': 'contea di Beichuan, Sichuan'}],\n",
       "     'id': '56d62b0f1c85041400946f60',\n",
       "     'question': 'Dove si trova il monte Tangjia?'},\n",
       "    {'answers': [{'answer_start': 554, 'text': '1.200'}],\n",
       "     'id': '56d62b0f1c85041400946f62',\n",
       "     'question': 'Quanti soldati hanno dovuto recarsi nella zona a piedi?'}]},\n",
       "  {'context': 'Il Consiglio di Stato ha dichiarato un periodo di tre giorni di lutto nazionale per le vittime del terremoto a partire dal 19 maggio 2008, la bandiera nazionale della RPC e le bandiere regionali di Hong Kong e Macao regioni amministrative speciali ha volato a metà albero. Era la prima volta che un periodo di lutto nazionale era stato dichiarato per qualcosa di diverso dalla morte di un leader statale, e molti lo hanno definito la più grande manifestazione di lutto dalla morte di Mao Zedong. Alle 14:28 CST 28 il 19 maggio 2008, una settimana dopo il terremoto, il pubblico cinese ha tenuto un momento di silenzio. La gente taceva per tre minuti mentre la difesa aerea, la polizia e le sirene antincendio, e le corna di veicoli, navi e treni suonavano. Anche le auto e i camion sulle strade di Pechino si sono fermati. La gente spontaneamente scoppiò in allegria \"Zhongguo jiayou\"! (Vai, Cina!) e \"Sichuan jiayou\" (Let\\'s go, Sichuan!).',\n",
       "   'qas': [{'answers': [{'answer_start': 547, 'text': 'dopo'}],\n",
       "     'id': '56cede78aab44d1400b88b7c',\n",
       "     'question': 'Chi ha dichiarato il lutto?'},\n",
       "    {'answers': [{'answer_start': 64, 'text': 'lutto nazionale'}],\n",
       "     'id': '56d62ce51c85041400946f7a',\n",
       "     'question': 'Che cosa ha dichiarato il Consiglio di Stato?'},\n",
       "    {'answers': [{'answer_start': 484, 'text': 'Mao Zedong'}],\n",
       "     'id': '56d62ce51c85041400946f7b',\n",
       "     'question': 'Questa è stata la più grande manifestazione di lutto dalla morte di chi?'},\n",
       "    {'answers': [{'answer_start': 123, 'text': '19 maggio 2008'}],\n",
       "     'id': '56d62ce51c85041400946f7c',\n",
       "     'question': 'Quando i cinesi hanno avuto un momento di silenzio?'},\n",
       "    {'answers': [{'answer_start': 39, 'text': 'periodo di tre giorni'}],\n",
       "     'id': '56d62ce51c85041400946f7e',\n",
       "     'question': 'Quanto tempo è durato il lutto nazionale per le vittime del terremoto?'}]},\n",
       "  {'context': \"Il Comitato Organizzatore di Ningbo del comitato organizzatore della torcia olimpica di Pechino ha annunciato che la staffetta, prevista per svolgersi a Ningbo durante la mattinata nazionale, sarebbe stata sospesa per la durata del periodo di lutto. Il percorso della torcia attraverso il paese è stato ridimensionato, e c' è stato un minuto di silenzio quando la tappa successiva ha iniziato nella città di Ruijin, Jiangxi il mercoledì dopo il terremoto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 29, 'text': 'Ningbo'}],\n",
       "     'id': '56cedecdaab44d1400b88b8e',\n",
       "     'question': \"Dov' era previsto il relè?\"},\n",
       "    {'answers': [{'answer_start': 151, 'text': 'a Ningbo'}],\n",
       "     'id': '56d62e501c85041400946f95',\n",
       "     'question': 'Dove doveva avvenire il relè della torcia?'},\n",
       "    {'answers': [{'answer_start': 250, 'text': 'Il percorso'}],\n",
       "     'id': '56d62e501c85041400946f96',\n",
       "     'question': 'Quale parte del relè ha cambiato?'},\n",
       "    {'answers': [{'answer_start': 408, 'text': 'Ruijin, Jiangxi'}],\n",
       "     'id': '56d62e501c85041400946f97',\n",
       "     'question': \"Dove c' era un minuto di silenzio durante la staffetta?\"}]},\n",
       "  {'context': 'Molti siti web hanno convertito la loro home page in bianco e nero; Sina. com e Sohu, i principali portali internet, hanno limitato le loro homepage alle notizie e rimosso tutte le pubblicità. I siti web cinesi di condivisione video Youku e Tudou hanno mostrato uno sfondo nero e collocato più video che mostrano filmati di terremoto e reportage di notizie. La versione cinese di MSN, cn. msn. com, mostrava anche annunci pubblicitari sul terremoto e gli sforzi di soccorso.',\n",
       "   'qas': []},\n",
       "  {'context': \"Ye Zhiping, il preside della scuola media di Sangzao a Sangzao, una delle più grandi della Contea di An, ha ricevuto il merito di un' azione proattiva che ha risparmiato la vita a tutti i 2.323 alunni presenti quando si è verificato il terremoto. Nel corso di un triennio che si è concluso nel 2007, ha seguito un' importante revisione della sua scuola. Durante quel periodo ha ottenuto più di 400.000 yuan (US$60.000) dal dipartimento di istruzione contea, denaro usato per ampliare e rafforzare i pilastri di cemento e la ringhiera balcone di tutti e quattro i piani della sua scuola, così come fissare i pavimenti in cemento.\",\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Ye Zhiping'}],\n",
       "     'id': '56cee003aab44d1400b88bb1',\n",
       "     'question': 'Chi era il preside della scuola media di Sangzao?'},\n",
       "    {'answers': [{'answer_start': 188, 'text': '2.323'}],\n",
       "     'id': '56cee003aab44d1400b88bb3',\n",
       "     'question': 'Quanti studenti hanno frequentato la scuola?'},\n",
       "    {'answers': [{'answer_start': 394, 'text': '400.000 yuan'}],\n",
       "     'id': '56cee003aab44d1400b88bb5',\n",
       "     'question': 'Quanto denaro è stato utilizzato per rafforzare la costruzione della scuola?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Ye Zhiping'}],\n",
       "     'id': '56d64f7c1c85041400947095',\n",
       "     'question': 'Quale direttore scolastico ha rafforzato la sua scuola?'},\n",
       "    {'answers': [{'answer_start': 45, 'text': 'Sangzao'}],\n",
       "     'id': '56d64f7c1c85041400947097',\n",
       "     'question': \"Dov' è la scuola media di Sangzao?\"}]},\n",
       "  {'context': \"Tuttavia, Reuters ha riferito nel mese di giugno che, ad oggi, i pubblici ministeri cinesi hanno aderito a un' indagine ufficiale in dieci scuole crollato durante il devastante terremoto di maggio per ottenere materiale di prima mano della qualità delle costruzioni nelle scuole crollato, avviare indagini preliminari e prepararsi per eventuali indagini sulla criminalità professionale. È stato inoltre riferito che, dopo il terremoto del mese scorso, si sarebbero dovuti effettuare controlli di sicurezza nelle scuole di tutta la Cina.\",\n",
       "   'qas': [{'answers': [{'answer_start': 483,\n",
       "       'text': 'controlli di sicurezza'}],\n",
       "     'id': '56cee069aab44d1400b88bbd',\n",
       "     'question': 'Cosa doveva essere fatto nelle scuole dopo il sisma?'},\n",
       "    {'answers': [{'answer_start': 360, 'text': 'criminalità professionale'}],\n",
       "     'id': '56d658061c850414009470a8',\n",
       "     'question': 'Quali indagini stanno conducendo i pubblici ministeri?'},\n",
       "    {'answers': [{'answer_start': 512, 'text': 'scuole di tutta la Cina'}],\n",
       "     'id': '56d658061c850414009470a9',\n",
       "     'question': 'Dove saranno i cinesi ad effettuare i controlli di sicurezza?'},\n",
       "    {'answers': [{'answer_start': 10, 'text': 'Reuters'}],\n",
       "     'id': '56d658061c850414009470aa',\n",
       "     'question': 'Quale gruppo ha riferito che i pubblici ministeri cinesi sono stati coinvolti nelle indagini sui crolli della scuola?'}]},\n",
       "  {'context': 'Il New York Times ha riferito che \"funzionari di governo a Pechino e Sichuan hanno detto che stanno indagando sui crolli. Riconoscendo la debolezza dei codici edilizi nelle campagne, il 27 maggio la Commissione nazionale per lo sviluppo e la riforma ha dichiarato di aver elaborato un emendamento per migliorare gli standard di costruzione delle scuole elementari e medie nelle zone rurali. Gli esperti stanno rivedendo il progetto, ha detto la commissione. Per limitare le proteste, i funzionari hanno spinto i genitori a firmare un documento che vietava loro di organizzare proteste in cambio di denaro, ma alcuni che si rifiutavano di firmare sono stati minacciati. Gli importi dei pagamenti variavano da scuola a scuola, ma erano all\\' incirca gli stessi. Ad Hanwang, ai genitori è stato offerto un pacchetto del valore di 8.800 USD in contanti e una pensione per genitore di quasi 5.600 USD.',\n",
       "   'qas': [{'answers': [{'answer_start': 462, 'text': 'limitare le proteste'}],\n",
       "     'id': '56d65a4b1c850414009470b0',\n",
       "     'question': 'Cosa stanno cercando di fare i funzionari per protestare i genitori?'},\n",
       "    {'answers': [{'answer_start': 598, 'text': 'denaro'}],\n",
       "     'id': '56d65a4b1c850414009470b1',\n",
       "     'question': 'Quali sono i funzionari che offrono ai genitori in cambio di proteste?'}]},\n",
       "  {'context': 'Oltre ai genitori, Liu Shaokun (???), un insegnante di scuola del Sichuan, è stato arrestato il 25 giugno 2008 per \"diffondere voci e distruggere l\\' ordine sociale\" sul terremoto del Sichuan. La famiglia di Liu è stato poi detto che egli è stato indagato su sospetto del reato di istigazione alla sovversione. Liu aveva viaggiato per lo Shifang, scattato foto di edifici scolastici crollati, e metterli online. Aveva anche espresso la sua rabbia per \"gli edifici scadenti tofu-dregs\" (?????) in un\\' intervista ai media. Gli è stato ordinato di servire un anno di rieducazione attraverso il lavoro (RTL). Secondo l\\' organizzazione per i diritti umani in Cina, Liu è stato rilasciato per scontare la sua condanna RTL al di fuori del campo di lavoro.',\n",
       "   'qas': [{'answers': [{'answer_start': 19, 'text': 'Liu Shaokun'}],\n",
       "     'id': '56cee14aaab44d1400b88bcb',\n",
       "     'question': 'Chi era un insegnante di scuola del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 271,\n",
       "       'text': 'reato di istigazione alla sovversione'}],\n",
       "     'id': '56d65c671c850414009470ba',\n",
       "     'question': 'Perché è stato indagato?'},\n",
       "    {'answers': [{'answer_start': 394, 'text': 'metterli online'}],\n",
       "     'id': '56d65c671c850414009470bb',\n",
       "     'question': 'Che cosa ha fatto Liu Shankun con le foto che ha scattato delle scuole crollate?'},\n",
       "    {'answers': [{'answer_start': 492, 'text': \"in un' intervista ai media\"}],\n",
       "     'id': '56d65c671c850414009470bc',\n",
       "     'question': 'Dove ha definito gli edifici scolastici scadenti?'},\n",
       "    {'answers': [{'answer_start': 552, 'text': 'un anno di rieducazione'}],\n",
       "     'id': '56d65c671c850414009470bd',\n",
       "     'question': 'Qual era la sua punizione assegnata?'}]},\n",
       "  {'context': 'Nel gennaio 2010, il giornale inglese con sede a Hong Kong The Standard ha riferito che lo scrittore Tan Zuoren ha tentato di documentare la costruzione scadente che potrebbe aver portato a massicce vittime nelle scuole, è stato condannato in prigione apparentemente per la sua scrittura di un articolo nel 2007 a sostegno del movimento pro-democrazia nel 1989.',\n",
       "   'qas': [{'answers': [{'answer_start': 303, 'text': 'nel 2007'}],\n",
       "     'id': '56cee1e4aab44d1400b88be0',\n",
       "     'question': 'Quando è avvenuta la condanna?'},\n",
       "    {'answers': [{'answer_start': 4, 'text': 'gennaio 2010'}],\n",
       "     'id': '56cee1e4aab44d1400b88be1',\n",
       "     'question': \"Quando è stato pubblicato l' articolo sul caso?\"}]},\n",
       "  {'context': \"A causa della magnitudo del terremoto e dell' attenzione mediatica sulla Cina, le nazioni e le organizzazioni straniere hanno risposto immediatamente al disastro offrendo condoglianze e assistenza. Il 14 maggio, l' UNICEF ha riferito che la Cina ha chiesto formalmente il sostegno della comunità internazionale per rispondere ai bisogni delle famiglie colpite.\",\n",
       "   'qas': [{'answers': [{'answer_start': 234,\n",
       "       'text': 'che la Cina ha chiesto formalmente il sostegno della comunità internazionale'}],\n",
       "     'id': '56cee23caab44d1400b88be6',\n",
       "     'question': \"Che cosa ha riferito l' UNICEF?\"},\n",
       "    {'answers': [{'answer_start': 171, 'text': 'condoglianze e assistenza'}],\n",
       "     'id': '56d660e91c850414009470d3',\n",
       "     'question': 'Che cosa hanno offerto alla Cina le nazioni straniere a causa della gravità del terremoto?'},\n",
       "    {'answers': [{'answer_start': 201, 'text': '14 maggio'}],\n",
       "     'id': '56d660e91c850414009470d4',\n",
       "     'question': 'Quando ha chiesto formalmente aiuto alla comunità internazionale?'},\n",
       "    {'answers': [{'answer_start': 215, 'text': 'UNICEF'}],\n",
       "     'id': '56d660e91c850414009470d5',\n",
       "     'question': 'Quale organizzazione ha riferito che la Cina ha chiesto aiuto?'}]},\n",
       "  {'context': \"Entro il 14 maggio, il Ministero degli Affari civili ha dichiarato che 10,7 miliardi di yuan (circa 1,5 miliardi di dollari) era stato donato dal pubblico cinese. Houston Rockets centro Yao Ming, una delle icone sportive più popolari del paese, ha dato $214.000 e $71.000 alla Società Croce Rossa della Cina. L' associazione ha inoltre raccolto un totale di 26 milioni di dollari in donazioni finora raccolte. Anche altre multinazionali situate in Cina hanno annunciato ingenti donazioni.\",\n",
       "   'qas': [{'answers': [{'answer_start': 358,\n",
       "       'text': '26 milioni di dollari'}],\n",
       "     'id': '56cee294aab44d1400b88bed',\n",
       "     'question': 'Quanto ha raccolto la Croce Rossa in donazioni?'},\n",
       "    {'answers': [{'answer_start': 71, 'text': '10,7 miliardi di yuan'}],\n",
       "     'id': '56d6622d1c850414009470db',\n",
       "     'question': 'Quanto denaro era stato donato entro il 14 maggio?'},\n",
       "    {'answers': [{'answer_start': 186, 'text': 'Yao Ming'}],\n",
       "     'id': '56d6622d1c850414009470dd',\n",
       "     'question': 'Quale famoso giocatore di basket ha fatto due grandi donazioni alla crisi?'},\n",
       "    {'answers': [{'answer_start': 358, 'text': '26 milioni'}],\n",
       "     'id': '56d6622d1c850414009470de',\n",
       "     'question': 'Quanto ha raccolto la Società della Croce Rossa?'}]},\n",
       "  {'context': 'Francis Marcus della Federazione Internazionale della Croce Rossa ha elogiato lo sforzo cinese di salvataggio come \"veloce e molto efficiente\" a Pechino martedì. Ma ha aggiunto che la portata del disastro era tale che \"non possiamo aspettarci che il governo possa fare tutto e gestire ogni aspetto delle necessità\". L\\' economista ha osservato che la Cina ha reagito al disastro \"rapidamente e con un\\' insolita apertura\", contrastandola con la risposta segreta della Birmania al ciclone Nargis, che ha devastato il paese 10 giorni prima del terremoto.',\n",
       "   'qas': [{'answers': [{'answer_start': 410, 'text': 'apertura'}],\n",
       "     'id': '56d614dd1c85041400946f07',\n",
       "     'question': 'Quale atteggiamento atipico ha mostrato la Cina?'},\n",
       "    {'answers': [{'answer_start': 520, 'text': '10 giorni'}],\n",
       "     'id': '56d614dd1c85041400946f09',\n",
       "     'question': 'Quanto tempo prima del terremoto il ciclone Nargis colpì la Birmania?'},\n",
       "    {'answers': [{'answer_start': 21,\n",
       "       'text': 'Federazione Internazionale della Croce Rossa'}],\n",
       "     'id': '56d614dd1c85041400946f0a',\n",
       "     'question': 'Quale organizzazione ha rappresentato Francesco Marco?'}]},\n",
       "  {'context': 'Tutte le emittenti televisive della Cina continentale (insieme ad alcune stazioni di Hong Kong e delle comunità espatriate) hanno cancellato tutti i programmi programmati regolarmente, hanno mostrato il loro logo in scala di grigi e hanno sostituito i programmi cancellati con filmati dal vivo del CCTV-1 per più giorni dopo il terremoto. Anche i canali televisivi a pagamento (come il canale V) sono stati sospesi.',\n",
       "   'qas': [{'answers': [{'answer_start': 298, 'text': 'CCTV-1'}],\n",
       "     'id': '56d646091c8504140094705e',\n",
       "     'question': 'Qual è stata la fonte dei feed live?'}]},\n",
       "  {'context': \"Sebbene il governo cinese sia stato inizialmente elogiato per la sua risposta al terremoto (soprattutto rispetto al blocco degli aiuti da parte della giunta militare di governo del Myanmar durante il ciclone Nargis), ha poi visto un' erosione della fiducia nello scandalo della costruzione scolastica.\",\n",
       "   'qas': [{'answers': [{'answer_start': 181, 'text': 'Myanmar'}],\n",
       "     'id': '56d6488e1c8504140094706f',\n",
       "     'question': 'Quale governo ha bloccato gli aiuti dopo il ciclone Nargis?'},\n",
       "    {'answers': [{'answer_start': 263,\n",
       "       'text': 'scandalo della costruzione scolastica'}],\n",
       "     'id': '56d6488e1c85041400947070',\n",
       "     'question': \"Su quale scandalo ha perso nell' opinione pubblica il governo cinese?\"},\n",
       "    {'answers': [{'answer_start': 69, 'text': 'risposta al terremoto'}],\n",
       "     'id': '56d6488e1c85041400947071',\n",
       "     'question': 'A cosa è stato lodato per la prima volta il governo cinese?'}]},\n",
       "  {'context': \"Il 29 maggio 2008, i funzionari governativi hanno iniziato a ispezionare le rovine di migliaia di scuole crollate, alla ricerca di indizi sul perché si sono sgretolate. Migliaia di genitori in tutta la provincia hanno accusato funzionari locali e costruttori di tagliare angoli nella costruzione della scuola, citando che dopo il terremoto altri edifici vicini sono stati poco danneggiati. All' indomani del terremoto, molti governi locali hanno promesso di indagare formalmente sui crolli della scuola, ma a partire dal 17 luglio 2008 in tutto il Sichuan, i genitori di bambini perduti nelle scuole crollate si sono lamentati di non aver ancora ricevuto alcuna segnalazione. Funzionari locali li ha esortati a non protestare, ma i genitori hanno dimostrato e chiesto un' indagine. Inoltre, i censori hanno scoraggiato la pubblicazione sui media di storie di scuole costruite in modo inadeguato e vi è stato un incidente in cui la polizia ha allontanato i manifestanti.\",\n",
       "   'qas': []},\n",
       "  {'context': 'Il AP ha riferito che \"I media controllati dallo Stato ha ampiamente ignorato la questione, apparentemente sotto le istruzioni dell\\' ufficio di propaganda. Genitori e volontari che hanno interrogato le autorità sono stati detenuti e minacciati.',\n",
       "   'qas': [{'answers': [{'answer_start': 25,\n",
       "       'text': 'media controllati dallo Stato'}],\n",
       "     'id': '56d650911c8504140094709f',\n",
       "     'question': 'Chi ha ignorato la questione della scuola?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Il AP'}],\n",
       "     'id': '56d650911c850414009470a2',\n",
       "     'question': 'Quale fonte mediatica ha riferito che ciò accade?'}]},\n",
       "  {'context': 'Il 15 maggio 2008 Geoffery York del Globeandmail. com ha riferito che gli edifici di costruzione scadente sono comunemente chiamati \"edifici tofu\" perché i costruttori tagliano gli angoli sostituendo barre d\\' acciaio con fili di ferro sottili per il rinforzo del calcestruzzo, utilizzando cemento di qualità inferiore, se ce ne sono, e utilizzando meno mattoni di quanto dovrebbero.',\n",
       "   'qas': []},\n",
       "  {'context': \"Rimangono tuttavia ancora delle domande, in quanto alcuni funzionari di governo corrotti non sono ancora stati consegnati alla giustizia, mentre le numerose famiglie che hanno perso l' unico figlio, cercano ancora di ottenere un risarcimento e di rendere giustizia a quanto era accaduto. Secondo il Times, molti genitori sono stati avvertiti dal governo di non mettere in scena una protesta sotto la minaccia dell' arresto.\",\n",
       "   'qas': []}]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_it_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de0765e",
   "metadata": {},
   "source": [
    "Great, we've loaded our first local dataset! But while this worked for the training set, what we really want is to include both the `train` and `test` splits in a single `DatasetDict` object so we can apply `Dataset.map()` functions across both splits at once. To do this, we can provide a dictionary to the `data_files` argument that maps each split name to a file associated with that split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "412b02ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4ce099a266f33e7b\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/default-4ce099a266f33e7b/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f254de926991429e9a1a1d3d849ef1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 442\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 48\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\"train\": \"data/SQuAD_it-train.json\", \"test\": \"data/SQuAD_it-test.json\"}\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "squad_it_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f416e5",
   "metadata": {},
   "source": [
    "This is exactly what we wanted. Now, we can apply various preprocessing techniques to clean up the data, tokenize the reviews, and so on.\n",
    "\n",
    "> The `data_files` argument of the `load_dataset()` function is quite flexible and can be either a single file path, a list of file paths, or a dictionary that maps split names to file paths. You can also glob files that match a specified pattern according to the rules used by the Unix shell (e.g., you can glob all the JSON files in a directory as a single split by setting `data_files=\"*.json\"`). See the 🤗 Datasets [documentation](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files) for more details.\n",
    "\n",
    "The loading scripts in 🤗 Datasets actually support automatic decompression of the input files, so we could have skipped the use of `gzip` by pointing the `data_files` argument directly to the compressed files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d767344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a17967084772b575\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/default-a17967084772b575/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261b6254255141c5863e9483c140cc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\"train\": \"data/SQuAD_it-train.json.gz\", \"test\": \"data/SQuAD_it-test.json.gz\"}\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956802cb",
   "metadata": {},
   "source": [
    "This can be useful if you don't want to manually decompress many GZIP files. The automatic decompression also applies to other common formats like ZIP and TAR, so you just need to point `data_files` to the compressed files and you're good to go!\n",
    "\n",
    "Now that you know how to load local files on your laptop or desktop, let's take a look at loading remote files.\n",
    "### Loading a remote dataset\n",
    "\n",
    "If you're working as a data scientist or coder in a company, there's a good chance the datasets you want to analyze are stored on some remote server. Fortunately, loading remote files is just as simple as loading local ones! Instead of providing a path to local files, we point the `data_files` argument of `load_dataset()` to one or more URLs where the remote files are stored. For example, for the SQuAD-it dataset hosted on GitHub, we can just point `data_files` to the <i>SQuAD_it-\\*.json.gz</i> URLs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea40ad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-57dcee3ea6992346\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/default-57dcee3ea6992346/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830f19cba86e4afb9150f8e0316f6ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://github.com/crux82/squad-it/raw/master/\"\n",
    "data_files = {\n",
    "    \"train\": url + \"SQuAD_it-train.json.gz\",\n",
    "    \"test\": url + \"SQuAD_it-test.json.gz\",\n",
    "}\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d9fe9",
   "metadata": {},
   "source": [
    "This returns the same `DatasetDict` object obtained above, but saves us the step of manually downloading and decompressing the <i>SQuAD_it-\\*.json.gz</i> files. This wraps up our foray into the various ways to load datasets that aren't hosted on the Hugging Face Hub. Now that we've got a dataset to play with, let's get our hands dirty with various data-wrangling techniques!\n",
    "\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">Pick another dataset hosted on GitHub or the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) and try loading it both locally and remotely using the techniques introduced above. For bonus points, try loading a dataset that's stored in a CSV or text format (see the [documentation](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files) for more information on these formats).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08d3ad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-09 08:51:11--  https://archive.ics.uci.edu/ml/machine-learning-databases/00611/accelerometer.csv\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3731094 (3,6M) [application/x-httpd-php]\n",
      "Saving to: ‘accelerometer.csv’\n",
      "\n",
      "accelerometer.csv   100%[===================>]   3,56M  1005KB/s    in 3,6s    \n",
      "\n",
      "2022-05-09 08:51:15 (1005 KB/s) - ‘accelerometer.csv’ saved [3731094/3731094]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-529bdd5cde81af21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/matthias/.cache/huggingface/datasets/csv/default-529bdd5cde81af21/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafa346f61c14bc49f2d1275a023d1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a526c2e145404607bcfc078afc9e9743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/matthias/.cache/huggingface/datasets/csv/default-529bdd5cde81af21/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee83c776c904d5cae02526a0ac377cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerometer dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['wconfid', 'pctid', 'x', 'y', 'z'],\n",
      "        num_rows: 153000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-24f66c6afbe12d7b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/matthias/.cache/huggingface/datasets/csv/default-24f66c6afbe12d7b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6377dc208046fc84b6f286c7e082e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d8d616d1d548348df49ced31f84968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0009cede5a5f4a3f9ab2307882edce13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/matthias/.cache/huggingface/datasets/csv/default-24f66c6afbe12d7b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206a40ffc520457a8ed498fad7eeab9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['5.1', '3.5', '1.4', '0.2', 'Iris-setosa'],\n",
      "        num_rows: 149\n",
      "    })\n",
      "})\n",
      "Add some preprocessing to correct the `features` and to add the first instance (=current `features`)!\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "## load dataset locally, from csv\n",
    "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00611/accelerometer.csv\"\n",
    "!mv accelerometer.csv data\n",
    "accelerometer_dataset = load_dataset(\"csv\", data_files=\"data/accelerometer.csv\")\n",
    "print(\"Accelerometer dataset:\\n{}\".format(accelerometer_dataset))\n",
    "## load dataset remotely\n",
    "data_files = {\"train\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"}\n",
    "iris_dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "text = \"Add some preprocessing to correct the `features` and to add the first instance (=current `features`)!\"\n",
    "print(\"Iris dataset:\\n{}\\n{}\".format(iris_dataset, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e887dcf",
   "metadata": {},
   "source": [
    "## [Time to slice and dice](https://huggingface.co/course/chapter5/3?fw=pt)\n",
    "\n",
    "Most of the time, the data you work with won't be perfectly prepared for training models. In this section we'll explore the various features that 🤗 Datasets provides to clean up your datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1af2a3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/tqfSFcPMgOI\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/tqfSFcPMgOI\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3fabd2",
   "metadata": {},
   "source": [
    "### Slicing and dicing our data\n",
    "\n",
    "Similar to Pandas, 🤗 Datasets provides several functions to manipulate the contents of `Dataset` and `DatasetDict` objects. We already encountered the `Dataset.map()` method in Chapter 3, and in this section we'll explore some of the other functions at our disposal.\n",
    "\n",
    "For this example we'll use the [Drug Review Dataset](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29) that's hosted on the [UC Irvine Machine Learning Repository}(https://archive.ics.uci.edu/ml/index.php), which contains patient reviews on various drugs, along with the condition being treated and a 10-star rating of the patient's satisfaction.\n",
    "\n",
    "First we need to download and extract the data, which can be done with the `wget` and `unzip` commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63d590cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following commands need to run only once\n",
    "#!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
    "#!mv drugsCom_raw.zip data\n",
    "#!unzip data/drugsCom_raw.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5583394",
   "metadata": {},
   "source": [
    "Since TSV is just a variant of CSV that uses tabs instead of commas as the separator, we can load these files by using the csv loading script and specifying the `delimiter` argument in the `load_dataset()` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36cdb5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-936f472160ee3f45\n",
      "Reusing dataset csv (/Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7ec60f6317430599fcdbece0543a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\"train\": \"data/drugsComTrain_raw.tsv\", \"test\": \"data/drugsComTest_raw.tsv\"}\n",
    "# \\t is the tab character in Python\n",
    "drug_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab8d09f",
   "metadata": {},
   "source": [
    "A good practice when doing any sort of data analysis is to grab a small random sample to get a quick feel for the type of data you're working with. In 🤗 Datasets, we can create a random sample by chaining the `Dataset.shuffle()` and `Dataset.select()` functions together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "daa8c474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-de03cc33fccffb38.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': [87571, 178045, 80482],\n",
       " 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],\n",
       " 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],\n",
       " 'review': ['\"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!\"',\n",
       "  '\"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.\"',\n",
       "  '\"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.\"'],\n",
       " 'rating': [9.0, 3.0, 10.0],\n",
       " 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],\n",
       " 'usefulCount': [36, 13, 128]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_sample = drug_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "# Peek at the first few examples\n",
    "drug_sample[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e494060",
   "metadata": {},
   "source": [
    "Note that we've fixed the seed in `Dataset.shuffle()` for reproducibility purposes. `Dataset.select()` expects an iterable of indices, so we've passed `range(1000)` to grab the first 1,000 examples from the shuffled dataset. From this sample we can already see a few quirks in our dataset:\n",
    "- The `Unnamed: 0` column looks suspiciously like an anonymized ID for each patient.\n",
    "- The `condition` column includes a mix of uppercase and lowercase labels.\n",
    "- The `reviews` are of varying length and contain a mix of Python line separators (`\\r\\n`) as well as HTML character codes like `&\\#039;`.\n",
    "\n",
    "Let's see how we can use 🤗 Datasets to deal with each of these issues. To test the patient ID hypothesis for the `Unnamed: 0` column, we can use the `Dataset.unique()` function to verify that the number of IDs matches the number of rows in each split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "899a1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in drug_dataset.keys():\n",
    "    assert len(drug_dataset[split]) == len(drug_dataset[split].unique(\"Unnamed: 0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c161243b",
   "metadata": {},
   "source": [
    "This seems to confirm our hypothesis, so let's clean up the dataset a bit by renaming the `Unnamed: 0` column to something a bit more interpretable. We can use the `DatasetDict.rename_column()` function to rename the column across both splits in one go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ea65766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
       "        num_rows: 161297\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
       "        num_rows: 53766\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.rename_column(\n",
    "    original_column_name=\"Unnamed: 0\", new_column_name=\"patient_id\"\n",
    ")\n",
    "drug_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203098f",
   "metadata": {},
   "source": [
    "> ✏️ Try it out! <font color=\"darkgreen\">Use the `Dataset.unique()` function to find the number of unique drugs and conditions in the training and test sets.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f47be469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique drugs in the 'train' set:\t3436\n",
      "unique drugs in the 'test' set: \t2637\n",
      "unique conditions in the 'train' set:\t885\n",
      "unique conditions in the 'test' set:\t709\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "print(\"unique drugs in the 'train' set:\\t{}\".format(len(drug_dataset[\"train\"].unique(\"drugName\"))))\n",
    "print(\"unique drugs in the 'test' set: \\t{}\".format(len(drug_dataset[\"test\"].unique(\"drugName\"))))\n",
    "print(\"unique conditions in the 'train' set:\\t{}\".format(len(drug_dataset[\"train\"].unique(\"condition\"))))\n",
    "print(\"unique conditions in the 'test' set:\\t{}\".format(len(drug_dataset[\"test\"].unique(\"condition\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d2bc4f",
   "metadata": {},
   "source": [
    "Next, let's normalize all the `condition` labels using `Dataset.map()`. As we did with tokenization in [Chapter 3](https://huggingface.co/course/chapter3), we can define a simple function that can be applied across all the rows of each split in `drug_dataset`:\n",
    "\n",
    "```python\n",
    "def lowercase_condition(example):\n",
    "    return {\"condition\": example[\"condition\"].lower()}\n",
    "drug_dataset.map(lowercase_condition)\n",
    "\n",
    "AttributeError: 'NoneType' object has no attribute 'lower'\n",
    "```\n",
    "\n",
    "Oh no, we've run into a problem with our map function! From the error we can infer that some of the entries in the `condition` column are `None`, which cannot be lowercased as they're not strings. Let's drop these rows using `Dataset.filter()`, which works in a similar way to `Dataset.map()` and expects a function that receives a single example of the dataset. Instead of writing an explicit function like:\n",
    "```python\n",
    "def filter_nones(x):\n",
    "    return x[\"condition\"] is not None\n",
    "```\n",
    "and then running `drug_dataset.filter(filter_nones)`, we can do this in one line using a *lambda function*. In Python, lambda functions are small functions that you can define without explicitly naming them. They take the general form:\n",
    "```python\n",
    "lambda <arguments> : <expression>\n",
    "```\n",
    "where `lambda` is one of Python's special [keywords](https://docs.python.org/3/reference/lexical_analysis.html#keywords), `<arguments>` is a list/set of comma-separated values that define the inputs to the function, and `<expression>` represents the operations you wish to execute. For example, we can define a simple lambda function that squares a number as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0729b9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda x : x * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e11a1",
   "metadata": {},
   "source": [
    "To apply this function to an input, we need to wrap it and the input in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba80884d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x: x * x)(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395b777",
   "metadata": {},
   "source": [
    "Similarly, we can define lambda functions with multiple arguments by separating them with commas. For example, we can compute the area of a triangle as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f88841d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda base, height: 0.5 * base * height)(4, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061cf515",
   "metadata": {},
   "source": [
    "Lambda functions are handy when you want to define small, single-use functions (for more information about them, we recommend reading the excellent [Real Python tutorial](https://realpython.com/python-lambda/) by Andre Burgaud). In the 🤗 Datasets context, we can use lambda functions to define simple map and filter operations, so let's use this trick to eliminate the `None` entries in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d030f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f64f09b63c706564.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-7fea3cdfc8bb1b98.arrow\n"
     ]
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.filter(lambda x: x[\"condition\"] is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7856e8de",
   "metadata": {},
   "source": [
    "With the `None` entries removed, we can normalize our `condition` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "783d75a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-77429251a248855c.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-213c6b1d44c7f94e.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['left ventricular dysfunction', 'adhd', 'birth control']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lowercase_condition(example):\n",
    "    return {\"condition\": example[\"condition\"].lower()}\n",
    "\n",
    "drug_dataset = drug_dataset.map(lowercase_condition)\n",
    "# Check that lowercasing worked\n",
    "drug_dataset[\"train\"][\"condition\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ab578",
   "metadata": {},
   "source": [
    "It works! Now that we've cleaned up the labels, let's take a look at cleaning up the reviews themselves.\n",
    "\n",
    "### Creating new columns\n",
    "Whenever you're dealing with customer reviews, a good practice is to check the number of words in each review. A review might be just a single word like \"Great!\" or a full-blown essay with thousands of words, and depending on the use case you'll need to handle these extremes differently. To compute the number of words in each review, we'll use a rough heuristic based on splitting each text by whitespace.\n",
    "\n",
    "Let's define a simple function that counts the number of words in each review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50736974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_review_length(example):\n",
    "    return {\"review_length\": len(example[\"review\"].split())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e2027",
   "metadata": {},
   "source": [
    "Unlike our `lowercase_condition()` function, `compute_review_length()` returns a dictionary whose key does not correspond to one of the column names in the dataset. In this case, when `compute_review_length()` is passed to `Dataset.map()`, it will be applied to all the rows in the dataset to create a new `review_length` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad562c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-193c1d46a6f267ec.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-86816261ceb2b42f.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'patient_id': 206461,\n",
       " 'drugName': 'Valsartan',\n",
       " 'condition': 'left ventricular dysfunction',\n",
       " 'review': '\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"',\n",
       " 'rating': 9.0,\n",
       " 'date': 'May 20, 2012',\n",
       " 'usefulCount': 27,\n",
       " 'review_length': 17}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.map(compute_review_length)\n",
    "# Inspect the first training example\n",
    "drug_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccbe4f3",
   "metadata": {},
   "source": [
    "As expected, we can see a `review_length` column has been added to our training set. We can sort this new column with `Dataset.sort()` to see what the extreme values look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4da923d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached sorted indices for dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f8818bfccacb538c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'patient_id': [103488, 23627, 20558],\n",
       " 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],\n",
       " 'condition': ['birth control', 'muscle spasm', 'pain'],\n",
       " 'review': ['\"Excellent.\"', '\"useless\"', '\"ok\"'],\n",
       " 'rating': [10.0, 1.0, 6.0],\n",
       " 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],\n",
       " 'usefulCount': [5, 2, 10],\n",
       " 'review_length': [1, 1, 1]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset[\"train\"].sort(\"review_length\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93678486",
   "metadata": {},
   "source": [
    "As we suspected, some reviews contain just a single word, which, although it may be okay for sentiment analysis, would not be informative if we want to predict the condition.\n",
    "\n",
    "> <font color=\"darkgreen\">🙋 An alternative way to add new columns to a dataset is with the `Dataset.add_column()` function. This allows you to provide the column as a Python list or NumPy array and can be handy in situations where `Dataset.map()` is not well suited for your analysis.</font>\n",
    "\n",
    "Let's use the `Dataset.filter()` function to remove reviews that contain fewer than 30 words. Similarly to what we did with the condition column, we can filter out the very short reviews by requiring that the reviews have a length above this threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bc01c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9162fbabc86b82d2.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b480588b5a2d2126.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 138514, 'test': 46108}\n"
     ]
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.filter(lambda x: x[\"review_length\"] > 30)\n",
    "print(drug_dataset.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6c9dc",
   "metadata": {},
   "source": [
    "As you can see, this has removed around 15% of the reviews from our original training and test sets.\n",
    "\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">Use the `Dataset.sort()` function to inspect the reviews with the largest numbers of words. See the documentation to see which argument you need to use to sort the reviews by length in descending order.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b6d48aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
      "    num_rows: 138514\n",
      "})\n",
      "\n",
      "review 0\n",
      "length 1894\n",
      "\"Two and a half months ago I was prescribed Venlafaxine to help prevent chronic migraines.\n",
      "It did help the migraines (reduced them by almost half), but with it came a host of side effects that were far worse than the problem I was trying to get rid of.\n",
      "Having now come off of the stuff, I would not recommend anyone ever use Venlafaxine unless they suffer from extreme / suicidal depression. I mean extreme in the most emphatic sense of the word. \n",
      "Before trying Venlafaxine, I was a writer. While on Venlafaxine, I could barely write or speak or communicate at all. More than that, I just didn&#039;t want to. Not normal for a usually outgoing extrovert.\n",
      "Now, I&#039;m beginning to write again - but my ability to speak and converse with others has deteriorated by about 95%. Writing these words is taking forever; keeping up in conversation with even one person is impossible, and I barely see the point of trying either. On Venlafaxine, words pretty much left me - my conversational vocabulary  was whittled down to the following:\n",
      "&quot;Mmm&quot; for yes; a sharp and clipped &quot;Mm&quot; for &quot;No&quot;\n",
      "&quot;Okay.&quot;\n",
      "&quot;Really?&quot;\n",
      "&quot;Oh right.&quot;\n",
      "&quot;Cool.&quot;\n",
      "&quot;That sucks&quot;\n",
      "At the moment, I&#039;m a week into withdrawal, and I have to try extremely hard just to make the most mundane small talk. Last night I went to a party with some close friends, cheesy &#039;90s music, and a barbecue. About half of them are academics, and I couldn&#039;t keep up with conversations I normally would be able to; the other half like to dance and party, but I felt glued to my seat (as well as practically mute) and eventually walked off and found a quiet sofa to lie down on.\n",
      "I have never felt so isolated and lonely in my life. Thanks Venlafaxine.\n",
      "If you consider yourself a social, creative, and curious person, DO NOT TAKE EVEN ONE DOSE OF VENLAFAXINE. Unless of course you are extremely extremely depressed. I&#039;ve suffered from depression in the past, but only mildly. Venlafaxine has shown me what true depression feels like.\n",
      "As for the other side effects:\n",
      "- About two days&#039; worth of total joyful euphoria during the first 48 hours of taking Venlafaxine. Anxiety of all kinds evaporated. This felt amazing - although I can&#039;t remember what it felt like now. At the time, this extremely brief effect was powerful enough to make me feel that pushing on with Venlafaxine would be a Good Idea.\n",
      "- After that, I started feeling very sleepy. All the time. I slept more. No euphoria; more anxiety.\n",
      "- A week later, the night sweats started. My room was pretty cold (it was only spring in the UK), but I sweated more than I ever have on any tropical holiday. This meant that despite being extremely sleepy, I couldn&#039;t sleep.\n",
      "Since the side effects were supposed to wear off after six weeks or so, I stuck with Venlafaxine for six weeks. Over that time I became so sleep deprived that I lived in a state of permanent exhaustion.\n",
      "Enter the writer&#039;s worst enemy: Brain fog. I spent entire days so braindead that the most challenging thing I could manage was staring blankly at a wall - or lifting my phone to read text messages and attempt to learn something from articles about Venlafaxine. I&#039;ve read the same articles countless times, but nothing sank in; every time I read the same article it felt like I was reading it for the first time. I recognised the layout and design of each webpage, and that way I was able to realise I&#039;d read it before, but the actual text went in one eye and out the other.\n",
      "In conversation, I had a brain like a sieve. Words went in one ear and out the other. Normally, I could pump out a lot of writing on a regular basis; on Venlafaxine, I wrote a small and frankly pitiful handful of short and uninspired pieces, and that was it. If you love being productive and creative, do not go near Venlafaxine.\n",
      "The above was my life for six weeks - and that was enough. I did see family and friends while on Venlafaxine, but I constantly forgot what was going on and must have seemed scatterbrained or borderline retarded at times. Although I did explain to people what was going on with my medication, it just seemed to make people uncomfortable - and I&#039;ve now become the butt of a lot of jokes relating to my consistent uselessness at everything from chatting to party games and my inability to work or do anything productive. Someone even compared me to Lenny from Of Mice And Men and asked when my family were going to take me into the back garden and shoot me in the head rather than continue to care for me. All of this contributed to the worst feeling of loneliness and isolation I have ever experienced in my life.\n",
      "Venlafaxine not only trapped me inside my head - it also emptied my head of anything worth remembering, and left me barely able to learn new things. \n",
      "I&#039;d sit around tables with people and realise I couldn&#039;t remember the names of people I&#039;d know for years - or even family members. \n",
      "I&#039;d hear a song playing and say &quot;Hey - what&#039;s the name of this dance?&quot;\n",
      "Any sentence longer than a few words requires a minute or so to compose when written. Spoken out loud? Forget about it. When I try to speak, I sound like the Goon from Popeye.\n",
      "After six weeks of hell, my doctor and I agreed to taper off my 75mg daily dose. This process lasted a month, not following a particular schedule (which might have been a better idea), and was mostly side effect free until I came down to 18.25mg a day - one half of one 37.5mg tablet.\n",
      "After three days of that, it really hit the fan. I got up one day, pottered around a bit, and suddenly decided that I wanted to kill myself. Literally out of nowhere.\n",
      "Fortunately I was of sound enough mind to call the Samaritans, who recommended I call the emergency services, who sent an ambulance to take me to hospital. For suicidal thoughts. \n",
      "To be honest, I&#039;d rather have gone to Disneyland.\n",
      "Once I was in A&amp;E, I got to wait for several hours, just stewing in a room with a sofa and not much else. Then I met the most useless doctor of all time. After I refused his suggestion that I not only go back on Venlafaxine, but *try a higher dose* than the one that got me into this mess in the first place, he said there wasn&#039;t anything else they could do - and handed me a little leaflet for a local mental health charity meetup that happens every so often.\n",
      "By this point I&#039;d decided that suicide would not be the best option - and nor would going on even more Venlafaxine than before. I also binned the leaflet on my way out, determined to keep going and just deal with the withdrawal.\n",
      "Since that time, my intelligence level has plummeted to the point of being humiliating. But that&#039;s not even the worst of it.\n",
      "As I mentioned before, I started taking Venlafaxine for migraines. Now that I&#039;m not taking it, they&#039;re coming back again - but they&#039;ve also changed.\n",
      "A few days ago, days before the party I should probably have stayed home for only I couldn&#039;t stand sitting at home any longer so I went and ended up alone in a darkened room and felt more depressed than I have in my entire life, I was at home when I collapsed. The right side of my body gave way, I hit the wall, and fell on the floor where I lay frozen for God knows how long. Then when I did get up, I realised I couldn&#039;t speak at all, the right side of my body was almost paralysed, and the right side of my head was numb on the outside, and in agony on the inside.\n",
      "After calling the emergency services again, I was taken through the standard questions I guess they ask everyone when they think the person in question is having a stroke. Like the suicidal thoughts, stroke symptoms were a new experience for me. Thanks, Venlafaxine.\n",
      "When the ambulance arrived, they were able to reassure me that I wasn&#039;t having a stroke, as one side of my face wasn&#039;t drooping. This was good news - but since they couldn&#039;t explain what was actually going on, I was taking to hospital for a brain scan and blood tests and a meeting with a doctor who told me I&#039;d had a right-sided hemiplegic migraine. I&#039;d never had one before, and didn&#039;t know they existed until then; my migraines have always felt like my head is both in a vice and exploding at the same time, and I get them across my whole head, not just one side.\n",
      "At this point, I&#039;m determined to continue fighting the withdrawal symptoms. The only thing that&#039;s really helped me in doing this was the discovery of a cognitive distortion called &quot;emotional reasoning&quot;. This involves assuming that because you feel bad, things must actually be bad.\n",
      "Obviously emotional reasoning (which is worth Googling as it&#039;s quite an in depth subject, or at least feels like it given that my brain&#039;s been hopefully temporarily damaged by Venlafaxine) is pretty common in depression. It&#039;s also been my brain&#039;s default way of operating possibly for as long as I can remember, but definitely since I started taking Venlafaxine. The emotional and physical and psychological rollercoaster Venlafaxine puts you through is utterly exhausting - and while it&#039;s throwing you all over the place and especially during withdrawal it&#039;s tough to keep in mind that a lot of the negative thoughts your mind throws up are going to be based on how you feel (i.e. the levels and mix of different chemicals in your brain), NOT on any Real Life Stuff. You&#039;ll most likely unintentionally filter out all the good stuff in your brain and only remember the darkest and worst things you possibly can, and attach all kinds of apparently logical arguments to make a case against yourself / a case that argues that you and your life are awful.\n",
      "Looking back on this experience, my thoughts were similar to one of those films you see advertised as &quot;...based on a true story&quot;. Works of fiction based very loosely on facts.\n",
      "Rather than a film you&#039;d give two stars and never watch again, emotional reasoning&#039;s end product is a lie - not to mention the most toxic thoughts a human being can think. Depression can definitely make people tell these lies to themselves - but Venlafaxine made my brain malfunction so badly that putting together an apparently sensible argument for any depressive thoughts suddenly seemed like the most obvious thing in the world one day.\n",
      "If I hadn&#039;t had those thoughts, I would&#039;ve just made lunch.\n",
      "So that&#039;s about it for now - if I don&#039;t update this story in the future, assume I got better and decided to never revisit this page again, preferring to leave Venlafaxine and its horrific toxicity behind me. Good luck with your own journey :)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "review 1\n",
      "length 1162\n",
      "\"I don&rsquo;t find a lot of positive stories about antidepressants, or I find stories where people are taking the antidepressant the wrong way.\n",
      "\n",
      "I wanted to share my experience.  A positive one.\n",
      "\n",
      "I&rsquo;ve had generalized anxiety disorder, SEVERE OCD, and panic disorder for as long as I can remember.  My first memory of having an episode was when I was 4 years old at my kindergarten interview.  I feel as though I was born with the illnesses mentioned above, right from the womb.  When I was a child I was extremely anxious, had bad separation anxiety from my parents and had extreme OCD, I was just a kid and thought that the way I was feeling is how all kids felt, I didn&rsquo;t realize that I was different.  This went on, and got even worse in middle school.  I began developing trichtilomania in middle school.  In high school I went from being a 90% above student, to failing every class within a couple of years.  I couldn&rsquo;t leave the house.  My panic disorder and gad caused debilitating physical symptoms.  I would be shaking when I had to leave the house, I wouldn&rsquo;t drink alcohol because I was afraid of vomiting, I was suffering so much, for my whole entire life with severe phobias, fears, and anxiety.  I prayed and prayed and prayed to God every night for it to go away.  I was a 16 year old living in a prison of her own mind.  It never went away.  Every single day was the worst day of my life, I would wake up and the thoughts just started,  I never had a break.  My life was exhausting.\n",
      "\n",
      "I am of east indian background and my parents didn&rsquo;t understand mental illness well.  It is very taboo in my culture.  I went to tons of doctors and they told me it was just growing pains,  no doctor ever told me that maybe I should see a therapist.  I didn&rsquo;t have any support.  When I was 22 I attempted suicide.  Luckily the attempt didn&rsquo;t work and I was forced to go on medication.  I was livid, I was so against antidepressants, I was so so so scared, it felt unnatural. My general practitioner put me on Effexor, I took it for almost 8 weeks, it helped me to not want to kill myself, but It also made me gain tons of weight which made me depressed, and it make me hear voices.  One evening a voice told me to choke my mom, and I started freaking out and my parents drove me immediately to the hospital.  At the hospital I talked to a psych nurse who calmed me down, and got me an appointment with a psychiatrist the next day.  This appointment and this psychiatrist saved my life, and changed my entire life.\n",
      "\n",
      "I want to really mention that you should not be going to a General Practitioner for mental illness medication, you should ALWAYS&hellip;ALWAYS go to a psychiatrist no matter what.  If your GP is the only person you are seeing to help you manage your meds for ocd, anxiety, etc, that is the WRONG MOVE.  That is such a common mistake people are making, you NEED a psychiatrist in order to get the meds right, please do not just go to your regular doctor, you&rsquo;ll be cheating yourself.\n",
      "\n",
      "I went to the psychiatrist appointment the next day.  It was the first time I had ever seen a psychiatrist.   I got into her room and we talked about everything, my childhood, my phobias, my ocd.  She then brought my parents into the room to explain the whole situation to them and the fact that I have a chemical imbalance in my brain and that I have been suffering for way too long.  My parents were so supportive.  The doctor told me I was on the wrong medication, that I never should have been placed on Effexor which is an SNRI, and that I should be on an SSRI considering my main problem is OCD and GAD.  We talked a lot about it and she told me she would like to place me on Prozac.  She said for me, because my neural pathways have been the same for 20 plus years, that I would need a higher dosage of Prozac especially for anxiety and OCD.   I see on this forum, that so many people are on 20mg, or 40mg for anxiety disorders.   You should be on 60mg at least, do not be afraid to go higher.  People that say Prozac or an SSRI didn&rsquo;t really do anything for their anxiety or ocd is because they are only taking a 20mg dose,  That is not an OCD dose.  40-80mg for anxiety and OCD.   Please up your dose.   Use the medication, REALLY USE IT.  Do not be afraid!\n",
      "\n",
      "My doctor started me on 40mg, eventually took me to 100mg, and then I went back to 80mg.  Yes the side effects are insane, I was nauseated, I couldn&rsquo;t sleep, I was shaking, I had anxiety, but she prescribed me Ativan and said to use it until the Prozac kicked in.  That the Ativan would keep me comfortable until that happened.  Don&rsquo;t try to be a hero, use your Ativan or your Xanax or whatever to stay as comfortable as possible.\n",
      "\n",
      "I could write so much more, but I&rsquo;ll conclude with this.  4 months after being on 80mg of Prozac everyday, I woke up one day and I was cured.   Yes cured.  I had no OCD, I had no anxiety, I no longer had fears or phobias.   I was cured.   You have no idea how that day felt.  It was like the first day of my whole entire life.  I woke up being the real me, who is free spirited and isn&rsquo;t afraid of anything!  I was finally free, I was no longer a prisoner.  I didn&rsquo;t even have to go to therapy.  I just woke up one day a brand new person, from taking a high dose of Prozac every single day.\n",
      "\n",
      "DO NOT go off of the antidepressants.   Your ocd, your anxiety, depression etc will come back.  I WOULD never dream or even think to come off of my antidepressants,  I have an illness, that will return if I go off the medication, because I have a brain disorder.  OCD is a brain disorder.  Do not stop taking medication for your brain disorder, do not try to fix your brain disorder with just a 20mg or 40mg dose.  Own your medication, be on it for life.\n",
      "\n",
      "It&rsquo;s been 5 years since I have been cured.  If it wasn&rsquo;t for Prozac, I would be dead.\n",
      "\n",
      "1)\tYou need a psychiatrist\n",
      "2)\tDo not be afraid to take more than 40mg of Prozac to treat panic attacks etc,  I am on 80mg a day and my life is a ball.  It is so wonderful and so carefree.\n",
      "3)\tDo not stop the meds.  Be on the meds for life.\"\n",
      "\n",
      "review 2\n",
      "length 1107\n",
      "\"My Complicated experience with the insertion of the copper IUD. It was &quot;one of the most difficult &amp; Complicated IUD insertions I&#039;ve had in a very long time&quot; quoting the words of my Gynecologist MD. Now I have not been sexually active for over a year and a half (by choice) &amp; I&#039;ve never had kids so that for one was a concern for my doctor since she said i might be very tight &amp; feel pain. Anywhom I am 23 and recently decided to date again &amp; wanted to have a convinient birth control that won&#039;t affect my weight or cause acne since acne has recently been a new battle for me, so my first step was hitting the Internet for options. After reading many reviews for multiple birth controls I decided on the copper para guard which is for 10-12 years. Now I went to my doctor and had a screening for STDs &amp; HIV which is protocol to any birth control procedure. Then pregnancy tests were taken a few days before the insertion and the day of the insertion, after everything came out negative I was ready for my IUD. I was schedule to go in on Tuesday September 1, 2015 so I went in with anticipation of pain and I was very nervous. Mostly because it was something new for me to have a speculum inside me since I just had my first Pap smear ,ever, two weeks prior to the IUD insertion. As my doctor placed the speculum I had some discomfort, she had trouble finding my cervix, after some time she had everything positioned right and began to try and dilate my cervix, right when she started I began to feel extreme cramping. My doctor could not get her tool that she used to dilate my cervix to stay in, I was too tight due to the fact that I&#039;ve never had kids so it wasn&#039;t easy, my cervix kept pushing the prob out. She attempted a few more times until I couldn&#039;t take the pain anymore because the cramping became so severe I began to cry. Now I know i sound ridiculous crying but I have a pretty high tolerance for pain &amp; I never understood how many woman couldn&#039;t take the cramping they had when on their period because I don&#039;t experience cramping on my periods, at least until now. I now have so much more sympathy for those who do have this pain every month. My doctor gave me other birth control options because she wasn&#039;t successful in Inserting the IUD but she knew I didn&#039;t want others so she offered to use an anesthetic on my cervix to help with the insertion (which is not normally a part of the procedure but since I had a special case she offered this option to me). I was not happy with the fact that I had to have a needle inserted in my cervix but this was the birth control I wanted and I was going to do whatever to get it. I was in too much pain that day so I had to come back the next morning. So here I go Wednesday morning into my doctors office, laying down ready to get a needle inserted into my cervix which terrified me because I already knew how painful it was but I didn&#039;t feel a thing when she put the anesthetic, I was told I would feel a slight sting and some burning sensation but I didn&#039;t feel anything. It took her about 15 min to position the IUD correctly, she had to dilate me 8cm to get a good view and make sure I had a successful insertion. I felt NOTHING &amp; then she was done. Right after she had me lay down for a few minutes then had me slowly sit up, I felt like I was going to faint, The MD said my eyes were not focusing on her and I was so pale. At that point my whole face and hands where numb. She stayed there with me until I regained full blood flow to my upper body. FYI my doctor said some woman actually faint after the procedure &amp; in some rare cases they even have seizure because the pain of dilating the cervix is so intense. I was lucky of not having any cramps because my cervix was numb. 8 hrs later the numbness began to fade &amp; the pain started, I got prescribed 600 Tylenol which helped a little. I spotted the next 3 days, I had to use pantie liners. Then my period came 1 week early just 4 days after I got my IUD placed, it was very heavy the first 3 days with medium cramping and my period lasted 5 1/2 days. My usual periods post the IUD was 4 days with only 1 heavy day. I have now had my IUD going on 3 weeks and I have little spotting every day so I use liners all the time. Now the part that I was most nervous about was the whole &quot;me checking if I can feel the IUD strings&quot; Its something I&#039;m a bit uncomfortable doing mostly because I&#039;ve never done it before so the first couple of times I tried to check for the strings I couldn&#039;t feel anything so I began to freak out and rushed to my doctors office after my unsuccessful attempts. She said to wait until my first period was over and then to try again. I tried again after my period and I still couldn&#039;t feel anything then I found a way to check that best fits me since I have small hands so I&#039;ll share my wisdom with you guys lol. I check in the shower every morning I lift one leg as if I&#039;m going to shave then I insert my pointer and I squat a little which helps and I&#039;m able to feel the tip of the strings. I have not had any cramping since my period and my discharge has reduced. I&#039;m very happy with my IUD &amp; I plan on using it safely and responsibly as I have heard many woman have got pregnant with the IUD. I still plan on using condoms because of STDs and I got the IUD as a backup just in case. I plan on keeping it for the full 10 year unless there are any complications. Sorry for the long story but I for one would have loved to hear the entire experience someone had so I decided to share mine. Hope it helps at least one person :)\"\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "drug_dataset_sorted_by_review_length = drug_dataset[\"train\"].sort(\"review_length\", reverse=True)\n",
    "print(drug_dataset_sorted_by_review_length)\n",
    "for i in range(3):\n",
    "    review = drug_dataset_sorted_by_review_length[\"review\"][i]\n",
    "    review_length = drug_dataset_sorted_by_review_length[\"review_length\"][i]\n",
    "    print(\"\\nreview {}\\nlength {}\\n{}\".format(i, review_length, review))\n",
    "# documentation: https://huggingface.co/docs/datasets/v2.0.0/en/package_reference/main_classes#datasets.Dataset.sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762956b",
   "metadata": {},
   "source": [
    "The last thing we need to deal with is the presence of HTML character codes in our reviews. We can use Python's `html`\n",
    " module to unescape these characters, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f46d0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm a transformer called BERT\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "text = \"I&#039;m a transformer called BERT\"\n",
    "html.unescape(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff9683",
   "metadata": {},
   "source": [
    "We'll use `Dataset.map()` to unescape all the HTML characters in our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78487ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-61eca8a742e40f3e.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-935d9d6f9521c0b6.arrow\n"
     ]
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.map(lambda x: {\"review\": html.unescape(x[\"review\"])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89efe167",
   "metadata": {},
   "source": [
    "As you can see, the `Dataset.map()` method is quite useful for processing data — and we haven't even scratched the surface of everything it can do!\n",
    "\n",
    "### The `map()` method's superpowers\n",
    "\n",
    "The `Dataset.map()` method takes a batched argument that, if set to `True`, causes it to send a batch of examples to the map function at once (the batch size is configurable but defaults to 1,000). For instance, the previous map function that unescaped all the HTML took a bit of time to run (you can read the time taken from the progress bars). We can speed this up by processing several elements at the same time using a list comprehension.\n",
    "\n",
    "When you specify `batched=True` the function receives a dictionary with the fields of the dataset, but each value is now a *list of values*, and not just a single value. The return value of `Dataset.map()` should be the same: a dictionary with the fields we want to update or add to our dataset, and a list of values. For example, here is another way to unescape all HTML characters, but using `batched=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fee16fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-a0cbbd2ffb7355cd.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-32491582872fd4f2.arrow\n"
     ]
    }
   ],
   "source": [
    "new_drug_dataset = drug_dataset.map(lambda x: {\"review\": [html.unescape(o) for o in x[\"review\"]]}, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45f358",
   "metadata": {},
   "source": [
    "If you're running this code in a notebook, you'll see that this command executes way faster than the previous one. And it's not because our reviews have already been HTML-unescaped — if you re-execute the instruction from the previous section (without `batched=True`), it will take the same amount of time as before. This is because list comprehensions are usually faster than executing the same code in a `for` loop, and we also gain some performance by accessing lots of elements at the same time instead of one by one.\n",
    "\n",
    "Using `Dataset.map()` with `batched=True` will be essential to unlock the speed of the \"fast\" tokenizers that we'll encounter in [Chapter 6](https://huggingface.co/course/chapter6), which can quickly tokenize big lists of texts. For instance, to tokenize all the drug reviews with a fast tokenizer, we could use a function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db910cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"review\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec23138",
   "metadata": {},
   "source": [
    "As you saw in [Chapter 3](https://huggingface.co/course/chapter3), we can pass one or several examples to the tokenizer, so we can use this function with or without `batched=True`. Let's take this opportunity to compare the performance of the different options. In a notebook, you can time a one-line instruction by adding `%time` before the line of code you wish to measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28f44f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ecb7a569a9a15e82.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9bd5e7e841461c1f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 ms, sys: 17.6 ms, total: 37.2 ms\n",
      "Wall time: 65.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa04884",
   "metadata": {},
   "source": [
    "You can also time a whole cell by putting `%%time` at the beginning of the cell. On the hardware we executed this on, it showed 10.8s for this instruction (it's the number written after \"Wall time\").\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">Execute the same instruction with and without `batched=True`, then try it with a slow tokenizer (add `use_fast=False` in the `AutoTokenizer.from_pretrained()` method) so you can see what numbers you get on your hardware.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78f1c118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ecb7a569a9a15e82.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9bd5e7e841461c1f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 ms, sys: 13.1 ms, total: 32.2 ms\n",
      "Wall time: 30.6 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463e23382a3b43348c9b038576766659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138514 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af3cc1230324f269d5e46fc89b953d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46108 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 518 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2306ab5a40e44cebdb0418e41e1d813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58381986849465d8ee9a6cf8700f292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 41s, sys: 498 ms, total: 3min 41s\n",
      "Wall time: 3min 41s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6771cd43d6c404f819b5b2fe4526d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138514 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc993eec1c4f4f1d8198efca03df44bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46108 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 3s, sys: 1.94 s, total: 4min 5s\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "## a fast tokenizer\n",
    "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)\n",
    "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=False)\n",
    "## not a fast tokenizer\n",
    "not_a_fast_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
    "def not_a_fast_tokenize_function(examples):\n",
    "    return not_a_fast_tokenizer(examples[\"review\"], truncation=True)\n",
    "%time tokenized_dataset = drug_dataset.map(not_a_fast_tokenize_function, batched=True)\n",
    "%time tokenized_dataset = drug_dataset.map(not_a_fast_tokenize_function, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec11ce",
   "metadata": {},
   "source": [
    "Here are the results we obtained with and without batching, with a fast and a slow tokenizer:\n",
    "\n",
    "|Options|Fast tokenizer|Slow tokenizer|\n",
    "|-------|--------------|--------------|\n",
    "|`batched=True`|10.8s|4min41s|\n",
    "|`batched=False`|59.2s|5min3s|\n",
    "\n",
    "This means that using a fast tokenizer with the `batched=True` option is 30 times faster than its slow counterpart with no batching — this is truly amazing! That's the main reason why fast tokenizers are the default when using `AutoTokenizer` (and why they are called \"fast\"). They're able to achieve such a speedup because behind the scenes the tokenization code is executed in Rust, which is a language that makes it easy to parallelize code execution.\n",
    "\n",
    "Parallelization is also the reason for the nearly 6x speedup the fast tokenizer achieves with batching: you can't parallelize a single tokenization operation, but when you want to tokenize lots of texts at the same time you can just split the execution across several processes, each responsible for its own texts.\n",
    "\n",
    "`Dataset.map()` also has some parallelization capabilities of its own. Since they are not backed by Rust, they won't let a slow tokenizer catch up with a fast one, but they can still be helpful (especially if you're using a tokenizer that doesn't have a fast version). To enable multiprocessing, use the `num_proc` argument and specify the number of processes to use in your call to `Dataset.map()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa51b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-436b0d1c59b8aa41.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-71c08cd5e57ebaa3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-43d5021c26bef8ba.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-55edafcd9a34f2bc.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-e224d450c4c9362c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b944340046e7161b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9bae87aa32d50eba.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-6b0330801c7f46fb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-d7b37f1960d2065a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f4d01ea38426a5a9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-4dd898bdc91be19a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-67a290b17857f9e0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-1347d520ff37f5c6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-34fd335e0e4c5e56.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-654d4aebd38208d6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-e07ce084fa2eaf19.arrow\n"
     ]
    }
   ],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
    "def slow_tokenize_function(examples):\n",
    "    return slow_tokenizer(examples[\"review\"], truncation=True)\n",
    "tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e19e2e",
   "metadata": {},
   "source": [
    "You can experiment a little with timing to determine the optimal number of processes to use; in our case 8 seemed to produce the best speed gain. Here are the numbers we got with and without multiprocessing:\n",
    "\n",
    "|Options|Fast tokenizer|Slow tokenizer|\n",
    "|-------|--------------|--------------|\n",
    "|`batched=True`|10.8s|4min41s|\n",
    "|`batched=False`|59.2s|5min3s|\n",
    "|`batched=True`, `num_proc=8`|6.52s|41.3s|\n",
    "|`batched=False`, `num_proc=8`|9.49s|45.2s|\n",
    "\n",
    "Those are much more reasonable results for the slow tokenizer, but the performance of the fast tokenizer was also substantially improved. Note, however, that won't always be the case — for values of `num_proc` other than 8, our tests showed that it was faster to use `batched=True` without that option. In general, we don't recommend using Python multiprocessing for fast tokenizers with `batched=True`.\n",
    "> <font color=\"darkgreen\">Using `num_proc` to speed up your processing is usually a great idea, as long as the function you are using is not already doing some kind of multiprocessing of its own.</font>\n",
    "\n",
    "All of this functionality condensed into a single method is already pretty amazing, but there's more! With `Dataset.map()` and `batched=True` you can change the number of elements in your dataset. This is super useful in many situations where you want to create several training features from one example, and we will need to do this as part of the preprocessing for several of the NLP tasks we'll undertake in [Chapter 7](https://huggingface.co/course/chapter7).\n",
    "> <font color=\"darkgreen\">💡 In machine learning, an *example* is usually defined as the set of *features* that we feed to the model. In some contexts, these features will be the set of columns in a `Dataset`, but in others (like here and for question answering), multiple features can be extracted from a single example and belong to a single column.</font>\n",
    "\n",
    "Let's have a look at how it works! Here we will tokenize our examples and truncate them to a maximum length of 128, but we will ask the tokenizer to return *all* the chunks of the texts instead of just the first one. This can be done with `return_overflowing_tokens=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e9d0409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_split(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"review\"],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_overflowing_tokens=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a832e0",
   "metadata": {},
   "source": [
    "Let's test this on one example before using `Dataset.map()` on the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e049f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 49]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tokenize_and_split(drug_dataset[\"train\"][0])\n",
    "[len(inp) for inp in result[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d950d2",
   "metadata": {},
   "source": [
    "So, our first example in the training set became two features because it was tokenized to more than the maximum number of tokens we specified: the first one of length 128 and the second one of length 49. Now let's do this for all elements of the dataset!\n",
    "```python\n",
    "tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)\n",
    "\n",
    "ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000\n",
    "```\n",
    "\n",
    "Oh no! That didn't work! Why not? Looking at the error message will give us a clue: there is a mismatch in the lengths of one of the columns, one being of length 1,463 and the other of length 1,000. If you've looked at the `Dataset.map()` documentation, you may recall that it's the number of samples passed to the function that we are mapping; here those 1,000 examples gave 1,463 new features, resulting in a shape error.\n",
    "\n",
    "The problem is that we're trying to mix two different datasets of different sizes: the `drug_dataset` columns will have a certain number of examples (the 1,000 in our error), but the `tokenized_dataset` we are building will have more (the 1,463 in the error message). That doesn't work for a `Dataset`, so we need to either remove the columns from the old dataset or make them the same size as they are in the new dataset. We can do the former with the `remove_columns` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f7610db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-00d65e85202c60ee.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-dd2c01358151e4b1.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = drug_dataset.map(\n",
    "    tokenize_and_split, batched=True, remove_columns=drug_dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f3aca0",
   "metadata": {},
   "source": [
    "Now this works without error. We can check that our new dataset has many more elements than the original dataset by comparing the lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cfbfe5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206772, 138514)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset[\"train\"]), len(drug_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecd6b7",
   "metadata": {},
   "source": [
    "We mentioned that we can also deal with the mismatched length problem by making the old columns the same size as the new ones. To do this, we will need the `overflow_to_sample_mapping` field the tokenizer returns when we set `return_overflowing_tokens=True`. It gives us a mapping from a new feature index to the index of the sample it originated from. Using this, we can associate each key present in our original dataset with a list of values of the right size by repeating the values of each example as many times as it generates new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "afccb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_split(examples):\n",
    "    result = tokenizer(\n",
    "        examples[\"review\"],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_overflowing_tokens=True,\n",
    "    )\n",
    "    # Extract mapping between new and old indices\n",
    "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
    "    for key, values in examples.items():\n",
    "        result[key] = [values[i] for i in sample_map]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a72cb",
   "metadata": {},
   "source": [
    "We can see it works with `Dataset.map()` without us needing to remove the old columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3180ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-4cc454344d95ff24.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-cc8dd0e4a7bcff76.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 206772\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 68876\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93496d19",
   "metadata": {},
   "source": [
    "We get the same number of training features as before, but here we've kept all the old fields. If you need them for some post-processing after applying your model, you might want to use this approach.\n",
    "\n",
    "You've now seen how 🤗 Datasets can be used to preprocess a dataset in various ways. Although the processing functions of 🤗 Datasets will cover most of your model training needs, there may be times when you'll need to switch to Pandas to access more powerful features, like `DataFrame.groupby()` or high-level APIs for visualization. Fortunately, 🤗 Datasets is designed to be interoperable with libraries such as Pandas, NumPy, PyTorch, TensorFlow, and JAX. Let's take a look at how this works.\n",
    "\n",
    "### From `Datasets` to `DataFrames` and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7534b661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthias/opt/anaconda3/envs/hf/lib/python3.8/site-packages/IPython/core/display.py:717: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/tfcY1067A5Q\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/tfcY1067A5Q\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08112ce",
   "metadata": {},
   "source": [
    "To enable the conversion between various third-party libraries, 🤗 Datasets provides a `Dataset.set_format()` function. This function only changes the *output format* of the dataset, so you can easily switch to another format without affecting the underlying *data format*, which is Apache Arrow. The formatting is done in place. To demonstrate, let's convert our dataset to Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad40ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71ea5e",
   "metadata": {},
   "source": [
    "Now when we access elements of the dataset we get a `pandas.DataFrame` instead of a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "228f63e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>10</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id    drugName      condition  \\\n",
       "0       95260  Guanfacine           adhd   \n",
       "1       92703      Lybrel  birth control   \n",
       "2      138000  Ortho Evra  birth control   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  \"My son is halfway through his fourth week of ...     8.0   \n",
       "1  \"I used to take another oral contraceptive, wh...     5.0   \n",
       "2  \"This is my first time using any form of birth...     8.0   \n",
       "\n",
       "                date  usefulCount  review_length  \n",
       "0     April 27, 2010          192            141  \n",
       "1  December 14, 2009           17            134  \n",
       "2   November 3, 2015           10             89  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103a37a",
   "metadata": {},
   "source": [
    "Let's create a `pandas.DataFrame` for the whole training set by selecting all the elements of `drug_dataset[\"train\"]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12c29e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drug_dataset[\"train\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f9a8f7",
   "metadata": {},
   "source": [
    "> <font color=\"darkgreen\">🚨 Under the hood, `Dataset.set_format()` changes the return format for the dataset's `__getitem__()` dunder method. This means that when we want to create a new object like `train_df` from a `Dataset` in the `\"pandas\"` format, we need to slice the whole dataset to obtain a `pandas.DataFrame`. You can verify for yourself that the type of `drug_dataset[\"train\"]` is `Dataset`, irrespective of the output format.</font>\n",
    "\n",
    "From here we can use all the Pandas functionality that we want. For example, we can do fancy chaining to compute the class distribution among the `condition` entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3867bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>birth control</td>\n",
       "      <td>27655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>8023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acne</td>\n",
       "      <td>5209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>4991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pain</td>\n",
       "      <td>4744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       condition  frequency\n",
       "0  birth control      27655\n",
       "1     depression       8023\n",
       "2           acne       5209\n",
       "3        anxiety       4991\n",
       "4           pain       4744"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = (\n",
    "    train_df[\"condition\"]\n",
    "    .value_counts()\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"condition\", \"condition\": \"frequency\"})\n",
    ")\n",
    "frequencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84884b",
   "metadata": {},
   "source": [
    "And once we're done with our Pandas analysis, we can always create a new `Dataset` object by using the `Dataset.from_pandas()` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c272a307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['condition', 'frequency'],\n",
       "    num_rows: 819\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "freq_dataset = Dataset.from_pandas(frequencies)\n",
    "freq_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74c45f",
   "metadata": {},
   "source": [
    "> ✏️ Try it out! <font color=\"darkgreen\">Compute the average rating per drug and store the result in a new `Dataset`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "03e010e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drugName</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A + D Cracked Skin Relief</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A / B Otic</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abiraterone</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Absorbine Jr.</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Accolate</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Zileuton</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>Zostavax</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>Zoster vaccine live</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>Zostrix Diabetic Foot Pain</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>depo-subQ provera 104</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3052 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        drugName  rating\n",
       "0      A + D Cracked Skin Relief    10.0\n",
       "1                     A / B Otic    10.0\n",
       "8                    Abiraterone    10.0\n",
       "12                 Absorbine Jr.    10.0\n",
       "17                      Accolate    10.0\n",
       "...                          ...     ...\n",
       "2999                    Zileuton     1.0\n",
       "3024                    Zostavax     1.0\n",
       "3025         Zoster vaccine live     1.0\n",
       "3027  Zostrix Diabetic Foot Pain     1.0\n",
       "3049       depo-subQ provera 104     1.0\n",
       "\n",
       "[3052 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying it out\n",
    "## https://stackoverflow.com/questions/30482071/how-to-calculate-mean-values-grouped-on-another-column-in-pandas\n",
    "## https://stackoverflow.com/questions/17141558/how-to-sort-a-dataframe-in-python-pandas-by-two-or-more-columns\n",
    "ratings = (\n",
    "    train_df\n",
    "    .groupby(\"drugName\", as_index=False)[\"rating\"]\n",
    "    .mean()\n",
    "    .sort_values([\"rating\", \"drugName\"], ascending=[False, True])\n",
    ")\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e99a9d",
   "metadata": {},
   "source": [
    "This wraps up our tour of the various preprocessing techniques available in 🤗 Datasets. To round out the section, let's create a validation set to prepare the dataset for training a classifier on. Before doing so, we'll reset the output format of `drug_dataset` from `\"pandas\"` to `\"arrow\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0ff8c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b8f4a",
   "metadata": {},
   "source": [
    "### Creating a validation set\n",
    "\n",
    "Although we have a test set we could use for evaluation, it's a good practice to leave the test set untouched and create a separate validation set during development. Once you are happy with the performance of your models on the validation set, you can do a final sanity check on the test set. This process helps mitigate the risk that you'll overfit to the test set and deploy a model that fails on real-world data.\n",
    "\n",
    "🤗 Datasets provides a `Dataset.train_test_split()` function that is based on the famous functionality from `scikit-learn`. Let's use it to split our training set into `train` and `validation` splits (we set the seed argument for reproducibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "19828e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-fa2e5035d44eb731.arrow and /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-77e4b8011fe95505.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 110811\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 27703\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 46108\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset_clean = drug_dataset[\"train\"].train_test_split(train_size=0.8, seed=42)\n",
    "# Rename the default \"test\" split to \"validation\"\n",
    "drug_dataset_clean[\"validation\"] = drug_dataset_clean.pop(\"test\")\n",
    "# Add the \"test\" set to our `DatasetDict`\n",
    "drug_dataset_clean[\"test\"] = drug_dataset[\"test\"]\n",
    "drug_dataset_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff824e53",
   "metadata": {},
   "source": [
    "Great, we've now prepared a dataset that's ready for training some models on! In section 5 we'll show you how to upload datasets to the Hugging Face Hub, but for now let's cap off our analysis by looking at a few ways you can save datasets on your local machine.\n",
    "\n",
    "### Saving a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8af2a8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/blF9uxYcKHo\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/blF9uxYcKHo\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5514f37",
   "metadata": {},
   "source": [
    "Although 🤗 Datasets will cache every downloaded dataset and the operations performed on it, there are times when you'll want to save a dataset to disk (e.g., in case the cache gets deleted). As shown in the table below, 🤗 Datasets provides three main functions to save your dataset in different formats:\n",
    "\n",
    "|Data format|Function|\n",
    "|-----------|--------|\n",
    "|Arrow|`Dataset.save_to_disk()`|\n",
    "|CSV|`Dataset.to_csv()`|\n",
    "|JSON|`Dataset.to_json()`|\n",
    "\n",
    "For example, let's save our cleaned dataset in the Arrow format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d4987d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-c4dec85fb2b4f24b.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/csv/default-936f472160ee3f45/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-2971f6df953fc535.arrow\n"
     ]
    }
   ],
   "source": [
    "drug_dataset_clean.save_to_disk(\"drug-reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4624fa",
   "metadata": {},
   "source": [
    "This will create a directory with the following structure:\n",
    "```\n",
    "drug-reviews/\n",
    "├── dataset_dict.json\n",
    "├── test\n",
    "│   ├── dataset.arrow\n",
    "│   ├── dataset_info.json\n",
    "│   └── state.json\n",
    "├── train\n",
    "│   ├── dataset.arrow\n",
    "│   ├── dataset_info.json\n",
    "│   ├── indices.arrow\n",
    "│   └── state.json\n",
    "└── validation\n",
    "    ├── dataset.arrow\n",
    "    ├── dataset_info.json\n",
    "    ├── indices.arrow\n",
    "    └── state.json\n",
    "```\n",
    "where we can see that each split is associated with its own *dataset.arrow* table, and some metadata in *dataset_info.json* and *state.json*. You can think of the Arrow format as a fancy table of columns and rows that is optimized for building high-performance applications that process and transport large datasets.\n",
    "\n",
    "Once the dataset is saved, we can load it by using the `load_from_disk()` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e87ebe1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 110811\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 27703\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 46108\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "drug_dataset_reloaded = load_from_disk(\"drug-reviews\")\n",
    "drug_dataset_reloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1eb22",
   "metadata": {},
   "source": [
    "For the CSV and JSON formats, we have to store each split as a separate file. One way to do this is by iterating over the keys and values in the `DatasetDict` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7e8c3a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f17c1918fc4794b0893ad8c01b63f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccbef71516c4e30a90d45c5cf551fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbc83db7e72475dad25c3870cdfcd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, dataset in drug_dataset_clean.items():\n",
    "    dataset.to_json(f\"drug-reviews-{split}.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46755b31",
   "metadata": {},
   "source": [
    "This saves each split in [JSON Lines format](https://jsonlines.org/), where each row in the dataset is stored as a single line of JSON. Here's what the first example looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "df805102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"patient_id\":89879,\"drugName\":\"Cyclosporine\",\"condition\":\"keratoconjunctivitis sicca\",\"review\":\"\\\"I have used Restasis for about a year now and have seen almost no progress.  For most of my life I've had red and bothersome eyes. After trying various eye drops, my doctor recommended Restasis.  He said it typically takes 3 to 6 months for it to really kick in but it never did kick in.  When I put the drops in it burns my eyes for the first 30 - 40 minutes.  I've talked with my doctor about this and he said it is normal but should go away after some time, but it hasn't. Every year around spring time my eyes get terrible irritated  and this year has been the same (maybe even worse than other years) even though I've been using Restasis for a year now. The only difference I notice was for the first couple weeks, but now I'm ready to move on.\\\"\",\"rating\":2.0,\"date\":\"April 20, 2013\",\"usefulCount\":69,\"review_length\":147}\r\n"
     ]
    }
   ],
   "source": [
    "!mv drug-reviews-test.jsonl data\n",
    "!mv drug-reviews-train.jsonl data\n",
    "!mv drug-reviews-validation.jsonl data\n",
    "!head -n 1 data/drug-reviews-train.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abefb99c",
   "metadata": {},
   "source": [
    "We can then use the techniques from [section 2](https://huggingface.co/course/chapter5/2) to load the JSON files as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b57f2008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5a5ec922f92efec5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /Users/matthias/.cache/huggingface/datasets/json/default-5a5ec922f92efec5/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee336f6c5b834e379b721e3248fc72c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3b8236392544b99780d58e388cf347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/matthias/.cache/huggingface/datasets/json/default-5a5ec922f92efec5/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eaf0681fe84a20a762a817060efd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 110811\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 27703\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 46108\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": \"data/drug-reviews-train.jsonl\",\n",
    "    \"validation\": \"data/drug-reviews-validation.jsonl\",\n",
    "    \"test\": \"data/drug-reviews-test.jsonl\",\n",
    "}\n",
    "drug_dataset_reloaded = load_dataset(\"json\", data_files=data_files)\n",
    "drug_dataset_reloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b927bb8",
   "metadata": {},
   "source": [
    "And that's it for our excursion into data wrangling with 🤗 Datasets! Now that we have a cleaned dataset for training a model on, here are a few ideas that you could try out:\n",
    "1. Use the techniques from [Chapter 3](https://huggingface.co/course/chapter3) to train a classifier that can predict the patient condition based on the drug review.\n",
    "1. Use the `summarization` pipeline from [Chapter 1](https://huggingface.co/course/chapter1) to generate summaries of the reviews.\n",
    "\n",
    "Next, we'll take a look at how 🤗 Datasets can enable you to work with huge datasets without blowing up your laptop!\n",
    "\n",
    "## [Big data? 🤗 Datasets to the rescue!](https://huggingface.co/course/chapter5/4?fw=pt)\n",
    "\n",
    "Nowadays it is not uncommon to find yourself working with multi-gigabyte datasets, especially if you're planning to pretrain a transformer like BERT or GPT-2 from scratch. In these cases, even *loading* the data can be a challenge. For example, the WebText corpus used to pretrain GPT-2 consists of over 8 million documents and 40 GB of text — loading this into your laptop's RAM is likely to give it a heart attack!\n",
    "\n",
    "Fortunately, 🤗 Datasets has been designed to overcome these limitations. It frees you from memory management problems by treating datasets as *memory-mapped* files, and from hard drive limits by *streaming* the entries in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46d47b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/JwISwTCPPWo\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/JwISwTCPPWo\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c04fc8",
   "metadata": {},
   "source": [
    "In this section we'll explore these features of 🤗 Datasets with a huge 825 GB corpus known as [the Pile](https://pile.eleuther.ai/). Let's get started!\n",
    "\n",
    "### What is the Pile?\n",
    "\n",
    "The Pile is an English text corpus that was created by [EleutherAI](https://www.eleuther.ai/) for training large-scale language models. It includes a diverse range of datasets, spanning scientific articles, GitHub code repositories, and filtered web text. The training corpus is available in [14 GB chunks](https://mystic.the-eye.eu/public/AI/pile/), and you can also download several of the [individual components](https://mystic.the-eye.eu/public/AI/pile_preliminary_components/). Let's start by taking a look at the PubMed Abstracts dataset, which is a corpus of abstracts from 15 million biomedical publications on [PubMed](https://pubmed.ncbi.nlm.nih.gov/). The dataset is in [JSON Lines format](https://jsonlines.org/) and is compressed using the `zstandard` library, so first we need to install that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2ccc6971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following command needs to run only once\n",
    "#!conda install -c conda-forge zstandard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af34372",
   "metadata": {},
   "source": [
    "Next, we can load the dataset using the method for remote files that we learned in [section 2](https://huggingface.co/course/chapter5/2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ddc4dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6ad3aefcb3b64942\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/default-6ad3aefcb3b64942/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['meta', 'text'],\n",
       "    num_rows: 15518009\n",
       "})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes a few minutes to run, so go grab a tea or coffee while you wait :)\n",
    "data_files = \"https://mystic.the-eye.eu/public/AI/pile_preliminary_components/\"\n",
    "data_files += \"PUBMED_title_abstracts_2019_baseline.jsonl.zst\"\n",
    "pubmed_dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "pubmed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd2b88",
   "metadata": {},
   "source": [
    "We can see that there are 15,518,009 rows and 2 columns in our dataset — that's a lot!\n",
    "> <font color=\"darkgreen\">✎ By default, 🤗 Datasets will decompress the files needed to load a dataset. If you want to preserve hard drive space, you can pass `DownloadConfig(delete_extracted=True)` to the `download_config` argument of `load_dataset()`. See the [documentation](https://huggingface.co/docs/datasets/package_reference/builder_classes.html?#datasets.utils.DownloadConfig) for more details.</font>\n",
    "\n",
    "Let's inspect the contents of the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e66ea478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'pmid': 11409574, 'language': 'eng'},\n",
       " 'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection.\\nTo determine the prevalence of hypoxaemia in children aged under 5 years suffering acute lower respiratory infections (ALRI), the risk factors for hypoxaemia in children under 5 years of age with ALRI, and the association of hypoxaemia with an increased risk of dying in children of the same age. Systematic review of the published literature. Out-patient clinics, emergency departments and hospitalisation wards in 23 health centres from 10 countries. Cohort studies reporting the frequency of hypoxaemia in children under 5 years of age with ALRI, and the association between hypoxaemia and the risk of dying. Prevalence of hypoxaemia measured in children with ARI and relative risks for the association between the severity of illness and the frequency of hypoxaemia, and between hypoxaemia and the risk of dying. Seventeen published studies were found that included 4,021 children under 5 with acute respiratory infections (ARI) and reported the prevalence of hypoxaemia. Out-patient children and those with a clinical diagnosis of upper ARI had a low risk of hypoxaemia (pooled estimate of 6% to 9%). The prevalence increased to 31% and to 43% in patients in emergency departments and in cases with clinical pneumonia, respectively, and it was even higher among hospitalised children (47%) and in those with radiographically confirmed pneumonia (72%). The cumulated data also suggest that hypoxaemia is more frequent in children living at high altitude. Three papers reported an association between hypoxaemia and death, with relative risks varying between 1.4 and 4.6. Papers describing predictors of hypoxaemia have focused on clinical signs for detecting hypoxaemia rather than on identifying risk factors for developing this complication. Hypoxaemia is a common and potentially lethal complication of ALRI in children under 5, particularly among those with severe disease and those living at high altitude. Given the observed high prevalence of hypoxaemia and its likely association with increased mortality, efforts should be made to improve the detection of hypoxaemia and to provide oxygen earlier to more children with severe ALRI.'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b21bfcd",
   "metadata": {},
   "source": [
    "Okay, this looks like the abstract from a medical article. Now let's see how much RAM we've used to load the dataset!\n",
    "\n",
    "### The magic of memory mapping\n",
    "A simple way to measure memory usage in Python is with the [`psutil`](https://psutil.readthedocs.io/en/latest/) library, which can be installed with `conda` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "93586589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following command needs to run only once\n",
    "#!conda install -c conda-forge psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4014d",
   "metadata": {},
   "source": [
    "It provides a `Process` class that allows us to check the memory usage of the current process as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0e4c5bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 2978.64 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "# Process.memory_info is expressed in bytes, so convert to megabytes\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60d837",
   "metadata": {},
   "source": [
    "Here, the `rss` attribute refers to the *resident set size*, which is the fraction of memory that a process occupies in RAM. This measurement also includes the memory used by the Python interpreter and the libraries we've loaded, so the actual amount of memory used to load the dataset is a bit smaller. For comparison, let's see how large the dataset is on disk, using the `dataset_size` attribute. Since the result is expressed in bytes like before, we need to manually convert it to gigabytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "27481141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in dataset : 20978892555\n",
      "Dataset size (cache file) : 19.54 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of files in dataset : {pubmed_dataset.dataset_size}\")\n",
    "size_gb = pubmed_dataset.dataset_size / (1024**3)\n",
    "print(f\"Dataset size (cache file) : {size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c9d609",
   "metadata": {},
   "source": [
    "Nice — despite it being almost 20 GB large, we're able to load and access the dataset with much less RAM!\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">Pick one of the subsets from the Pile that is larger than your laptop or desktop's RAM, load it with 🤗 Datasets, and measure the amount of RAM used. Note that to get an accurate measurement, you'll want to do this in a new process. You can find the decompressed sizes of each subset in Table 1 of the Pile paper.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b3747f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ecdac2973eb354f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /Users/matthias/.cache/huggingface/datasets/json/default-ecdac2973eb354f0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cbf80b1fb74c5a8aa66b6d8ed27487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747cd6a41eb94a4b8011210e45810285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/17.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6611cdd347d44554b1f4a3a03f717f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/matthias/.cache/huggingface/datasets/json/default-ecdac2973eb354f0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n",
      "Number of files in dataset : 55157239146\n",
      "Dataset size (cache file) : 51.37 GB\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "## https://pile.eleuther.ai/\n",
    "## https://arxiv.org/pdf/2101.00027.pdf\n",
    "## https://mystic.the-eye.eu/public/AI/pile_preliminary_components/\n",
    "data_files = \"https://mystic.the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst\"\n",
    "FreeLaw_dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "print(f\"Number of files in dataset : {FreeLaw_dataset.dataset_size}\")\n",
    "size_gb = FreeLaw_dataset.dataset_size / (1024**3)\n",
    "print(f\"Dataset size (cache file) : {size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f3c10",
   "metadata": {},
   "source": [
    "If you're familiar with Pandas, this result might come as a surprise because of Wes Kinney's famous [rule of thumb](https://wesmckinney.com/blog/apache-arrow-pandas-internals/) that you typically need 5 to 10 times as much RAM as the size of your dataset. So how does 🤗 Datasets solve this memory management problem? 🤗 Datasets treats each dataset as a [memory-mapped file](https://en.wikipedia.org/wiki/Memory-mapped_file), which provides a mapping between RAM and filesystem storage that allows the library to access and operate on elements of the dataset without needing to fully load it into memory.\n",
    "\n",
    "Memory-mapped files can also be shared across multiple processes, which enables methods like `Dataset.map()` to be parallelized without needing to move or copy the dataset. Under the hood, these capabilities are all realized by the [Apache Arrow](https://arrow.apache.org/) memory format and [`pyarrow`](https://arrow.apache.org/docs/python/index.html) library, which make the data loading and processing lightning fast. (For more details about Apache Arrow and comparisons to Pandas, check out [Dejan Simic's blog post](https://towardsdatascience.com/apache-arrow-read-dataframe-with-zero-memory-69634092b1a).) To see this in action, let's run a little speed test by iterating over all the elements in the PubMed Abstracts dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "93bb1297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterated over 15518009 examples (about 51.4 GB) in 147.5s, i.e., 0.348 GB/s\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "code_snippet = \"\"\"\n",
    "batch_size = 1000\n",
    "for idx in range(0, len(pubmed_dataset), batch_size):\n",
    "    _ = pubmed_dataset[idx:idx + batch_size]\n",
    "\"\"\"\n",
    "time = timeit.timeit(stmt=code_snippet, number=1, globals=globals())\n",
    "print(\"Iterated over {} examples (about {:.1f} GB) in {:.1f}s, i.e., {:.3f} GB/s\".format(\n",
    "    len(pubmed_dataset), size_gb, time, size_gb/time\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febebbd0",
   "metadata": {},
   "source": [
    "Here we've used Python's `timeit` module to measure the execution time taken by `code_snippet`. You'll typically be able to iterate over a dataset at speeds of a few tenths of a GB/s to several GB/s. This works great for the vast majority of applications, but sometimes you'll have to work with a dataset that is too large to even store on your laptop's hard drive. For example, if we tried to download the Pile in its entirety, we'd need 825 GB of free disk space! To handle these cases, 🤗 Datasets provides a streaming feature that allows us to download and access elements on the fly, without needing to download the whole dataset. Let's take a look at how this works.\n",
    "> <font color=\"darkgreen\">💡 In Jupyter notebooks, you can also time cells using the [`%%timeit` magic function](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit).</font>\n",
    "\n",
    "### Streaming datasets\n",
    "To enable dataset streaming you just need to pass the `streaming=True` argument to the `load_dataset()` function. For example, let's load the PubMed Abstracts dataset again, but in streaming mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bcd15b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ecdac2973eb354f0\n"
     ]
    }
   ],
   "source": [
    "pubmed_dataset_streamed = load_dataset(\"json\", data_files=data_files, split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c88eb6",
   "metadata": {},
   "source": [
    "Instead of the familiar `Dataset` that we've encountered elsewhere in this chapter, the object returned with `streaming=True` is an `IterableDataset`. As the name suggests, to access the elements of an `IterableDataset` we need to iterate over it. We can access the first element of our streamed dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "90b292fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "  'case_ID': '110921.json',\n",
       "  'date_created': '2010-04-28T17:12:49Z'},\n",
       " 'text': '\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General.\\nRobert Gilbert Johnston argued the cause for respondent. With him on the brief was Clayton C. Ikei.[*]\\n*240 JUSTICE BLACKMUN delivered the opinion of the Court.\\nThe issue in this case is whether the transfer of a prisoner from a state prison in Hawaii to one in California implicates a liberty interest within the meaning of the Due Process Clause of the Fourteenth Amendment.\\n\\nI\\n\\nA\\nRespondent Delbert Kaahanui Wakinekona is serving a sentence of life imprisonment without the possibility of parole as a result of his murder conviction in a Hawaii state court. He also is serving sentences for various other crimes, including rape, robbery, and escape. At the Hawaii State Prison outside Honolulu, respondent was classified as a maximum security risk and placed in the maximum control unit.\\nPetitioner Antone Olim is the Administrator of the Hawaii State Prison. The other petitioners constituted a prison \"Program Committee.\" On August 2, 1976, the Committee held hearings to determine the reasons for a breakdown in discipline and the failure of certain programs within the prison\\'s maximum control unit. Inmates of the unit appeared at these hearings. The Committee singled out respondent and another inmate as troublemakers. On August 5, respondent received notice that the Committee, at a hearing to be held on August 10, would review his correctional program to determine whether his classification within the system should be changed and whether he should be transferred to another Hawaii facility or to a mainland institution.\\n*241 The August 10 hearing was conducted by the same persons who had presided over the hearings on August 2. Respondent retained counsel to represent him. The Committee recommended that respondent\\'s classification as a maximum security risk be continued and that he be transferred to a prison on the mainland. He received the following explanation from the Committee:\\n\"The Program Committee, having reviewed your entire file, your testimony and arguments by your counsel, concluded that your control classification remains at Maximum. You are still considered a security risk in view of your escapes and subsequent convictions for serious felonies. The Committee noted the progress you made in vocational training and your expressed desire to continue in this endeavor. However your relationship with staff, who reported that you threaten and intimidate them, raises grave concerns regarding your potential for further disruptive and violent behavior. Since there is no other Maximum security prison in Hawaii which can offer you the correctional programs you require and you cannot remain at [the maximum control unit] because of impending construction of a new facility, the Program Committee recommends your transfer to an institution on the mainland.\" App. 7-8.\\nPetitioner Olim, as Administrator, accepted the Committee\\'s recommendation, and a few days later respondent was transferred to Folsom State Prison in California.\\n\\nB\\nRule IV of the Supplementary Rules and Regulations of the Corrections Division, Department of Social Services and Housing, State of Hawaii, approved in June 1976, recites that the inmate classification process is not concerned with punishment. Rather, it is intended to promote the best interests *242 of the inmate, the State, and the prison community.[1] Paragraph 3 of Rule IV requires a hearing prior to a prison transfer involving \"a grievous loss to the inmate,\" which the Rule defines \"generally\" as \"a serious loss to a reasonable man.\" App. 21.[2] The Administrator, under ¶ 2 of the Rule, is required to establish \"an impartial Program Committee\" to conduct such a hearing, the Committee to be \"composed of at least three members who were not actively involved in the process by which the inmate . . . was brought before the Committee.\" App. 20. Under ¶ 3, the Committee must give the inmate written notice of the hearing, permit him, with certain stated exceptions, to confront and cross-examine witnesses, afford him an opportunity to be heard, and apprise him of the Committee\\'s findings. App. 21-24.[3]\\nThe Committee is directed to make a recommendation to the Administrator, who then decides what action to take:\\n\"[The Administrator] may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate *243. . . , other inmates . . . , institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" Rule IV, ¶ 3d(3), App. 24.\\nThe regulations contain no standards governing the Administrator\\'s exercise of his discretion. See Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981).\\n\\nC\\nRespondent filed suit under 42 U. S. C. § 1983 against petitioners as the state officials who caused his transfer. He alleged that he had been denied procedural due process because the Committee that recommended his transfer consisted of the same persons who had initiated the hearing, this being in specific violation of Rule IV, ¶ 2, and because the Committee was biased against him. The United States District Court for the District of Hawaii dismissed the complaint, holding that the Hawaii regulations governing prison transfers do not create a substantive liberty interest protected by the Due Process Clause. 459 F. Supp. 473 (1978).[4]\\nThe United States Court of Appeals for the Ninth Circuit, by a divided vote, reversed. 664 F. 2d 708 (1981). It held that Hawaii had created a constitutionally protected liberty interest by promulgating Rule IV. In so doing, the court declined to follow cases from other Courts of Appeals holding that certain procedures mandated by prison transfer regulations do not create a liberty interest. See, e. g., Cofone v. Manson, 594 F. 2d 934 (CA2 1979); Lombardo v. Meachum, 548 F. 2d 13 (CA1 1977). The court reasoned that Rule IV gives Hawaii prisoners a justifiable expectation that they will not be transferred to the mainland absent a hearing, before an impartial committee, concerning the facts alleged in the *244 prehearing notice.[5] Because the Court of Appeals\\' decision created a conflict among the Circuits, and because the case presents the further question whether the Due Process Clause in and of itself protects against interstate prison transfers, we granted certiorari. 456 U. S. 1005 (1982).\\n\\nII\\nIn Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236 (1976), this Court held that an intrastate prison transfer does not directly implicate the Due Process Clause of the Fourteenth Amendment. In Meachum, inmates at a Massachusetts medium security prison had been transferred to a maximum security prison in that Commonwealth. In Montanye, a companion case, an inmate had been transferred from one maximum security New York prison to another as punishment for a breach of prison rules. This Court rejected \"the notion that any grievous loss visited upon a person by the State is sufficient to invoke the procedural protections of the Due Process Clause.\" Meachum, 427 U. S., at 224 (emphasis in original). It went on to state:\\n\"The initial decision to assign the convict to a particular institution is not subject to audit under the Due Process Clause, although the degree of confinement in one prison may be quite different from that in another. The conviction has sufficiently extinguished the defendant\\'s liberty *245 interest to empower the State to confine him in any of its prisons.\\n\"Neither, in our view, does the Due Process Clause in and of itself protect a duly convicted prisoner against transfer from one institution to another within the state prison system. Confinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Id., at 224-225 (emphasis in original).\\nThe Court observed that, although prisoners retain a residuum of liberty, see Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974), a holding that \"any substantial deprivation imposed by prison authorities triggers the procedural protections of the Due Process Clause would subject to judicial review a wide spectrum of discretionary actions that traditionally have been the business of prison administrators rather than of the federal courts.\" 427 U. S., at 225 (emphasis in original).\\nApplying the Meachum and Montanye principles in Vitek v. Jones, 445 U. S. 480 (1980), this Court held that the transfer of an inmate from a prison to a mental hospital did implicate a liberty interest. Placement in the mental hospital was \"not within the range of conditions of confinement to which a prison sentence subjects an individual,\" because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" Id., at 493. Respondent argues that the same is true of confinement of a Hawaii prisoner on the mainland, and that Vitek therefore controls.\\nWe do not agree. Just as an inmate has no justifiable expectation that he will be incarcerated in any particular prison within a State, he has no justifiable expectation that he will be incarcerated in any particular State.[6] Often, confinement *246 in the inmate\\'s home State will not be possible. A person convicted of a federal crime in a State without a federal correctional facility usually will serve his sentence in another State. Overcrowding and the need to separate particular prisoners may necessitate interstate transfers. For any number of reasons, a State may lack prison facilities capable of providing appropriate correctional programs for all offenders.\\nStatutes and interstate agreements recognize that, from time to time, it is necessary to transfer inmates to prisons in other States. On the federal level, 18 U. S. C. § 5003(a) authorizes the Attorney General to contract with a State for the transfer of a state prisoner to a federal prison, whether in that State or another. See Howe v. Smith, 452 U. S. 473 (1981).[7] Title 18 U. S. C. § 4002 (1976 ed. and Supp. V) permits the Attorney General to contract with any State for the placement of a federal prisoner in state custody for up to three years. Neither statute requires that the prisoner remain in the State in which he was convicted and sentenced.\\nOn the state level, many States have statutes providing for the transfer of a state prisoner to a federal prison, e. g., Haw. Rev. Stat. § 353-18 (1976), or another State\\'s prison, e. g., Alaska Stat. Ann. § 33.30.100 (1982). Corrections compacts between States, implemented by statutes, authorize incarceration of a prisoner of one State in another State\\'s prison. See, e. g., Cal. Penal Code Ann. § 11189 (West 1982) (codifying Interstate Corrections Compact); § 11190 (codifying Western Interstate Corrections Compact); Conn. Gen. *247 Stat. § 18-102 (1981) (codifying New England Interstate Corrections Compact); § 18-106 (codifying Interstate Corrections Compact); Haw. Rev. Stat. § 355-1 (1976) (codifying Western Interstate Corrections Compact); Idaho Code § 20-701 (1979) (codifying Interstate Corrections Compact); Ky. Rev. Stat. § 196.610 (1982) (same). And prison regulations such as Hawaii\\'s Rule IV anticipate that inmates sometimes will be transferred to prisons in other States.\\nIn short, it is neither unreasonable nor unusual for an inmate to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced, or to be transferred to an out-of-state prison after serving a portion of his sentence in his home State. Confinement in another State, unlike confinement in a mental institution, is \"within the normal limits or range of custody which the conviction has authorized the State to impose.\" Meachum, 427 U. S., at 225.[8] Even when, as here, the transfer involves long distances and an ocean crossing, the confinement remains within constitutional limits. The difference between such a transfer and an intrastate or interstate transfer of *248 shorter distance is a matter of degree, not of kind,[9] and Meachum instructs that \"the determining factor is the nature of the interest involved rather than its weight.\" 427 U. S., at 224. The reasoning of Meachum and Montanye compels the conclusion that an interstate prison transfer, including one from Hawaii to California, does not deprive an inmate of any liberty interest protected by the Due Process Clause in and of itself.\\n\\nIII\\nThe Court of Appeals held that Hawaii\\'s prison regulations create a constitutionally protected liberty interest. In Meachum, however, the State had \"conferred no right on the *249 prisoner to remain in the prison to which he was initially assigned, defeasible only upon proof of specific acts of misconduct,\" 427 U. S., at 226, and \"ha[d] not represented that transfers [would] occur only on the occurrence of certain events,\" id., at 228. Because the State had retained \"discretion to transfer [the prisoner] for whatever reason or for no reason at all,\" ibid., the Court found that the State had not created a constitutionally protected liberty interest. Similarly, because the state law at issue in Montanye \"impose[d] no conditions on the discretionary power to transfer,\" 427 U. S., at 243, there was no basis for invoking the protections of the Due Process Clause.\\nThese cases demonstrate that a State creates a protected liberty interest by placing substantive limitations on official discretion. An inmate must show \"that particularized standards or criteria guide the State\\'s decisionmakers.\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 467 (1981) (BRENNAN, J., concurring). If the decisionmaker is not \"required to base its decisions on objective and defined criteria,\" but instead \"can deny the requested relief for any constitutionally permissible reason or for no reason at all,\" ibid., the State has not created a constitutionally protected liberty interest. See id., at 466-467 (opinion of the Court); see also Vitek v. Jones, 445 U. S., at 488-491 (summarizing cases).\\nHawaii\\'s prison regulations place no substantive limitations on official discretion and thus create no liberty interest entitled to protection under the Due Process Clause. As Rule IV itself makes clear, and as the Supreme Court of Hawaii has held in Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981, the prison Administrator\\'s discretion to transfer an inmate is completely unfettered. No standards govern or restrict the Administrator\\'s determination. Because the Administrator is the only decisionmaker under Rule IV, we need not decide whether the introductory paragraph *250 of Rule IV, see n. 1, supra, places any substantive limitations on the purely advisory Program Committee.[10]\\nThe Court of Appeals thus erred in attributing significance to the fact that the prison regulations require a particular kind of hearing before the Administrator can exercise his unfettered discretion.[11] As the United States Court of Appeals for the Seventh Circuit recently stated in Shango v. Jurich, 681 F. 2d 1091, 1100-1101 (1982), \"[a] liberty interest is of course a substantive interest of an individual; it cannot be the right to demand needless formality.\"[12] Process is not an end in itself. Its constitutional purpose is to protect a substantive interest to which the individual has a legitimate claim of entitlement. See generally Simon, Liberty and Property in the Supreme Court: A Defense of Roth and Perry, 71 Calif. L. Rev. 146, 186 (1983). If officials may transfer a prisoner \"for whatever reason or for no reason at all,\" Meachum, 427 U. S., at 228, there is no such interest for process to protect. The State may choose to require procedures for reasons other than protection against deprivation of substantive *251 rights, of course,[13] but in making that choice the State does not create an independent substantive right. See Hewitt v. Helms, 459 U. S. 460, 471 (1983).\\n\\nIV\\nIn sum, we hold that the transfer of respondent from Hawaii to California did not implicate the Due Process Clause directly, and that Hawaii\\'s prison regulations do not create a protected liberty interest.[14] Accordingly, the judgment of the Court of Appeals is\\nReversed.\\nJUSTICE MARSHALL, with whom JUSTICE BRENNAN joins, and with whom JUSTICE STEVENS joins as to Part I, dissenting.\\nIn my view, the transfer of respondent Delbert Kaahanui Wakinekona from a prison in Hawaii to a prison in California implicated an interest in liberty protected by the Due Process Clause of the Fourteenth Amendment. I respectfully dissent.\\n\\nI\\nAn inmate\\'s liberty interest is not limited to whatever a State chooses to bestow upon him. An inmate retains a significant residuum of constitutionally protected liberty following his incarceration independent of any state law. As we stated in Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974): \"[A] prisoner is not wholly stripped of constitutional protections when he is imprisoned for crime. There is no iron curtain drawn between the Constitution and the prisons *252 of this country. . . . [Prisoners] may not be deprived of life, liberty, or property without due process of law.\"\\nIn determining whether a change in the conditions of imprisonment implicates a prisoner\\'s retained liberty interest, the relevant question is whether the change constitutes a sufficiently \"grievous loss\" to trigger the protection of due process. Vitek v. Jones, 445 U. S. 480, 488 (1980). See Morrissey v. Brewer, 408 U. S. 471, 481 (1972), citing Joint Anti-Fascist Refugee Committee v. McGrath, 341 U. S. 123, 168 (1951) (Frankfurter, J., concurring). The answer depends in part on a comparison of \"the treatment of the particular prisoner with the customary, habitual treatment of the population of the prison as a whole.\" Hewitt v. Helms, 459 U. S. 460, 486 (1983) (STEVENS, J., dissenting). This principle was established in our decision in Vitek, which held that the transfer of an inmate from a prison to a mental hospital implicated a liberty interest because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" 445 U. S., at 493. Because a significant qualitative change in the conditions of confinement is not \"within the range of conditions of confinement to which a prison sentence subjects an individual,\" ibid., such a change implicates a prisoner\\'s protected liberty interest.\\nThere can be little doubt that the transfer of Wakinekona from a Hawaii prison to a prison in California represents a substantial qualitative change in the conditions of his confinement. In addition to being incarcerated, which is the ordinary consequence of a criminal conviction and sentence, Wakinekona has in effect been banished from his home, a punishment historically considered to be \"among the severest.\"[1] For an indeterminate period of time, possibly the *253 rest of his life, nearly 2,500 miles of ocean will separate him from his family and friends. As a practical matter, Wakinekona may be entirely cut off from his only contacts with the outside world, just as if he had been imprisoned in an institution which prohibited visits by outsiders. Surely the isolation imposed on him by the transfer is far more drastic than that which normally accompanies imprisonment.\\nI cannot agree with the Court that Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236, 243 (1976), compel the conclusion that Wakinekona\\'s transfer implicates no liberty interest. Ante, at 248. Both cases involved transfers of prisoners between institutions located within the same State in which they were convicted, and the Court expressly phrased its holdings in terms of intrastate transfers.[2] Both decisions rested on the premise that no liberty interest is implicated by an initial decision to place a prisoner in one institution in the State rather than another. See Meachum, supra, at 224; Montanye, supra, at 243. On the basis of that premise, the Court concluded that the subsequent transfer of a prisoner to a different facility within the State likewise implicates no liberty interest. In this case, however, we cannot assume that a State\\'s initial placement of an individual in a prison far removed from his family and residence would raise no due process questions. None of our *254 prior decisions has indicated that such a decision would be immune from scrutiny under the Due Process Clause.\\nActual experience simply does not bear out the Court\\'s assumptions that interstate transfers are routine and that it is \"not unusual\" for a prisoner \"to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced.\" Ante, at 247. In Hawaii less than three percent of the state prisoners were transferred to prisons in other jurisdictions in 1979, and on a nationwide basis less than one percent of the prisoners held in state institutions were transferred to other jurisdictions.[3] Moreover, the vast majority of state prisoners are held in facilities located less than 250 miles from their homes.[4] Measured against these norms, Wakinekona\\'s transfer to a California prison represents a punishment \"qualitively different from the punishment characteristically suffered by a person convicted of crime.\" Vitek v. Jones, supra, at 493.\\nI therefore cannot agree that a State may transfer its prisoners at will, to any place, for any reason, without ever implicating any interest in liberty protected by the Due Process Clause.\\n\\nII\\nNor can I agree with the majority\\'s conclusion that Hawaii\\'s prison regulations do not create a liberty interest. This Court\\'s prior decisions establish that a liberty interest *255 may be \"created\"[5] by state laws, prison rules, regulations, or practices. State laws that impose substantive criteria which limit or guide the discretion of officials have been held to create a protected liberty interest. See, e. g., Hewitt v. Helms, 459 U. S. 460 (1983); Wolff v. McDonnell, 418 U. S. 539 (1974); Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979); Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). By contrast, a liberty interest is not created by a law which \"imposes no conditions on [prison officials\\'] discretionary power,\" Montanye, supra, at 243, authorizes prison officials to act \"for whatever reason or for no reason at all,\" Meachum, supra, at 228, or accords officials \"unfettered discretion,\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 466 (1981).\\nThe Court misapplies these principles in concluding that Hawaii\\'s prison regulations leave prison officials with unfettered discretion to transfer inmates. Ante, at 249-250. Rule IV establishes a scheme under which inmates are classified upon initial placement in an institution, and must subsequently be reclassified before they can be transferred to another institution. Under the Rule the standard for classifying inmates is their \"optimum placement within the Corrections Division\" in light of the \"best interests of the individual, the State, and the community.\"[6] In classifying inmates, the Program *256 Committee may not consider punitive aims. It may consider only factors relevant to determining where the individual will be \"best situated,\" such as \"his history, his changing needs, the resources and facilities available to the Corrections Divisions, the other inmates/wards, the exigencies of the community, and any other relevant factors.\" Paragraph 3 of Rule IV establishes a detailed set of procedures applicable when, as in this case, the reclassification of a prisoner may lead to a transfer involving a \"grievous loss,\" a phrase contained in the Rule itself.[7] The procedural rules are cast in mandatory language, and cover such matters as notice, access to information, hearing, confrontation and cross-examination, and the basis on which the Committee is to make its recommendation to the facility administrator.\\nThe limitations imposed by Rule IV are at least as substantial as those found sufficient to create a liberty interest in Hewitt v. Helms, supra, decided earlier this Term. In Hewitt an inmate contended that his confinement in administrative custody implicated an interest in liberty protected by the Due Process Clause. State law provided that a prison official could place inmates in administrative custody \"upon his assessment of the situation and the need for control,\" or \"where it has been determined that there is a threat of a serious disturbance, or a serious threat to the individual or others,\" and mandated certain procedures such as notice and a *257 hearing.[8] This Court construed the phrases \" `the need for control,\\' or `the threat of a serious disturbance,\\' \" as \"substantive predicates\" which restricted official discretion. Id., at 472. These restrictions, in combination with the mandatory procedural safeguards, \"deman[ded] a conclusion that the State has created a protected liberty interest.\" Ibid.\\nRule IV is not distinguishable in any meaningful respect from the provisions at issue in Helms. The procedural requirements contained in Rule IV are, if anything, far more elaborate than those involved in Helms, and are likewise couched in \"language of an unmistakably mandatory character.\" Id., at 471. Moreover, Rule IV, to no less an extent than the state law at issue in Helms, imposes substantive criteria restricting official discretion. In Helms this Court held that a statutory phrase such as \"the need for control\" constituted a limitation on the discretion of prison officials to place inmates in administrative custody. In my view Rule IV, which states that transfers are intended to ensure an inmate\\'s \"optimum placement\" in accordance with considerations which include \"his changing needs [and] the resources and facilities available to the Corrections Division,\" also restricts official discretion in ordering transfers.[9]\\nThe Court suggests that, even if the Program Committee does not have unlimited discretion in making recommendations for classifications and transfers, this cannot give rise to a state-created liberty interest because the prison Administrator retains \"completely unfettered\" \"discretion to transfer *258 an inmate,\" ante, at 249. I disagree. Rule IV, ¶ 3(d)(3), provides for review by the prison Administrator of recommendations forwarded to him by the Program Committee.[10] Even if this provision must be construed as authorizing the Administrator to transfer a prisoner for wholly arbitrary reasons,[11] that mere possibility does not defeat the protectible expectation otherwise created by Hawaii\\'s reclassification and transfer scheme that transfers will take place only if required to ensure an inmate\\'s optimum placement. In Helms a prison regulation also left open the possibility that the Superintendent could decide, for any reason or no reason at all, whether an inmate should be confined in administrative custody.[12] This Court nevertheless held that the state scheme as a whole created an interest in liberty protected by the Due Process Clause. 459 U. S., at 471-472. Helms thus necessarily rejects the view that state laws which impose substantive *259 limitations and elaborate procedural requirements on official conduct create no liberty interest solely because there remains the possibility that an official will act in an arbitrary manner at the end of the process.[13]\\nFor the foregoing reasons, I dissent.\\nNOTES\\n[*]  Briefs of amici curiae urging reversal were filed for the State of Alaska et al. by Paul L. Douglas, Attorney General of Nebraska, J. Kirk Brown, Assistant Attorney General, Judith W. Rogers, Corporation Counsel of the District of Columbia, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William J. Guste, Jr., of Louisiana, William A. Allain of Mississippi, Michael T. Greely of Montana, Richard H. Bryan of Nevada, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Gerald L. Baliles of Virginia, Kenneth O. Eikenberry of Washington, Chauncey H. Browning of West Virginia, Bronson C. La Follette of Wisconsin, and Steven F. Freudenthal of Wyoming; and for the Commonwealth of Massachusetts et al. by Francis X. Bellotti, Attorney General of Massachusetts, Stephen R. Delinsky, Barbara A. H. Smith, and Leo J. Cushing, Assistant Attorneys General, Anthony Ching, Solicitor General of Arizona, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William A. Allain of Mississippi, Michael T. Greely of Montana, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert O. Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Chauncey H. Browning of West Virginia, and Bronson C. La Follette of Wisconsin.\\n[1]  Paragraph 1 of Rule IV states:\\n\\n\"An inmate\\'s . . . classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates . . . , the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[2]  Petitioners concede, \"for purposes of the argument,\" that respondent suffered a \"grievous loss\" within the meaning of Rule IV when he was transferred from Hawaii to the mainland. Tr. of Oral Arg. 9, 25.\\n[3]  Rule V provides that an inmate may retain legal counsel if his hearing concerns a \"potential Interstate transfer.\" App. 25.\\n[4]  Respondent also had alleged that the transfer violated the Hawaii Constitution and state regulations and statutes. In light of its dismissal of respondent\\'s federal claims, the District Court declined to exercise pendent jurisdiction over these state-law claims. 459 F. Supp., at 476.\\n[5]  Several months before the Court of Appeals handed down its decision, the Supreme Court of Hawaii had held that because Hawaii\\'s prison regulations do not limit the Administrator\\'s discretion to transfer prisoners to the mainland, they do not create any liberty interest. Lono v. Ariyoshi, 63 Haw. 138, 621 P. 2d 976 (1981). In a petition for rehearing in the present case, petitioners directed the Ninth Circuit\\'s attention to the Lono decision. See 664 F. 2d, at 714. The Court of Appeals, however, concluded that the Hawaii court\\'s interpretation of the regulations was not different from its own; the Hawaii court merely had reached a different result on the \"federal question.\" The Court of Appeals thus adhered to its resolution of the case. Id., at 714-715.\\n[6]  Indeed, in Vitek itself the Court did not read Meachum and Montanye as stating a rule applicable only to intrastate transfers. The Court stated: \"In Meachum v. Fano . . . and Montanye v. Haymes . . . we held that the transfer of a prisoner from one prison to another does not infringe a protected liberty interest.\" 445 U. S., at 489 (emphasis added). The Court\\'s other cases describing Meachum and Montanye also have eschewed the narrow reading respondent now proposes. See Hewitt v. Helms, 459 U. S. 460, 467-468 (1983); Moody v. Daggett, 429 U. S. 78, 88, n. 9 (1976).\\n[7]  This statute has been invoked to transfer prisoners from Hawaii state facilities to federal prisons on the mainland. See Anthony v. Wilkinson, 637 F. 2d 1130 (CA7 1980), vacated and remanded sub nom. Hawaii v. Mederios, 453 U. S. 902 (1981).\\n[8]  After the decisions in Meachum and Montanye, courts almost uniformly have held that an inmate has no entitlement to remain in a prison in his home State. See Beshaw v. Fenton, 635 F. 2d 239, 246-247 (CA3 1980), cert. denied, 453 U. S. 912 (1981); Cofone v. Manson, 594 F. 2d 934, 937, n. 4 (CA2 1979); Sisbarro v. Warden, 592 F. 2d 1, 3 (CA1), cert. denied, 444 U. S. 849 (1979); Fletcher v. Warden, 467 F. Supp. 777, 779-780 (Kan. 1979); Curry-Bey v. Jackson, 422 F. Supp. 926, 931-933 (DC 1976); McDonnell v. United States Attorney General, 420 F. Supp. 217, 220 (ED Ill. 1976); Goodnow v. Perrin, 120 N. H. 669, 671, 421 A. 2d 1008, 1010 (1980); Girouard v. Hogan, 135 Vt. 448, 449-450, 378 A. 2d 105, 106-107 (1977); In re Young, 95 Wash. 2d 216, 227-228, 622 P. 2d 373, 379 (1980); cf. Fajeriak v. McGinnis, 493 F. 2d 468 (CA9 1974) (pre-Meachum transfers from Alaska to other States); Hillen v. Director of Department of Social Services, 455 F. 2d 510 (CA9), cert. denied, 409 U. S. 989 (1972) (pre-Meachum transfer from Hawaii to California). But see In re Young, 95 Wash. 2d, at 233, 622 P. 2d, at 382 (concurring opinion); State ex rel. Olson v. Maxwell, 259 N. W. 2d 621 (N. D. 1977); cf. Tai v. Thompson, 387 F. Supp. 912 (Haw. 1975) (pre-Meachum transfer).\\n[9]  Respondent\\'s argument to the contrary is unpersuasive. The Court in Montanye took note that among the hardships that may result from a prison transfer are separation of the inmate from home and family, separation from inmate friends, placement in a new and possibly hostile environment, difficulty in making contact with counsel, and interruption of educational and rehabilitative programs. 427 U. S., at 241, n. 4. These are the same hardships respondent faces as a result of his transfer from Hawaii to California.\\n\\nRespondent attempts to analogize his transfer to banishment in the English sense of \"beyond the seas,\" arguing that banishment surely is not within the range of confinement justified by his sentence. But respondent in no sense has been banished; his conviction, not the transfer, deprived him of his right freely to inhabit the State. The fact that his confinement takes place outside Hawaii is merely a fortuitous consequence of the fact that he must be confined, not an additional element of his punishment. See Girouard v. Hogan, 135 Vt., at 449-450, 378 A. 2d, at 106-107. Moreover, respondent has not been exiled; he remains within the United States.\\nIn essence, respondent\\'s banishment argument simply restates his claim that a transfer from Hawaii to the mainland is different in kind from other transfers. As has been shown in the text, however, respondent\\'s transfer was authorized by his conviction. A conviction, whether in Hawaii, Alaska, or one of the contiguous 48 States, empowers the State to confine the inmate in any penal institution in any State unless there is state law to the contrary or the reason for confining the inmate in a particular institution is itself constitutionally impermissible. See Montanye, 427 U. S., at 242; id., at 244 (dissenting opinion); Cruz v. Beto, 405 U. S. 319 (1972); Fajeriak v. McGinnis, 493 F. 2d, at 470.\\n[10]  In Hewitt v. Helms, 459 U. S. 460 (1983), unlike this case, state law limited the decisionmakers\\' discretion. To the extent the dissent doubts that the Administrator\\'s discretion under Rule IV is truly unfettered, post, at 258, and n. 11, it doubts the ability or authority of the Hawaii Supreme Court to construe state law.\\n[11]  In Meachum itself, the Court of Appeals had interpreted the applicable regulations as entitling inmates to a pretransfer hearing, see Fano v. Meachum, 520 F. 2d 374, 379-380 (CA1 1975), but this Court held that state law created no liberty interest.\\n[12]  Other courts agree that an expectation of receiving process is not, without more, a liberty interest protected by the Due Process Clause. See, e. g., United States v. Jiles, 658 F. 2d 194, 200 (CA3 1981), cert. denied, 455 U. S. 923 (1982); Bills v. Henderson, 631 F. 2d 1287, 1298-1299 (CA6 1980); Pugliese v. Nelson, 617 F. 2d 916, 924-925 (CA2 1980); Cofone v. Manson, 594 F. 2d, at 938; Lombardo v. Meachum, 548 F. 2d 13, 14-16 (CA1 1977); Adams v. Wainwright, 512 F. Supp. 948, 953 (ND Fla. 1981); Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981.\\n[13]  Petitioners assert that the hearings required by Rule IV not only enable the officials to gather information and thereby to exercise their discretion intelligently, but also have a therapeutic purpose: inmate participation in the decisionmaking process, it is hoped, reduces tension in the prison. See Tr. of Oral Arg. 52-53.\\n[14]  In light of this conclusion, respondent\\'s claim of bias in the composition of the prison Program Committee becomes irrelevant.\\n[1]  4 J. Elliott, Debates on the Federal Constitution 555 (1836). Whether it is called banishment, exile, deportation, relegation, or transportation, compelling a person \"to quit a city, place, or country, for a specified period of time, or for life,\" has long been considered a unique and severe deprivation, and was specifically outlawed by \"[t]he twelfth section of the English Habeas Corpus Act, 31 Car. II, one of the three great muniments of English liberty.\" United States v. Ju Toy, 198 U. S. 253, 269-270 (1905) (Brewer, J., dissenting).\\n[2]  Thus in Meachum the Court stated that the State, by convicting the defendant, was \"empower[ed] to confine him in any of its prisons,\" 427 U. S., at 224 (emphasis deleted), that a \"transfer from one institution to another within the state prison system\" implicated no due process interest, id., at 225, and that \"[c]onfinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Ibid. See also Montanye, 427 U. S., at 242 (\"We held in Meachum v. Fano, that no Due Process Clause liberty interest of a duly convicted prison inmate is infringed when he is transferred from one prison to another within the State\").\\n[3]  U. S. Dept. of Justice, Bureau of Justice Statistics, Sourcebook of Criminal Justice Statistics \\x97 1981, Table 6.27, pp. 478-479 (T. Flanagan, D. Van Alstyne, & M. Gottfredson eds. 1982). These figures reflect \"all inmates who were transferred from one State\\'s jurisdiction to another to continue sentences already in force,\" and \"[d]oes not include the release if [the] State does not relinquish jurisdiction.\" Id., at 590.\\n[4]  U. S. Dept. of Justice, Profile of State Prison Inmates: Sociodemographic Findings from the 1974 Survey of Inmates of State Correctional Facilities 1 (1979). Over 70 percent of state inmates are held in institutions located less than 250 miles from their homes.\\n[5]  But see Hewitt v. Helms, 459 U. S. 460, 488 (1983) (STEVENS, J., dissenting) (Prison regulations \"provide evidentiary support for the conclusion that the transfer affects a constitutionally protected interest in liberty,\" but they \"do not create that interest\" (emphasis in original)).\\n[6]  Paragraph 1 of Rule IV provides:\\n\\n\"An inmate\\'s/ward\\'s classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates/wards, the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[7]  While the term \"grievous loss\" is not explicitly defined, the prison regulations treat a transfer to the mainland as a grievous loss entitling an inmate to the procedural rights established in Rule IV, ¶ 3. This is readily inferred from Rule IV, ¶ 3, which states that intrastate transfers do not involve a grievous loss, and Rule V, which permits inmates to retain counsel only in specified circumstances, one of which is a reclassification that may result in an interstate transfer. App. 25.\\n[8]  See 459 U. S., at 470-471, n. 6.\\n[9]  See also Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). In that case, the District Court held that the language of a prison policy statement, stating that \"[i]nmates may be segregated for medical, psychiatric, disciplinary, or administrative reasons,\" 462 F. Supp., at 403, was sufficient to create a protected expectation that an inmate would not be segregated for arbitrary reasons. See also Bills v. Henderson, 631 F. 2d 1287, 1293 (CA6 1980), cert. denied, 449 U. S. 1093 (1981); Winsett v. McGinnes, 617 F. 2d 996, 107 (CA3 1980) (en banc).\\n[10]  Rule IV, ¶ 3(d)(3), provides:\\n\\n\"The facility administrator will, within a reasonable period of time, review the Program Committee\\'s recommendation. He may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate/ward, other inmates/wards, institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" App. 21.\\n[11]  I doubt that Rule IV would be construed to permit the Administrator to order a transfer for punitive reasons, since Rule IV expressly disallows punitive transfers.\\n[12]  That provision stated: \"All decisions of the Program Review Committee shall be reviewed by the Superintendent for his sustaining the decision or amending or reversing the decision in favor of the inmate.\" Pennsylvania Bureau of Correction Administrative Directive BC-ADM 801, Rule III(H)(7). App. to Brief for Respondent in Hewitt v. Helms, O. T. 1982, No. 81-638, p. 12a. Because an inmate could be confined in administrative custody only if the Program Review Committee determined that such confinement is and continues to be \"appropriate,\" id., at 18a, the Superintendent in Helms was the \"decisionmaker,\" ante, at 249-250, who determined whether inmates would be held in administrative custody.\\n[13]  This view was also implicitly rejected in Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979). The Court held that the Nebraska statute governing the decision whether or not to grant parole created a \"protectible entitlement,\" id., at 12, even though the statute, which listed a number of factors to be considered in the parole decision, also authorized the Parole Board to deny parole on the basis of \"[a]ny other factors the board determines to be relevant.\" Id., at 18.\\n\\nTo the extent that Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981), on which the majority relies, ante, at 249, suggests that no liberty interest is created as state law has not entirely eliminated the possibility of arbitrary action, it is inconsistent with both Helms and Greenholtz.\\n'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(pubmed_dataset_streamed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec3f42",
   "metadata": {},
   "source": [
    "The elements from a streamed dataset can be processed on the fly using `IterableDataset.map()`, which is useful during training if you need to tokenize the inputs. The process is exactly the same as the one we used to tokenize our dataset in [Chapter 3](https://huggingface.co/course/chapter3), with the only difference being that outputs are returned one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6296044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10289 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "  'case_ID': '110921.json',\n",
       "  'date_created': '2010-04-28T17:12:49Z'},\n",
       " 'text': '\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General.\\nRobert Gilbert Johnston argued the cause for respondent. With him on the brief was Clayton C. Ikei.[*]\\n*240 JUSTICE BLACKMUN delivered the opinion of the Court.\\nThe issue in this case is whether the transfer of a prisoner from a state prison in Hawaii to one in California implicates a liberty interest within the meaning of the Due Process Clause of the Fourteenth Amendment.\\n\\nI\\n\\nA\\nRespondent Delbert Kaahanui Wakinekona is serving a sentence of life imprisonment without the possibility of parole as a result of his murder conviction in a Hawaii state court. He also is serving sentences for various other crimes, including rape, robbery, and escape. At the Hawaii State Prison outside Honolulu, respondent was classified as a maximum security risk and placed in the maximum control unit.\\nPetitioner Antone Olim is the Administrator of the Hawaii State Prison. The other petitioners constituted a prison \"Program Committee.\" On August 2, 1976, the Committee held hearings to determine the reasons for a breakdown in discipline and the failure of certain programs within the prison\\'s maximum control unit. Inmates of the unit appeared at these hearings. The Committee singled out respondent and another inmate as troublemakers. On August 5, respondent received notice that the Committee, at a hearing to be held on August 10, would review his correctional program to determine whether his classification within the system should be changed and whether he should be transferred to another Hawaii facility or to a mainland institution.\\n*241 The August 10 hearing was conducted by the same persons who had presided over the hearings on August 2. Respondent retained counsel to represent him. The Committee recommended that respondent\\'s classification as a maximum security risk be continued and that he be transferred to a prison on the mainland. He received the following explanation from the Committee:\\n\"The Program Committee, having reviewed your entire file, your testimony and arguments by your counsel, concluded that your control classification remains at Maximum. You are still considered a security risk in view of your escapes and subsequent convictions for serious felonies. The Committee noted the progress you made in vocational training and your expressed desire to continue in this endeavor. However your relationship with staff, who reported that you threaten and intimidate them, raises grave concerns regarding your potential for further disruptive and violent behavior. Since there is no other Maximum security prison in Hawaii which can offer you the correctional programs you require and you cannot remain at [the maximum control unit] because of impending construction of a new facility, the Program Committee recommends your transfer to an institution on the mainland.\" App. 7-8.\\nPetitioner Olim, as Administrator, accepted the Committee\\'s recommendation, and a few days later respondent was transferred to Folsom State Prison in California.\\n\\nB\\nRule IV of the Supplementary Rules and Regulations of the Corrections Division, Department of Social Services and Housing, State of Hawaii, approved in June 1976, recites that the inmate classification process is not concerned with punishment. Rather, it is intended to promote the best interests *242 of the inmate, the State, and the prison community.[1] Paragraph 3 of Rule IV requires a hearing prior to a prison transfer involving \"a grievous loss to the inmate,\" which the Rule defines \"generally\" as \"a serious loss to a reasonable man.\" App. 21.[2] The Administrator, under ¶ 2 of the Rule, is required to establish \"an impartial Program Committee\" to conduct such a hearing, the Committee to be \"composed of at least three members who were not actively involved in the process by which the inmate . . . was brought before the Committee.\" App. 20. Under ¶ 3, the Committee must give the inmate written notice of the hearing, permit him, with certain stated exceptions, to confront and cross-examine witnesses, afford him an opportunity to be heard, and apprise him of the Committee\\'s findings. App. 21-24.[3]\\nThe Committee is directed to make a recommendation to the Administrator, who then decides what action to take:\\n\"[The Administrator] may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate *243. . . , other inmates . . . , institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" Rule IV, ¶ 3d(3), App. 24.\\nThe regulations contain no standards governing the Administrator\\'s exercise of his discretion. See Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981).\\n\\nC\\nRespondent filed suit under 42 U. S. C. § 1983 against petitioners as the state officials who caused his transfer. He alleged that he had been denied procedural due process because the Committee that recommended his transfer consisted of the same persons who had initiated the hearing, this being in specific violation of Rule IV, ¶ 2, and because the Committee was biased against him. The United States District Court for the District of Hawaii dismissed the complaint, holding that the Hawaii regulations governing prison transfers do not create a substantive liberty interest protected by the Due Process Clause. 459 F. Supp. 473 (1978).[4]\\nThe United States Court of Appeals for the Ninth Circuit, by a divided vote, reversed. 664 F. 2d 708 (1981). It held that Hawaii had created a constitutionally protected liberty interest by promulgating Rule IV. In so doing, the court declined to follow cases from other Courts of Appeals holding that certain procedures mandated by prison transfer regulations do not create a liberty interest. See, e. g., Cofone v. Manson, 594 F. 2d 934 (CA2 1979); Lombardo v. Meachum, 548 F. 2d 13 (CA1 1977). The court reasoned that Rule IV gives Hawaii prisoners a justifiable expectation that they will not be transferred to the mainland absent a hearing, before an impartial committee, concerning the facts alleged in the *244 prehearing notice.[5] Because the Court of Appeals\\' decision created a conflict among the Circuits, and because the case presents the further question whether the Due Process Clause in and of itself protects against interstate prison transfers, we granted certiorari. 456 U. S. 1005 (1982).\\n\\nII\\nIn Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236 (1976), this Court held that an intrastate prison transfer does not directly implicate the Due Process Clause of the Fourteenth Amendment. In Meachum, inmates at a Massachusetts medium security prison had been transferred to a maximum security prison in that Commonwealth. In Montanye, a companion case, an inmate had been transferred from one maximum security New York prison to another as punishment for a breach of prison rules. This Court rejected \"the notion that any grievous loss visited upon a person by the State is sufficient to invoke the procedural protections of the Due Process Clause.\" Meachum, 427 U. S., at 224 (emphasis in original). It went on to state:\\n\"The initial decision to assign the convict to a particular institution is not subject to audit under the Due Process Clause, although the degree of confinement in one prison may be quite different from that in another. The conviction has sufficiently extinguished the defendant\\'s liberty *245 interest to empower the State to confine him in any of its prisons.\\n\"Neither, in our view, does the Due Process Clause in and of itself protect a duly convicted prisoner against transfer from one institution to another within the state prison system. Confinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Id., at 224-225 (emphasis in original).\\nThe Court observed that, although prisoners retain a residuum of liberty, see Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974), a holding that \"any substantial deprivation imposed by prison authorities triggers the procedural protections of the Due Process Clause would subject to judicial review a wide spectrum of discretionary actions that traditionally have been the business of prison administrators rather than of the federal courts.\" 427 U. S., at 225 (emphasis in original).\\nApplying the Meachum and Montanye principles in Vitek v. Jones, 445 U. S. 480 (1980), this Court held that the transfer of an inmate from a prison to a mental hospital did implicate a liberty interest. Placement in the mental hospital was \"not within the range of conditions of confinement to which a prison sentence subjects an individual,\" because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" Id., at 493. Respondent argues that the same is true of confinement of a Hawaii prisoner on the mainland, and that Vitek therefore controls.\\nWe do not agree. Just as an inmate has no justifiable expectation that he will be incarcerated in any particular prison within a State, he has no justifiable expectation that he will be incarcerated in any particular State.[6] Often, confinement *246 in the inmate\\'s home State will not be possible. A person convicted of a federal crime in a State without a federal correctional facility usually will serve his sentence in another State. Overcrowding and the need to separate particular prisoners may necessitate interstate transfers. For any number of reasons, a State may lack prison facilities capable of providing appropriate correctional programs for all offenders.\\nStatutes and interstate agreements recognize that, from time to time, it is necessary to transfer inmates to prisons in other States. On the federal level, 18 U. S. C. § 5003(a) authorizes the Attorney General to contract with a State for the transfer of a state prisoner to a federal prison, whether in that State or another. See Howe v. Smith, 452 U. S. 473 (1981).[7] Title 18 U. S. C. § 4002 (1976 ed. and Supp. V) permits the Attorney General to contract with any State for the placement of a federal prisoner in state custody for up to three years. Neither statute requires that the prisoner remain in the State in which he was convicted and sentenced.\\nOn the state level, many States have statutes providing for the transfer of a state prisoner to a federal prison, e. g., Haw. Rev. Stat. § 353-18 (1976), or another State\\'s prison, e. g., Alaska Stat. Ann. § 33.30.100 (1982). Corrections compacts between States, implemented by statutes, authorize incarceration of a prisoner of one State in another State\\'s prison. See, e. g., Cal. Penal Code Ann. § 11189 (West 1982) (codifying Interstate Corrections Compact); § 11190 (codifying Western Interstate Corrections Compact); Conn. Gen. *247 Stat. § 18-102 (1981) (codifying New England Interstate Corrections Compact); § 18-106 (codifying Interstate Corrections Compact); Haw. Rev. Stat. § 355-1 (1976) (codifying Western Interstate Corrections Compact); Idaho Code § 20-701 (1979) (codifying Interstate Corrections Compact); Ky. Rev. Stat. § 196.610 (1982) (same). And prison regulations such as Hawaii\\'s Rule IV anticipate that inmates sometimes will be transferred to prisons in other States.\\nIn short, it is neither unreasonable nor unusual for an inmate to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced, or to be transferred to an out-of-state prison after serving a portion of his sentence in his home State. Confinement in another State, unlike confinement in a mental institution, is \"within the normal limits or range of custody which the conviction has authorized the State to impose.\" Meachum, 427 U. S., at 225.[8] Even when, as here, the transfer involves long distances and an ocean crossing, the confinement remains within constitutional limits. The difference between such a transfer and an intrastate or interstate transfer of *248 shorter distance is a matter of degree, not of kind,[9] and Meachum instructs that \"the determining factor is the nature of the interest involved rather than its weight.\" 427 U. S., at 224. The reasoning of Meachum and Montanye compels the conclusion that an interstate prison transfer, including one from Hawaii to California, does not deprive an inmate of any liberty interest protected by the Due Process Clause in and of itself.\\n\\nIII\\nThe Court of Appeals held that Hawaii\\'s prison regulations create a constitutionally protected liberty interest. In Meachum, however, the State had \"conferred no right on the *249 prisoner to remain in the prison to which he was initially assigned, defeasible only upon proof of specific acts of misconduct,\" 427 U. S., at 226, and \"ha[d] not represented that transfers [would] occur only on the occurrence of certain events,\" id., at 228. Because the State had retained \"discretion to transfer [the prisoner] for whatever reason or for no reason at all,\" ibid., the Court found that the State had not created a constitutionally protected liberty interest. Similarly, because the state law at issue in Montanye \"impose[d] no conditions on the discretionary power to transfer,\" 427 U. S., at 243, there was no basis for invoking the protections of the Due Process Clause.\\nThese cases demonstrate that a State creates a protected liberty interest by placing substantive limitations on official discretion. An inmate must show \"that particularized standards or criteria guide the State\\'s decisionmakers.\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 467 (1981) (BRENNAN, J., concurring). If the decisionmaker is not \"required to base its decisions on objective and defined criteria,\" but instead \"can deny the requested relief for any constitutionally permissible reason or for no reason at all,\" ibid., the State has not created a constitutionally protected liberty interest. See id., at 466-467 (opinion of the Court); see also Vitek v. Jones, 445 U. S., at 488-491 (summarizing cases).\\nHawaii\\'s prison regulations place no substantive limitations on official discretion and thus create no liberty interest entitled to protection under the Due Process Clause. As Rule IV itself makes clear, and as the Supreme Court of Hawaii has held in Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981, the prison Administrator\\'s discretion to transfer an inmate is completely unfettered. No standards govern or restrict the Administrator\\'s determination. Because the Administrator is the only decisionmaker under Rule IV, we need not decide whether the introductory paragraph *250 of Rule IV, see n. 1, supra, places any substantive limitations on the purely advisory Program Committee.[10]\\nThe Court of Appeals thus erred in attributing significance to the fact that the prison regulations require a particular kind of hearing before the Administrator can exercise his unfettered discretion.[11] As the United States Court of Appeals for the Seventh Circuit recently stated in Shango v. Jurich, 681 F. 2d 1091, 1100-1101 (1982), \"[a] liberty interest is of course a substantive interest of an individual; it cannot be the right to demand needless formality.\"[12] Process is not an end in itself. Its constitutional purpose is to protect a substantive interest to which the individual has a legitimate claim of entitlement. See generally Simon, Liberty and Property in the Supreme Court: A Defense of Roth and Perry, 71 Calif. L. Rev. 146, 186 (1983). If officials may transfer a prisoner \"for whatever reason or for no reason at all,\" Meachum, 427 U. S., at 228, there is no such interest for process to protect. The State may choose to require procedures for reasons other than protection against deprivation of substantive *251 rights, of course,[13] but in making that choice the State does not create an independent substantive right. See Hewitt v. Helms, 459 U. S. 460, 471 (1983).\\n\\nIV\\nIn sum, we hold that the transfer of respondent from Hawaii to California did not implicate the Due Process Clause directly, and that Hawaii\\'s prison regulations do not create a protected liberty interest.[14] Accordingly, the judgment of the Court of Appeals is\\nReversed.\\nJUSTICE MARSHALL, with whom JUSTICE BRENNAN joins, and with whom JUSTICE STEVENS joins as to Part I, dissenting.\\nIn my view, the transfer of respondent Delbert Kaahanui Wakinekona from a prison in Hawaii to a prison in California implicated an interest in liberty protected by the Due Process Clause of the Fourteenth Amendment. I respectfully dissent.\\n\\nI\\nAn inmate\\'s liberty interest is not limited to whatever a State chooses to bestow upon him. An inmate retains a significant residuum of constitutionally protected liberty following his incarceration independent of any state law. As we stated in Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974): \"[A] prisoner is not wholly stripped of constitutional protections when he is imprisoned for crime. There is no iron curtain drawn between the Constitution and the prisons *252 of this country. . . . [Prisoners] may not be deprived of life, liberty, or property without due process of law.\"\\nIn determining whether a change in the conditions of imprisonment implicates a prisoner\\'s retained liberty interest, the relevant question is whether the change constitutes a sufficiently \"grievous loss\" to trigger the protection of due process. Vitek v. Jones, 445 U. S. 480, 488 (1980). See Morrissey v. Brewer, 408 U. S. 471, 481 (1972), citing Joint Anti-Fascist Refugee Committee v. McGrath, 341 U. S. 123, 168 (1951) (Frankfurter, J., concurring). The answer depends in part on a comparison of \"the treatment of the particular prisoner with the customary, habitual treatment of the population of the prison as a whole.\" Hewitt v. Helms, 459 U. S. 460, 486 (1983) (STEVENS, J., dissenting). This principle was established in our decision in Vitek, which held that the transfer of an inmate from a prison to a mental hospital implicated a liberty interest because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" 445 U. S., at 493. Because a significant qualitative change in the conditions of confinement is not \"within the range of conditions of confinement to which a prison sentence subjects an individual,\" ibid., such a change implicates a prisoner\\'s protected liberty interest.\\nThere can be little doubt that the transfer of Wakinekona from a Hawaii prison to a prison in California represents a substantial qualitative change in the conditions of his confinement. In addition to being incarcerated, which is the ordinary consequence of a criminal conviction and sentence, Wakinekona has in effect been banished from his home, a punishment historically considered to be \"among the severest.\"[1] For an indeterminate period of time, possibly the *253 rest of his life, nearly 2,500 miles of ocean will separate him from his family and friends. As a practical matter, Wakinekona may be entirely cut off from his only contacts with the outside world, just as if he had been imprisoned in an institution which prohibited visits by outsiders. Surely the isolation imposed on him by the transfer is far more drastic than that which normally accompanies imprisonment.\\nI cannot agree with the Court that Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236, 243 (1976), compel the conclusion that Wakinekona\\'s transfer implicates no liberty interest. Ante, at 248. Both cases involved transfers of prisoners between institutions located within the same State in which they were convicted, and the Court expressly phrased its holdings in terms of intrastate transfers.[2] Both decisions rested on the premise that no liberty interest is implicated by an initial decision to place a prisoner in one institution in the State rather than another. See Meachum, supra, at 224; Montanye, supra, at 243. On the basis of that premise, the Court concluded that the subsequent transfer of a prisoner to a different facility within the State likewise implicates no liberty interest. In this case, however, we cannot assume that a State\\'s initial placement of an individual in a prison far removed from his family and residence would raise no due process questions. None of our *254 prior decisions has indicated that such a decision would be immune from scrutiny under the Due Process Clause.\\nActual experience simply does not bear out the Court\\'s assumptions that interstate transfers are routine and that it is \"not unusual\" for a prisoner \"to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced.\" Ante, at 247. In Hawaii less than three percent of the state prisoners were transferred to prisons in other jurisdictions in 1979, and on a nationwide basis less than one percent of the prisoners held in state institutions were transferred to other jurisdictions.[3] Moreover, the vast majority of state prisoners are held in facilities located less than 250 miles from their homes.[4] Measured against these norms, Wakinekona\\'s transfer to a California prison represents a punishment \"qualitively different from the punishment characteristically suffered by a person convicted of crime.\" Vitek v. Jones, supra, at 493.\\nI therefore cannot agree that a State may transfer its prisoners at will, to any place, for any reason, without ever implicating any interest in liberty protected by the Due Process Clause.\\n\\nII\\nNor can I agree with the majority\\'s conclusion that Hawaii\\'s prison regulations do not create a liberty interest. This Court\\'s prior decisions establish that a liberty interest *255 may be \"created\"[5] by state laws, prison rules, regulations, or practices. State laws that impose substantive criteria which limit or guide the discretion of officials have been held to create a protected liberty interest. See, e. g., Hewitt v. Helms, 459 U. S. 460 (1983); Wolff v. McDonnell, 418 U. S. 539 (1974); Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979); Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). By contrast, a liberty interest is not created by a law which \"imposes no conditions on [prison officials\\'] discretionary power,\" Montanye, supra, at 243, authorizes prison officials to act \"for whatever reason or for no reason at all,\" Meachum, supra, at 228, or accords officials \"unfettered discretion,\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 466 (1981).\\nThe Court misapplies these principles in concluding that Hawaii\\'s prison regulations leave prison officials with unfettered discretion to transfer inmates. Ante, at 249-250. Rule IV establishes a scheme under which inmates are classified upon initial placement in an institution, and must subsequently be reclassified before they can be transferred to another institution. Under the Rule the standard for classifying inmates is their \"optimum placement within the Corrections Division\" in light of the \"best interests of the individual, the State, and the community.\"[6] In classifying inmates, the Program *256 Committee may not consider punitive aims. It may consider only factors relevant to determining where the individual will be \"best situated,\" such as \"his history, his changing needs, the resources and facilities available to the Corrections Divisions, the other inmates/wards, the exigencies of the community, and any other relevant factors.\" Paragraph 3 of Rule IV establishes a detailed set of procedures applicable when, as in this case, the reclassification of a prisoner may lead to a transfer involving a \"grievous loss,\" a phrase contained in the Rule itself.[7] The procedural rules are cast in mandatory language, and cover such matters as notice, access to information, hearing, confrontation and cross-examination, and the basis on which the Committee is to make its recommendation to the facility administrator.\\nThe limitations imposed by Rule IV are at least as substantial as those found sufficient to create a liberty interest in Hewitt v. Helms, supra, decided earlier this Term. In Hewitt an inmate contended that his confinement in administrative custody implicated an interest in liberty protected by the Due Process Clause. State law provided that a prison official could place inmates in administrative custody \"upon his assessment of the situation and the need for control,\" or \"where it has been determined that there is a threat of a serious disturbance, or a serious threat to the individual or others,\" and mandated certain procedures such as notice and a *257 hearing.[8] This Court construed the phrases \" `the need for control,\\' or `the threat of a serious disturbance,\\' \" as \"substantive predicates\" which restricted official discretion. Id., at 472. These restrictions, in combination with the mandatory procedural safeguards, \"deman[ded] a conclusion that the State has created a protected liberty interest.\" Ibid.\\nRule IV is not distinguishable in any meaningful respect from the provisions at issue in Helms. The procedural requirements contained in Rule IV are, if anything, far more elaborate than those involved in Helms, and are likewise couched in \"language of an unmistakably mandatory character.\" Id., at 471. Moreover, Rule IV, to no less an extent than the state law at issue in Helms, imposes substantive criteria restricting official discretion. In Helms this Court held that a statutory phrase such as \"the need for control\" constituted a limitation on the discretion of prison officials to place inmates in administrative custody. In my view Rule IV, which states that transfers are intended to ensure an inmate\\'s \"optimum placement\" in accordance with considerations which include \"his changing needs [and] the resources and facilities available to the Corrections Division,\" also restricts official discretion in ordering transfers.[9]\\nThe Court suggests that, even if the Program Committee does not have unlimited discretion in making recommendations for classifications and transfers, this cannot give rise to a state-created liberty interest because the prison Administrator retains \"completely unfettered\" \"discretion to transfer *258 an inmate,\" ante, at 249. I disagree. Rule IV, ¶ 3(d)(3), provides for review by the prison Administrator of recommendations forwarded to him by the Program Committee.[10] Even if this provision must be construed as authorizing the Administrator to transfer a prisoner for wholly arbitrary reasons,[11] that mere possibility does not defeat the protectible expectation otherwise created by Hawaii\\'s reclassification and transfer scheme that transfers will take place only if required to ensure an inmate\\'s optimum placement. In Helms a prison regulation also left open the possibility that the Superintendent could decide, for any reason or no reason at all, whether an inmate should be confined in administrative custody.[12] This Court nevertheless held that the state scheme as a whole created an interest in liberty protected by the Due Process Clause. 459 U. S., at 471-472. Helms thus necessarily rejects the view that state laws which impose substantive *259 limitations and elaborate procedural requirements on official conduct create no liberty interest solely because there remains the possibility that an official will act in an arbitrary manner at the end of the process.[13]\\nFor the foregoing reasons, I dissent.\\nNOTES\\n[*]  Briefs of amici curiae urging reversal were filed for the State of Alaska et al. by Paul L. Douglas, Attorney General of Nebraska, J. Kirk Brown, Assistant Attorney General, Judith W. Rogers, Corporation Counsel of the District of Columbia, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William J. Guste, Jr., of Louisiana, William A. Allain of Mississippi, Michael T. Greely of Montana, Richard H. Bryan of Nevada, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Gerald L. Baliles of Virginia, Kenneth O. Eikenberry of Washington, Chauncey H. Browning of West Virginia, Bronson C. La Follette of Wisconsin, and Steven F. Freudenthal of Wyoming; and for the Commonwealth of Massachusetts et al. by Francis X. Bellotti, Attorney General of Massachusetts, Stephen R. Delinsky, Barbara A. H. Smith, and Leo J. Cushing, Assistant Attorneys General, Anthony Ching, Solicitor General of Arizona, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William A. Allain of Mississippi, Michael T. Greely of Montana, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert O. Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Chauncey H. Browning of West Virginia, and Bronson C. La Follette of Wisconsin.\\n[1]  Paragraph 1 of Rule IV states:\\n\\n\"An inmate\\'s . . . classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates . . . , the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[2]  Petitioners concede, \"for purposes of the argument,\" that respondent suffered a \"grievous loss\" within the meaning of Rule IV when he was transferred from Hawaii to the mainland. Tr. of Oral Arg. 9, 25.\\n[3]  Rule V provides that an inmate may retain legal counsel if his hearing concerns a \"potential Interstate transfer.\" App. 25.\\n[4]  Respondent also had alleged that the transfer violated the Hawaii Constitution and state regulations and statutes. In light of its dismissal of respondent\\'s federal claims, the District Court declined to exercise pendent jurisdiction over these state-law claims. 459 F. Supp., at 476.\\n[5]  Several months before the Court of Appeals handed down its decision, the Supreme Court of Hawaii had held that because Hawaii\\'s prison regulations do not limit the Administrator\\'s discretion to transfer prisoners to the mainland, they do not create any liberty interest. Lono v. Ariyoshi, 63 Haw. 138, 621 P. 2d 976 (1981). In a petition for rehearing in the present case, petitioners directed the Ninth Circuit\\'s attention to the Lono decision. See 664 F. 2d, at 714. The Court of Appeals, however, concluded that the Hawaii court\\'s interpretation of the regulations was not different from its own; the Hawaii court merely had reached a different result on the \"federal question.\" The Court of Appeals thus adhered to its resolution of the case. Id., at 714-715.\\n[6]  Indeed, in Vitek itself the Court did not read Meachum and Montanye as stating a rule applicable only to intrastate transfers. The Court stated: \"In Meachum v. Fano . . . and Montanye v. Haymes . . . we held that the transfer of a prisoner from one prison to another does not infringe a protected liberty interest.\" 445 U. S., at 489 (emphasis added). The Court\\'s other cases describing Meachum and Montanye also have eschewed the narrow reading respondent now proposes. See Hewitt v. Helms, 459 U. S. 460, 467-468 (1983); Moody v. Daggett, 429 U. S. 78, 88, n. 9 (1976).\\n[7]  This statute has been invoked to transfer prisoners from Hawaii state facilities to federal prisons on the mainland. See Anthony v. Wilkinson, 637 F. 2d 1130 (CA7 1980), vacated and remanded sub nom. Hawaii v. Mederios, 453 U. S. 902 (1981).\\n[8]  After the decisions in Meachum and Montanye, courts almost uniformly have held that an inmate has no entitlement to remain in a prison in his home State. See Beshaw v. Fenton, 635 F. 2d 239, 246-247 (CA3 1980), cert. denied, 453 U. S. 912 (1981); Cofone v. Manson, 594 F. 2d 934, 937, n. 4 (CA2 1979); Sisbarro v. Warden, 592 F. 2d 1, 3 (CA1), cert. denied, 444 U. S. 849 (1979); Fletcher v. Warden, 467 F. Supp. 777, 779-780 (Kan. 1979); Curry-Bey v. Jackson, 422 F. Supp. 926, 931-933 (DC 1976); McDonnell v. United States Attorney General, 420 F. Supp. 217, 220 (ED Ill. 1976); Goodnow v. Perrin, 120 N. H. 669, 671, 421 A. 2d 1008, 1010 (1980); Girouard v. Hogan, 135 Vt. 448, 449-450, 378 A. 2d 105, 106-107 (1977); In re Young, 95 Wash. 2d 216, 227-228, 622 P. 2d 373, 379 (1980); cf. Fajeriak v. McGinnis, 493 F. 2d 468 (CA9 1974) (pre-Meachum transfers from Alaska to other States); Hillen v. Director of Department of Social Services, 455 F. 2d 510 (CA9), cert. denied, 409 U. S. 989 (1972) (pre-Meachum transfer from Hawaii to California). But see In re Young, 95 Wash. 2d, at 233, 622 P. 2d, at 382 (concurring opinion); State ex rel. Olson v. Maxwell, 259 N. W. 2d 621 (N. D. 1977); cf. Tai v. Thompson, 387 F. Supp. 912 (Haw. 1975) (pre-Meachum transfer).\\n[9]  Respondent\\'s argument to the contrary is unpersuasive. The Court in Montanye took note that among the hardships that may result from a prison transfer are separation of the inmate from home and family, separation from inmate friends, placement in a new and possibly hostile environment, difficulty in making contact with counsel, and interruption of educational and rehabilitative programs. 427 U. S., at 241, n. 4. These are the same hardships respondent faces as a result of his transfer from Hawaii to California.\\n\\nRespondent attempts to analogize his transfer to banishment in the English sense of \"beyond the seas,\" arguing that banishment surely is not within the range of confinement justified by his sentence. But respondent in no sense has been banished; his conviction, not the transfer, deprived him of his right freely to inhabit the State. The fact that his confinement takes place outside Hawaii is merely a fortuitous consequence of the fact that he must be confined, not an additional element of his punishment. See Girouard v. Hogan, 135 Vt., at 449-450, 378 A. 2d, at 106-107. Moreover, respondent has not been exiled; he remains within the United States.\\nIn essence, respondent\\'s banishment argument simply restates his claim that a transfer from Hawaii to the mainland is different in kind from other transfers. As has been shown in the text, however, respondent\\'s transfer was authorized by his conviction. A conviction, whether in Hawaii, Alaska, or one of the contiguous 48 States, empowers the State to confine the inmate in any penal institution in any State unless there is state law to the contrary or the reason for confining the inmate in a particular institution is itself constitutionally impermissible. See Montanye, 427 U. S., at 242; id., at 244 (dissenting opinion); Cruz v. Beto, 405 U. S. 319 (1972); Fajeriak v. McGinnis, 493 F. 2d, at 470.\\n[10]  In Hewitt v. Helms, 459 U. S. 460 (1983), unlike this case, state law limited the decisionmakers\\' discretion. To the extent the dissent doubts that the Administrator\\'s discretion under Rule IV is truly unfettered, post, at 258, and n. 11, it doubts the ability or authority of the Hawaii Supreme Court to construe state law.\\n[11]  In Meachum itself, the Court of Appeals had interpreted the applicable regulations as entitling inmates to a pretransfer hearing, see Fano v. Meachum, 520 F. 2d 374, 379-380 (CA1 1975), but this Court held that state law created no liberty interest.\\n[12]  Other courts agree that an expectation of receiving process is not, without more, a liberty interest protected by the Due Process Clause. See, e. g., United States v. Jiles, 658 F. 2d 194, 200 (CA3 1981), cert. denied, 455 U. S. 923 (1982); Bills v. Henderson, 631 F. 2d 1287, 1298-1299 (CA6 1980); Pugliese v. Nelson, 617 F. 2d 916, 924-925 (CA2 1980); Cofone v. Manson, 594 F. 2d, at 938; Lombardo v. Meachum, 548 F. 2d 13, 14-16 (CA1 1977); Adams v. Wainwright, 512 F. Supp. 948, 953 (ND Fla. 1981); Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981.\\n[13]  Petitioners assert that the hearings required by Rule IV not only enable the officials to gather information and thereby to exercise their discretion intelligently, but also have a therapeutic purpose: inmate participation in the decisionmaking process, it is hoped, reduces tension in the prison. See Tr. of Oral Arg. 52-53.\\n[14]  In light of this conclusion, respondent\\'s claim of bias in the composition of the prison Program Committee becomes irrelevant.\\n[1]  4 J. Elliott, Debates on the Federal Constitution 555 (1836). Whether it is called banishment, exile, deportation, relegation, or transportation, compelling a person \"to quit a city, place, or country, for a specified period of time, or for life,\" has long been considered a unique and severe deprivation, and was specifically outlawed by \"[t]he twelfth section of the English Habeas Corpus Act, 31 Car. II, one of the three great muniments of English liberty.\" United States v. Ju Toy, 198 U. S. 253, 269-270 (1905) (Brewer, J., dissenting).\\n[2]  Thus in Meachum the Court stated that the State, by convicting the defendant, was \"empower[ed] to confine him in any of its prisons,\" 427 U. S., at 224 (emphasis deleted), that a \"transfer from one institution to another within the state prison system\" implicated no due process interest, id., at 225, and that \"[c]onfinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Ibid. See also Montanye, 427 U. S., at 242 (\"We held in Meachum v. Fano, that no Due Process Clause liberty interest of a duly convicted prison inmate is infringed when he is transferred from one prison to another within the State\").\\n[3]  U. S. Dept. of Justice, Bureau of Justice Statistics, Sourcebook of Criminal Justice Statistics \\x97 1981, Table 6.27, pp. 478-479 (T. Flanagan, D. Van Alstyne, & M. Gottfredson eds. 1982). These figures reflect \"all inmates who were transferred from one State\\'s jurisdiction to another to continue sentences already in force,\" and \"[d]oes not include the release if [the] State does not relinquish jurisdiction.\" Id., at 590.\\n[4]  U. S. Dept. of Justice, Profile of State Prison Inmates: Sociodemographic Findings from the 1974 Survey of Inmates of State Correctional Facilities 1 (1979). Over 70 percent of state inmates are held in institutions located less than 250 miles from their homes.\\n[5]  But see Hewitt v. Helms, 459 U. S. 460, 488 (1983) (STEVENS, J., dissenting) (Prison regulations \"provide evidentiary support for the conclusion that the transfer affects a constitutionally protected interest in liberty,\" but they \"do not create that interest\" (emphasis in original)).\\n[6]  Paragraph 1 of Rule IV provides:\\n\\n\"An inmate\\'s/ward\\'s classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates/wards, the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[7]  While the term \"grievous loss\" is not explicitly defined, the prison regulations treat a transfer to the mainland as a grievous loss entitling an inmate to the procedural rights established in Rule IV, ¶ 3. This is readily inferred from Rule IV, ¶ 3, which states that intrastate transfers do not involve a grievous loss, and Rule V, which permits inmates to retain counsel only in specified circumstances, one of which is a reclassification that may result in an interstate transfer. App. 25.\\n[8]  See 459 U. S., at 470-471, n. 6.\\n[9]  See also Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). In that case, the District Court held that the language of a prison policy statement, stating that \"[i]nmates may be segregated for medical, psychiatric, disciplinary, or administrative reasons,\" 462 F. Supp., at 403, was sufficient to create a protected expectation that an inmate would not be segregated for arbitrary reasons. See also Bills v. Henderson, 631 F. 2d 1287, 1293 (CA6 1980), cert. denied, 449 U. S. 1093 (1981); Winsett v. McGinnes, 617 F. 2d 996, 107 (CA3 1980) (en banc).\\n[10]  Rule IV, ¶ 3(d)(3), provides:\\n\\n\"The facility administrator will, within a reasonable period of time, review the Program Committee\\'s recommendation. He may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate/ward, other inmates/wards, institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" App. 21.\\n[11]  I doubt that Rule IV would be construed to permit the Administrator to order a transfer for punitive reasons, since Rule IV expressly disallows punitive transfers.\\n[12]  That provision stated: \"All decisions of the Program Review Committee shall be reviewed by the Superintendent for his sustaining the decision or amending or reversing the decision in favor of the inmate.\" Pennsylvania Bureau of Correction Administrative Directive BC-ADM 801, Rule III(H)(7). App. to Brief for Respondent in Hewitt v. Helms, O. T. 1982, No. 81-638, p. 12a. Because an inmate could be confined in administrative custody only if the Program Review Committee determined that such confinement is and continues to be \"appropriate,\" id., at 18a, the Superintendent in Helms was the \"decisionmaker,\" ante, at 249-250, who determined whether inmates would be held in administrative custody.\\n[13]  This view was also implicitly rejected in Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979). The Court held that the Nebraska statute governing the decision whether or not to grant parole created a \"protectible entitlement,\" id., at 12, even though the statute, which listed a number of factors to be considered in the parole decision, also authorized the Parole Board to deny parole on the basis of \"[a]ny other factors the board determines to be relevant.\" Id., at 18.\\n\\nTo the extent that Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981), on which the majority relies, ante, at 249, suggests that no liberty interest is created as state law has not entirely eliminated the possibility of arbitrary action, it is inconsistent with both Helms and Greenholtz.\\n',\n",
       " 'input_ids': [101,\n",
       "  4805,\n",
       "  2487,\n",
       "  1057,\n",
       "  1012,\n",
       "  1055,\n",
       "  1012,\n",
       "  22030,\n",
       "  1006,\n",
       "  3172,\n",
       "  1007,\n",
       "  19330,\n",
       "  5714,\n",
       "  3802,\n",
       "  2632,\n",
       "  1012,\n",
       "  1058,\n",
       "  1012,\n",
       "  11333,\n",
       "  4939,\n",
       "  5937,\n",
       "  7856,\n",
       "  2053,\n",
       "  1012,\n",
       "  6282,\n",
       "  1011,\n",
       "  17696,\n",
       "  2487,\n",
       "  1012,\n",
       "  4259,\n",
       "  2457,\n",
       "  1997,\n",
       "  2142,\n",
       "  2163,\n",
       "  1012,\n",
       "  5275,\n",
       "  2254,\n",
       "  2539,\n",
       "  1010,\n",
       "  3172,\n",
       "  1012,\n",
       "  2787,\n",
       "  2258,\n",
       "  2656,\n",
       "  1010,\n",
       "  3172,\n",
       "  1012,\n",
       "  8292,\n",
       "  28228,\n",
       "  6525,\n",
       "  3089,\n",
       "  2000,\n",
       "  1996,\n",
       "  2142,\n",
       "  2163,\n",
       "  2457,\n",
       "  1997,\n",
       "  9023,\n",
       "  2005,\n",
       "  1996,\n",
       "  6619,\n",
       "  4984,\n",
       "  1008,\n",
       "  23688,\n",
       "  2745,\n",
       "  1037,\n",
       "  1012,\n",
       "  14765,\n",
       "  1010,\n",
       "  2034,\n",
       "  4112,\n",
       "  4905,\n",
       "  2236,\n",
       "  1997,\n",
       "  7359,\n",
       "  1010,\n",
       "  5275,\n",
       "  1996,\n",
       "  3426,\n",
       "  2005,\n",
       "  9964,\n",
       "  2545,\n",
       "  1012,\n",
       "  2007,\n",
       "  2032,\n",
       "  2006,\n",
       "  1996,\n",
       "  4766,\n",
       "  2001,\n",
       "  2508,\n",
       "  1044,\n",
       "  1012,\n",
       "  4907,\n",
       "  10224,\n",
       "  4059,\n",
       "  1010,\n",
       "  4112,\n",
       "  4905,\n",
       "  2236,\n",
       "  1012,\n",
       "  2728,\n",
       "  7664,\n",
       "  10773,\n",
       "  5275,\n",
       "  1996,\n",
       "  3426,\n",
       "  2005,\n",
       "  6869,\n",
       "  4765,\n",
       "  1012,\n",
       "  2007,\n",
       "  2032,\n",
       "  2006,\n",
       "  1996,\n",
       "  4766,\n",
       "  2001,\n",
       "  11811,\n",
       "  1039,\n",
       "  1012,\n",
       "  25209,\n",
       "  2072,\n",
       "  1012,\n",
       "  1031,\n",
       "  1008,\n",
       "  1033,\n",
       "  1008,\n",
       "  11212,\n",
       "  3425,\n",
       "  2304,\n",
       "  23041,\n",
       "  5359,\n",
       "  1996,\n",
       "  5448,\n",
       "  1997,\n",
       "  1996,\n",
       "  2457,\n",
       "  1012,\n",
       "  1996,\n",
       "  3277,\n",
       "  1999,\n",
       "  2023,\n",
       "  2553,\n",
       "  2003,\n",
       "  3251,\n",
       "  1996,\n",
       "  4651,\n",
       "  1997,\n",
       "  1037,\n",
       "  7267,\n",
       "  2013,\n",
       "  1037,\n",
       "  2110,\n",
       "  3827,\n",
       "  1999,\n",
       "  7359,\n",
       "  2000,\n",
       "  2028,\n",
       "  1999,\n",
       "  2662,\n",
       "  17727,\n",
       "  19341,\n",
       "  4570,\n",
       "  1037,\n",
       "  7044,\n",
       "  3037,\n",
       "  2306,\n",
       "  1996,\n",
       "  3574,\n",
       "  1997,\n",
       "  1996,\n",
       "  2349,\n",
       "  2832,\n",
       "  11075,\n",
       "  1997,\n",
       "  1996,\n",
       "  15276,\n",
       "  7450,\n",
       "  1012,\n",
       "  1045,\n",
       "  1037,\n",
       "  6869,\n",
       "  4765,\n",
       "  3972,\n",
       "  8296,\n",
       "  10556,\n",
       "  23278,\n",
       "  11231,\n",
       "  2072,\n",
       "  11333,\n",
       "  4939,\n",
       "  5937,\n",
       "  7856,\n",
       "  2003,\n",
       "  3529,\n",
       "  1037,\n",
       "  6251,\n",
       "  1997,\n",
       "  2166,\n",
       "  10219,\n",
       "  2302,\n",
       "  1996,\n",
       "  6061,\n",
       "  1997,\n",
       "  17393,\n",
       "  2004,\n",
       "  1037,\n",
       "  2765,\n",
       "  1997,\n",
       "  2010,\n",
       "  4028,\n",
       "  10652,\n",
       "  1999,\n",
       "  1037,\n",
       "  7359,\n",
       "  2110,\n",
       "  2457,\n",
       "  1012,\n",
       "  2002,\n",
       "  2036,\n",
       "  2003,\n",
       "  3529,\n",
       "  11746,\n",
       "  2005,\n",
       "  2536,\n",
       "  2060,\n",
       "  6997,\n",
       "  1010,\n",
       "  2164,\n",
       "  9040,\n",
       "  1010,\n",
       "  13742,\n",
       "  1010,\n",
       "  1998,\n",
       "  4019,\n",
       "  1012,\n",
       "  2012,\n",
       "  1996,\n",
       "  7359,\n",
       "  2110,\n",
       "  3827,\n",
       "  2648,\n",
       "  16598,\n",
       "  1010,\n",
       "  6869,\n",
       "  4765,\n",
       "  2001,\n",
       "  6219,\n",
       "  2004,\n",
       "  1037,\n",
       "  4555,\n",
       "  3036,\n",
       "  3891,\n",
       "  1998,\n",
       "  2872,\n",
       "  1999,\n",
       "  1996,\n",
       "  4555,\n",
       "  2491,\n",
       "  3131,\n",
       "  1012,\n",
       "  9964,\n",
       "  2121,\n",
       "  9865,\n",
       "  2063,\n",
       "  19330,\n",
       "  5714,\n",
       "  2003,\n",
       "  1996,\n",
       "  8911,\n",
       "  1997,\n",
       "  1996,\n",
       "  7359,\n",
       "  2110,\n",
       "  3827,\n",
       "  1012,\n",
       "  1996,\n",
       "  2060,\n",
       "  9964,\n",
       "  2545,\n",
       "  11846,\n",
       "  1037,\n",
       "  3827,\n",
       "  1000,\n",
       "  2565,\n",
       "  2837,\n",
       "  1012,\n",
       "  1000,\n",
       "  2006,\n",
       "  2257,\n",
       "  1016,\n",
       "  1010,\n",
       "  3299,\n",
       "  1010,\n",
       "  1996,\n",
       "  2837,\n",
       "  2218,\n",
       "  19153,\n",
       "  2000,\n",
       "  5646,\n",
       "  1996,\n",
       "  4436,\n",
       "  2005,\n",
       "  1037,\n",
       "  12554,\n",
       "  1999,\n",
       "  9009,\n",
       "  1998,\n",
       "  1996,\n",
       "  4945,\n",
       "  1997,\n",
       "  3056,\n",
       "  3454,\n",
       "  2306,\n",
       "  1996,\n",
       "  3827,\n",
       "  1005,\n",
       "  1055,\n",
       "  4555,\n",
       "  2491,\n",
       "  3131,\n",
       "  1012,\n",
       "  13187,\n",
       "  1997,\n",
       "  1996,\n",
       "  3131,\n",
       "  2596,\n",
       "  2012,\n",
       "  2122,\n",
       "  19153,\n",
       "  1012,\n",
       "  1996,\n",
       "  2837,\n",
       "  25369,\n",
       "  2041,\n",
       "  6869,\n",
       "  4765,\n",
       "  1998,\n",
       "  2178,\n",
       "  24467,\n",
       "  2004,\n",
       "  4390,\n",
       "  12088,\n",
       "  1012,\n",
       "  2006,\n",
       "  2257,\n",
       "  1019,\n",
       "  1010,\n",
       "  6869,\n",
       "  4765,\n",
       "  2363,\n",
       "  5060,\n",
       "  2008,\n",
       "  1996,\n",
       "  2837,\n",
       "  1010,\n",
       "  2012,\n",
       "  1037,\n",
       "  4994,\n",
       "  2000,\n",
       "  2022,\n",
       "  2218,\n",
       "  2006,\n",
       "  2257,\n",
       "  2184,\n",
       "  1010,\n",
       "  2052,\n",
       "  3319,\n",
       "  2010,\n",
       "  20873,\n",
       "  2565,\n",
       "  2000,\n",
       "  5646,\n",
       "  3251,\n",
       "  2010,\n",
       "  5579,\n",
       "  2306,\n",
       "  1996,\n",
       "  2291,\n",
       "  2323,\n",
       "  2022,\n",
       "  2904,\n",
       "  1998,\n",
       "  3251,\n",
       "  2002,\n",
       "  2323,\n",
       "  2022,\n",
       "  4015,\n",
       "  2000,\n",
       "  2178,\n",
       "  7359,\n",
       "  4322,\n",
       "  2030,\n",
       "  2000,\n",
       "  1037,\n",
       "  8240,\n",
       "  5145,\n",
       "  1012,\n",
       "  1008,\n",
       "  22343,\n",
       "  1996,\n",
       "  2257,\n",
       "  2184,\n",
       "  4994,\n",
       "  2001,\n",
       "  4146,\n",
       "  2011,\n",
       "  1996,\n",
       "  2168,\n",
       "  5381,\n",
       "  2040,\n",
       "  2018,\n",
       "  15506,\n",
       "  2058,\n",
       "  1996,\n",
       "  19153,\n",
       "  2006,\n",
       "  2257,\n",
       "  1016,\n",
       "  1012,\n",
       "  6869,\n",
       "  4765,\n",
       "  6025,\n",
       "  9517,\n",
       "  2000,\n",
       "  5050,\n",
       "  2032,\n",
       "  1012,\n",
       "  1996,\n",
       "  2837,\n",
       "  6749,\n",
       "  2008,\n",
       "  6869,\n",
       "  4765,\n",
       "  1005,\n",
       "  1055,\n",
       "  5579,\n",
       "  2004,\n",
       "  1037,\n",
       "  4555,\n",
       "  3036,\n",
       "  3891,\n",
       "  2022,\n",
       "  2506,\n",
       "  1998,\n",
       "  2008,\n",
       "  2002,\n",
       "  2022,\n",
       "  4015,\n",
       "  2000,\n",
       "  1037,\n",
       "  3827,\n",
       "  2006,\n",
       "  1996,\n",
       "  8240,\n",
       "  1012,\n",
       "  2002,\n",
       "  2363,\n",
       "  1996,\n",
       "  2206,\n",
       "  7526,\n",
       "  2013,\n",
       "  1996,\n",
       "  2837,\n",
       "  1024,\n",
       "  1000,\n",
       "  1996,\n",
       "  2565,\n",
       "  2837,\n",
       "  1010,\n",
       "  2383,\n",
       "  8182,\n",
       "  2115,\n",
       "  2972,\n",
       "  5371,\n",
       "  1010,\n",
       "  2115,\n",
       "  10896,\n",
       "  1998,\n",
       "  9918,\n",
       "  2011,\n",
       "  2115,\n",
       "  9517,\n",
       "  1010,\n",
       "  5531,\n",
       "  2008,\n",
       "  2115,\n",
       "  2491,\n",
       "  5579,\n",
       "  3464,\n",
       "  2012,\n",
       "  4555,\n",
       "  1012,\n",
       "  2017,\n",
       "  2024,\n",
       "  2145,\n",
       "  2641,\n",
       "  1037,\n",
       "  3036,\n",
       "  3891,\n",
       "  1999,\n",
       "  3193,\n",
       "  1997,\n",
       "  2115,\n",
       "  12976,\n",
       "  1998,\n",
       "  4745,\n",
       "  20488,\n",
       "  2005,\n",
       "  3809,\n",
       "  10768,\n",
       "  7811,\n",
       "  3111,\n",
       "  1012,\n",
       "  1996,\n",
       "  2837,\n",
       "  3264,\n",
       "  1996,\n",
       "  5082,\n",
       "  2017,\n",
       "  2081,\n",
       "  1999,\n",
       "  13099,\n",
       "  2731,\n",
       "  1998,\n",
       "  2115,\n",
       "  5228,\n",
       "  4792,\n",
       "  2000,\n",
       "  3613,\n",
       "  1999,\n",
       "  2023,\n",
       "  23855,\n",
       "  1012,\n",
       "  2174,\n",
       "  2115,\n",
       "  3276,\n",
       "  2007,\n",
       "  3095,\n",
       "  1010,\n",
       "  2040,\n",
       "  2988,\n",
       "  2008,\n",
       "  2017,\n",
       "  15686,\n",
       "  1998,\n",
       "  20014,\n",
       "  27605,\n",
       "  13701,\n",
       "  2068,\n",
       "  1010,\n",
       "  13275,\n",
       "  6542,\n",
       "  5936,\n",
       "  4953,\n",
       "  2115,\n",
       "  4022,\n",
       "  2005,\n",
       "  2582,\n",
       "  23217,\n",
       "  3512,\n",
       "  1998,\n",
       "  6355,\n",
       "  5248,\n",
       "  1012,\n",
       "  2144,\n",
       "  2045,\n",
       "  2003,\n",
       "  2053,\n",
       "  2060,\n",
       "  4555,\n",
       "  3036,\n",
       "  3827,\n",
       "  1999,\n",
       "  7359,\n",
       "  2029,\n",
       "  2064,\n",
       "  3749,\n",
       "  2017,\n",
       "  1996,\n",
       "  20873,\n",
       "  3454,\n",
       "  2017,\n",
       "  5478,\n",
       "  1998,\n",
       "  2017,\n",
       "  3685,\n",
       "  3961,\n",
       "  2012,\n",
       "  1031,\n",
       "  1996,\n",
       "  4555,\n",
       "  2491,\n",
       "  3131,\n",
       "  1033,\n",
       "  2138,\n",
       "  1997,\n",
       "  17945,\n",
       "  2810,\n",
       "  1997,\n",
       "  1037,\n",
       "  2047,\n",
       "  4322,\n",
       "  1010,\n",
       "  1996,\n",
       "  2565,\n",
       "  2837,\n",
       "  26021,\n",
       "  2115,\n",
       "  4651,\n",
       "  2000,\n",
       "  2019,\n",
       "  5145,\n",
       "  2006,\n",
       "  1996,\n",
       "  8240,\n",
       "  1012,\n",
       "  1000,\n",
       "  10439,\n",
       "  1012,\n",
       "  1021,\n",
       "  1011,\n",
       "  1022,\n",
       "  1012,\n",
       "  9964,\n",
       "  2121,\n",
       "  19330,\n",
       "  5714,\n",
       "  1010,\n",
       "  2004,\n",
       "  8911,\n",
       "  1010,\n",
       "  3970,\n",
       "  1996,\n",
       "  2837,\n",
       "  1005,\n",
       "  1055,\n",
       "  12832,\n",
       "  1010,\n",
       "  1998,\n",
       "  1037,\n",
       "  2261,\n",
       "  2420,\n",
       "  2101,\n",
       "  6869,\n",
       "  4765,\n",
       "  2001,\n",
       "  4015,\n",
       "  2000,\n",
       "  1042,\n",
       "  27896,\n",
       "  5358,\n",
       "  2110,\n",
       "  3827,\n",
       "  1999,\n",
       "  2662,\n",
       "  1012,\n",
       "  1038,\n",
       "  3627,\n",
       "  4921,\n",
       "  1997,\n",
       "  1996,\n",
       "  26215,\n",
       "  3513,\n",
       "  1998,\n",
       "  7040,\n",
       "  1997,\n",
       "  1996,\n",
       "  20983,\n",
       "  2407,\n",
       "  1010,\n",
       "  2533,\n",
       "  1997,\n",
       "  2591,\n",
       "  2578,\n",
       "  1998,\n",
       "  3847,\n",
       "  1010,\n",
       "  2110,\n",
       "  1997,\n",
       "  7359,\n",
       "  1010,\n",
       "  4844,\n",
       "  1999,\n",
       "  2238,\n",
       "  3299,\n",
       "  1010,\n",
       "  28667,\n",
       "  7616,\n",
       "  2008,\n",
       "  1996,\n",
       "  24467,\n",
       "  5579,\n",
       "  2832,\n",
       "  2003,\n",
       "  2025,\n",
       "  4986,\n",
       "  2007,\n",
       "  7750,\n",
       "  1012,\n",
       "  2738,\n",
       "  1010,\n",
       "  2009,\n",
       "  2003,\n",
       "  3832,\n",
       "  2000,\n",
       "  5326,\n",
       "  1996,\n",
       "  2190,\n",
       "  5426,\n",
       "  1008,\n",
       "  22431,\n",
       "  1997,\n",
       "  1996,\n",
       "  24467,\n",
       "  1010,\n",
       "  1996,\n",
       "  2110,\n",
       "  1010,\n",
       "  1998,\n",
       "  1996,\n",
       "  3827,\n",
       "  2451,\n",
       "  1012,\n",
       "  1031,\n",
       "  1015,\n",
       "  1033,\n",
       "  20423,\n",
       "  1017,\n",
       "  1997,\n",
       "  3627,\n",
       "  4921,\n",
       "  5942,\n",
       "  1037,\n",
       "  4994,\n",
       "  3188,\n",
       "  2000,\n",
       "  1037,\n",
       "  3827,\n",
       "  4651,\n",
       "  5994,\n",
       "  1000,\n",
       "  1037,\n",
       "  24665,\n",
       "  2666,\n",
       "  6767,\n",
       "  2271,\n",
       "  3279,\n",
       "  2000,\n",
       "  1996,\n",
       "  24467,\n",
       "  1010,\n",
       "  1000,\n",
       "  2029,\n",
       "  1996,\n",
       "  3627,\n",
       "  11859,\n",
       "  1000,\n",
       "  3227,\n",
       "  1000,\n",
       "  2004,\n",
       "  1000,\n",
       "  1037,\n",
       "  3809,\n",
       "  3279,\n",
       "  2000,\n",
       "  1037,\n",
       "  9608,\n",
       "  2158,\n",
       "  1012,\n",
       "  1000,\n",
       "  10439,\n",
       "  1012,\n",
       "  2538,\n",
       "  1012,\n",
       "  1031,\n",
       "  1016,\n",
       "  1033,\n",
       "  1996,\n",
       "  8911,\n",
       "  1010,\n",
       "  2104,\n",
       "  1086,\n",
       "  1016,\n",
       "  1997,\n",
       "  1996,\n",
       "  3627,\n",
       "  1010,\n",
       "  2003,\n",
       "  3223,\n",
       "  2000,\n",
       "  5323,\n",
       "  1000,\n",
       "  2019,\n",
       "  17727,\n",
       "  8445,\n",
       "  4818,\n",
       "  2565,\n",
       "  2837,\n",
       "  1000,\n",
       "  2000,\n",
       "  6204,\n",
       "  2107,\n",
       "  1037,\n",
       "  4994,\n",
       "  1010,\n",
       "  1996,\n",
       "  2837,\n",
       "  2000,\n",
       "  2022,\n",
       "  1000,\n",
       "  3605,\n",
       "  1997,\n",
       "  2012,\n",
       "  2560,\n",
       "  2093,\n",
       "  2372,\n",
       "  2040,\n",
       "  2020,\n",
       "  2025,\n",
       "  8851,\n",
       "  2920,\n",
       "  1999,\n",
       "  1996,\n",
       "  2832,\n",
       "  2011,\n",
       "  2029,\n",
       "  1996,\n",
       "  24467,\n",
       "  1012,\n",
       "  1012,\n",
       "  1012,\n",
       "  2001,\n",
       "  2716,\n",
       "  2077,\n",
       "  1996,\n",
       "  2837,\n",
       "  1012,\n",
       "  1000,\n",
       "  10439,\n",
       "  1012,\n",
       "  2322,\n",
       "  1012,\n",
       "  2104,\n",
       "  1086,\n",
       "  1017,\n",
       "  1010,\n",
       "  1996,\n",
       "  2837,\n",
       "  2442,\n",
       "  2507,\n",
       "  1996,\n",
       "  24467,\n",
       "  2517,\n",
       "  5060,\n",
       "  1997,\n",
       "  1996,\n",
       "  4994,\n",
       "  1010,\n",
       "  9146,\n",
       "  2032,\n",
       "  1010,\n",
       "  2007,\n",
       "  3056,\n",
       "  3090,\n",
       "  11790,\n",
       "  1010,\n",
       "  2000,\n",
       "  14323,\n",
       "  1998,\n",
       "  2892,\n",
       "  1011,\n",
       "  11628,\n",
       "  9390,\n",
       "  1010,\n",
       "  8984,\n",
       "  2032,\n",
       "  2019,\n",
       "  4495,\n",
       "  2000,\n",
       "  2022,\n",
       "  2657,\n",
       "  1010,\n",
       "  1998,\n",
       "  10439,\n",
       "  29346,\n",
       "  2032,\n",
       "  1997,\n",
       "  1996,\n",
       "  2837,\n",
       "  1005,\n",
       "  1055,\n",
       "  9556,\n",
       "  1012,\n",
       "  10439,\n",
       "  1012,\n",
       "  2538,\n",
       "  1011,\n",
       "  2484,\n",
       "  1012,\n",
       "  1031,\n",
       "  1017,\n",
       "  1033,\n",
       "  1996,\n",
       "  2837,\n",
       "  2003,\n",
       "  2856,\n",
       "  2000,\n",
       "  2191,\n",
       "  1037,\n",
       "  12832,\n",
       "  2000,\n",
       "  1996,\n",
       "  8911,\n",
       "  1010,\n",
       "  2040,\n",
       "  2059,\n",
       "  7288,\n",
       "  2054,\n",
       "  2895,\n",
       "  2000,\n",
       "  2202,\n",
       "  1024,\n",
       "  1000,\n",
       "  1031,\n",
       "  1996,\n",
       "  8911,\n",
       "  1033,\n",
       "  2089,\n",
       "  1010,\n",
       "  2004,\n",
       "  1996,\n",
       "  2345,\n",
       "  3247,\n",
       "  8571,\n",
       "  1024,\n",
       "  1000,\n",
       "  1006,\n",
       "  1037,\n",
       "  1007,\n",
       "  21358,\n",
       "  27972,\n",
       "  2030,\n",
       "  7901,\n",
       "  1010,\n",
       "  1999,\n",
       "  2878,\n",
       "  2030,\n",
       "  1999,\n",
       "  2112,\n",
       "  1010,\n",
       "  1996,\n",
       "  12832,\n",
       "  1025,\n",
       "  2030,\n",
       "  1000,\n",
       "  1006,\n",
       "  1038,\n",
       "  1007,\n",
       "  2907,\n",
       "  1999,\n",
       "  14863,\n",
       "  7054,\n",
       "  3401,\n",
       "  2151,\n",
       "  2895,\n",
       "  2002,\n",
       "  7164,\n",
       "  15333,\n",
       "  29477,\n",
       "  17080,\n",
       "  11254,\n",
       "  1996,\n",
       "  3808,\n",
       "  1010,\n",
       "  3036,\n",
       "  1010,\n",
       "  2030,\n",
       "  7574,\n",
       "  1997,\n",
       "  1996,\n",
       "  3095,\n",
       "  1010,\n",
       "  24467,\n",
       "  1008,\n",
       "  22884,\n",
       "  1012,\n",
       "  1012,\n",
       "  1012,\n",
       "  1010,\n",
       "  2060,\n",
       "  13187,\n",
       "  1012,\n",
       "  1012,\n",
       "  1012,\n",
       "  1010,\n",
       "  5145,\n",
       "  1010,\n",
       "  2030,\n",
       "  2451,\n",
       "  1998,\n",
       "  ...],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  ...]}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenized_dataset = pubmed_dataset_streamed.map(lambda x: tokenizer(x[\"text\"]))\n",
    "next(iter(tokenized_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da923f78",
   "metadata": {},
   "source": [
    "> <font color=\"darkgreen\">💡 To speed up tokenization with streaming you can pass `batched=True`, as we saw in the last section. It will process the examples batch by batch; the default batch size is 1,000 and can be specified with the `batch_size` argument.</font>\n",
    "\n",
    "You can also shuffle a streamed dataset using `IterableDataset.shuffle()`, but unlike `Dataset.shuffle()` this only shuffles the elements in a predefined `buffer_size`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cf47ea51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "  'case_ID': '127009.json',\n",
       "  'date_created': '2010-04-28T17:22:54Z'},\n",
       " 'text': '537 U.S. 1176\\nMONTUEv.CALIFORNIA DEPARTMENT OF CORRECTIONS.\\nNo. 02-7879.\\nSupreme Court of United States.\\nJanuary 27, 2003.\\n\\n1\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT.\\n\\n\\n2\\nC. A. 9th Cir. Certiorari denied. Reported below: 48 Fed. Appx. 654.\\n\\n'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_dataset = pubmed_dataset_streamed.shuffle(buffer_size=10_000, seed=42)\n",
    "next(iter(shuffled_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd502e",
   "metadata": {},
   "source": [
    "In this example, we selected a random example from the first 10,000 examples in the buffer. Once an example is accessed, its spot in the buffer is filled with the next example in the corpus (i.e., the 10,001st example in the case above). You can also select elements from a streamed dataset using the `IterableDataset.take()` and `IterableDataset.skip()` functions, which act in a similar way to `Dataset.select()`. For example, to select the first 5 examples in the PubMed Abstracts dataset we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6dcebd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "   'case_ID': '110921.json',\n",
       "   'date_created': '2010-04-28T17:12:49Z'},\n",
       "  'text': '\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General.\\nRobert Gilbert Johnston argued the cause for respondent. With him on the brief was Clayton C. Ikei.[*]\\n*240 JUSTICE BLACKMUN delivered the opinion of the Court.\\nThe issue in this case is whether the transfer of a prisoner from a state prison in Hawaii to one in California implicates a liberty interest within the meaning of the Due Process Clause of the Fourteenth Amendment.\\n\\nI\\n\\nA\\nRespondent Delbert Kaahanui Wakinekona is serving a sentence of life imprisonment without the possibility of parole as a result of his murder conviction in a Hawaii state court. He also is serving sentences for various other crimes, including rape, robbery, and escape. At the Hawaii State Prison outside Honolulu, respondent was classified as a maximum security risk and placed in the maximum control unit.\\nPetitioner Antone Olim is the Administrator of the Hawaii State Prison. The other petitioners constituted a prison \"Program Committee.\" On August 2, 1976, the Committee held hearings to determine the reasons for a breakdown in discipline and the failure of certain programs within the prison\\'s maximum control unit. Inmates of the unit appeared at these hearings. The Committee singled out respondent and another inmate as troublemakers. On August 5, respondent received notice that the Committee, at a hearing to be held on August 10, would review his correctional program to determine whether his classification within the system should be changed and whether he should be transferred to another Hawaii facility or to a mainland institution.\\n*241 The August 10 hearing was conducted by the same persons who had presided over the hearings on August 2. Respondent retained counsel to represent him. The Committee recommended that respondent\\'s classification as a maximum security risk be continued and that he be transferred to a prison on the mainland. He received the following explanation from the Committee:\\n\"The Program Committee, having reviewed your entire file, your testimony and arguments by your counsel, concluded that your control classification remains at Maximum. You are still considered a security risk in view of your escapes and subsequent convictions for serious felonies. The Committee noted the progress you made in vocational training and your expressed desire to continue in this endeavor. However your relationship with staff, who reported that you threaten and intimidate them, raises grave concerns regarding your potential for further disruptive and violent behavior. Since there is no other Maximum security prison in Hawaii which can offer you the correctional programs you require and you cannot remain at [the maximum control unit] because of impending construction of a new facility, the Program Committee recommends your transfer to an institution on the mainland.\" App. 7-8.\\nPetitioner Olim, as Administrator, accepted the Committee\\'s recommendation, and a few days later respondent was transferred to Folsom State Prison in California.\\n\\nB\\nRule IV of the Supplementary Rules and Regulations of the Corrections Division, Department of Social Services and Housing, State of Hawaii, approved in June 1976, recites that the inmate classification process is not concerned with punishment. Rather, it is intended to promote the best interests *242 of the inmate, the State, and the prison community.[1] Paragraph 3 of Rule IV requires a hearing prior to a prison transfer involving \"a grievous loss to the inmate,\" which the Rule defines \"generally\" as \"a serious loss to a reasonable man.\" App. 21.[2] The Administrator, under ¶ 2 of the Rule, is required to establish \"an impartial Program Committee\" to conduct such a hearing, the Committee to be \"composed of at least three members who were not actively involved in the process by which the inmate . . . was brought before the Committee.\" App. 20. Under ¶ 3, the Committee must give the inmate written notice of the hearing, permit him, with certain stated exceptions, to confront and cross-examine witnesses, afford him an opportunity to be heard, and apprise him of the Committee\\'s findings. App. 21-24.[3]\\nThe Committee is directed to make a recommendation to the Administrator, who then decides what action to take:\\n\"[The Administrator] may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate *243. . . , other inmates . . . , institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" Rule IV, ¶ 3d(3), App. 24.\\nThe regulations contain no standards governing the Administrator\\'s exercise of his discretion. See Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981).\\n\\nC\\nRespondent filed suit under 42 U. S. C. § 1983 against petitioners as the state officials who caused his transfer. He alleged that he had been denied procedural due process because the Committee that recommended his transfer consisted of the same persons who had initiated the hearing, this being in specific violation of Rule IV, ¶ 2, and because the Committee was biased against him. The United States District Court for the District of Hawaii dismissed the complaint, holding that the Hawaii regulations governing prison transfers do not create a substantive liberty interest protected by the Due Process Clause. 459 F. Supp. 473 (1978).[4]\\nThe United States Court of Appeals for the Ninth Circuit, by a divided vote, reversed. 664 F. 2d 708 (1981). It held that Hawaii had created a constitutionally protected liberty interest by promulgating Rule IV. In so doing, the court declined to follow cases from other Courts of Appeals holding that certain procedures mandated by prison transfer regulations do not create a liberty interest. See, e. g., Cofone v. Manson, 594 F. 2d 934 (CA2 1979); Lombardo v. Meachum, 548 F. 2d 13 (CA1 1977). The court reasoned that Rule IV gives Hawaii prisoners a justifiable expectation that they will not be transferred to the mainland absent a hearing, before an impartial committee, concerning the facts alleged in the *244 prehearing notice.[5] Because the Court of Appeals\\' decision created a conflict among the Circuits, and because the case presents the further question whether the Due Process Clause in and of itself protects against interstate prison transfers, we granted certiorari. 456 U. S. 1005 (1982).\\n\\nII\\nIn Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236 (1976), this Court held that an intrastate prison transfer does not directly implicate the Due Process Clause of the Fourteenth Amendment. In Meachum, inmates at a Massachusetts medium security prison had been transferred to a maximum security prison in that Commonwealth. In Montanye, a companion case, an inmate had been transferred from one maximum security New York prison to another as punishment for a breach of prison rules. This Court rejected \"the notion that any grievous loss visited upon a person by the State is sufficient to invoke the procedural protections of the Due Process Clause.\" Meachum, 427 U. S., at 224 (emphasis in original). It went on to state:\\n\"The initial decision to assign the convict to a particular institution is not subject to audit under the Due Process Clause, although the degree of confinement in one prison may be quite different from that in another. The conviction has sufficiently extinguished the defendant\\'s liberty *245 interest to empower the State to confine him in any of its prisons.\\n\"Neither, in our view, does the Due Process Clause in and of itself protect a duly convicted prisoner against transfer from one institution to another within the state prison system. Confinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Id., at 224-225 (emphasis in original).\\nThe Court observed that, although prisoners retain a residuum of liberty, see Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974), a holding that \"any substantial deprivation imposed by prison authorities triggers the procedural protections of the Due Process Clause would subject to judicial review a wide spectrum of discretionary actions that traditionally have been the business of prison administrators rather than of the federal courts.\" 427 U. S., at 225 (emphasis in original).\\nApplying the Meachum and Montanye principles in Vitek v. Jones, 445 U. S. 480 (1980), this Court held that the transfer of an inmate from a prison to a mental hospital did implicate a liberty interest. Placement in the mental hospital was \"not within the range of conditions of confinement to which a prison sentence subjects an individual,\" because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" Id., at 493. Respondent argues that the same is true of confinement of a Hawaii prisoner on the mainland, and that Vitek therefore controls.\\nWe do not agree. Just as an inmate has no justifiable expectation that he will be incarcerated in any particular prison within a State, he has no justifiable expectation that he will be incarcerated in any particular State.[6] Often, confinement *246 in the inmate\\'s home State will not be possible. A person convicted of a federal crime in a State without a federal correctional facility usually will serve his sentence in another State. Overcrowding and the need to separate particular prisoners may necessitate interstate transfers. For any number of reasons, a State may lack prison facilities capable of providing appropriate correctional programs for all offenders.\\nStatutes and interstate agreements recognize that, from time to time, it is necessary to transfer inmates to prisons in other States. On the federal level, 18 U. S. C. § 5003(a) authorizes the Attorney General to contract with a State for the transfer of a state prisoner to a federal prison, whether in that State or another. See Howe v. Smith, 452 U. S. 473 (1981).[7] Title 18 U. S. C. § 4002 (1976 ed. and Supp. V) permits the Attorney General to contract with any State for the placement of a federal prisoner in state custody for up to three years. Neither statute requires that the prisoner remain in the State in which he was convicted and sentenced.\\nOn the state level, many States have statutes providing for the transfer of a state prisoner to a federal prison, e. g., Haw. Rev. Stat. § 353-18 (1976), or another State\\'s prison, e. g., Alaska Stat. Ann. § 33.30.100 (1982). Corrections compacts between States, implemented by statutes, authorize incarceration of a prisoner of one State in another State\\'s prison. See, e. g., Cal. Penal Code Ann. § 11189 (West 1982) (codifying Interstate Corrections Compact); § 11190 (codifying Western Interstate Corrections Compact); Conn. Gen. *247 Stat. § 18-102 (1981) (codifying New England Interstate Corrections Compact); § 18-106 (codifying Interstate Corrections Compact); Haw. Rev. Stat. § 355-1 (1976) (codifying Western Interstate Corrections Compact); Idaho Code § 20-701 (1979) (codifying Interstate Corrections Compact); Ky. Rev. Stat. § 196.610 (1982) (same). And prison regulations such as Hawaii\\'s Rule IV anticipate that inmates sometimes will be transferred to prisons in other States.\\nIn short, it is neither unreasonable nor unusual for an inmate to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced, or to be transferred to an out-of-state prison after serving a portion of his sentence in his home State. Confinement in another State, unlike confinement in a mental institution, is \"within the normal limits or range of custody which the conviction has authorized the State to impose.\" Meachum, 427 U. S., at 225.[8] Even when, as here, the transfer involves long distances and an ocean crossing, the confinement remains within constitutional limits. The difference between such a transfer and an intrastate or interstate transfer of *248 shorter distance is a matter of degree, not of kind,[9] and Meachum instructs that \"the determining factor is the nature of the interest involved rather than its weight.\" 427 U. S., at 224. The reasoning of Meachum and Montanye compels the conclusion that an interstate prison transfer, including one from Hawaii to California, does not deprive an inmate of any liberty interest protected by the Due Process Clause in and of itself.\\n\\nIII\\nThe Court of Appeals held that Hawaii\\'s prison regulations create a constitutionally protected liberty interest. In Meachum, however, the State had \"conferred no right on the *249 prisoner to remain in the prison to which he was initially assigned, defeasible only upon proof of specific acts of misconduct,\" 427 U. S., at 226, and \"ha[d] not represented that transfers [would] occur only on the occurrence of certain events,\" id., at 228. Because the State had retained \"discretion to transfer [the prisoner] for whatever reason or for no reason at all,\" ibid., the Court found that the State had not created a constitutionally protected liberty interest. Similarly, because the state law at issue in Montanye \"impose[d] no conditions on the discretionary power to transfer,\" 427 U. S., at 243, there was no basis for invoking the protections of the Due Process Clause.\\nThese cases demonstrate that a State creates a protected liberty interest by placing substantive limitations on official discretion. An inmate must show \"that particularized standards or criteria guide the State\\'s decisionmakers.\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 467 (1981) (BRENNAN, J., concurring). If the decisionmaker is not \"required to base its decisions on objective and defined criteria,\" but instead \"can deny the requested relief for any constitutionally permissible reason or for no reason at all,\" ibid., the State has not created a constitutionally protected liberty interest. See id., at 466-467 (opinion of the Court); see also Vitek v. Jones, 445 U. S., at 488-491 (summarizing cases).\\nHawaii\\'s prison regulations place no substantive limitations on official discretion and thus create no liberty interest entitled to protection under the Due Process Clause. As Rule IV itself makes clear, and as the Supreme Court of Hawaii has held in Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981, the prison Administrator\\'s discretion to transfer an inmate is completely unfettered. No standards govern or restrict the Administrator\\'s determination. Because the Administrator is the only decisionmaker under Rule IV, we need not decide whether the introductory paragraph *250 of Rule IV, see n. 1, supra, places any substantive limitations on the purely advisory Program Committee.[10]\\nThe Court of Appeals thus erred in attributing significance to the fact that the prison regulations require a particular kind of hearing before the Administrator can exercise his unfettered discretion.[11] As the United States Court of Appeals for the Seventh Circuit recently stated in Shango v. Jurich, 681 F. 2d 1091, 1100-1101 (1982), \"[a] liberty interest is of course a substantive interest of an individual; it cannot be the right to demand needless formality.\"[12] Process is not an end in itself. Its constitutional purpose is to protect a substantive interest to which the individual has a legitimate claim of entitlement. See generally Simon, Liberty and Property in the Supreme Court: A Defense of Roth and Perry, 71 Calif. L. Rev. 146, 186 (1983). If officials may transfer a prisoner \"for whatever reason or for no reason at all,\" Meachum, 427 U. S., at 228, there is no such interest for process to protect. The State may choose to require procedures for reasons other than protection against deprivation of substantive *251 rights, of course,[13] but in making that choice the State does not create an independent substantive right. See Hewitt v. Helms, 459 U. S. 460, 471 (1983).\\n\\nIV\\nIn sum, we hold that the transfer of respondent from Hawaii to California did not implicate the Due Process Clause directly, and that Hawaii\\'s prison regulations do not create a protected liberty interest.[14] Accordingly, the judgment of the Court of Appeals is\\nReversed.\\nJUSTICE MARSHALL, with whom JUSTICE BRENNAN joins, and with whom JUSTICE STEVENS joins as to Part I, dissenting.\\nIn my view, the transfer of respondent Delbert Kaahanui Wakinekona from a prison in Hawaii to a prison in California implicated an interest in liberty protected by the Due Process Clause of the Fourteenth Amendment. I respectfully dissent.\\n\\nI\\nAn inmate\\'s liberty interest is not limited to whatever a State chooses to bestow upon him. An inmate retains a significant residuum of constitutionally protected liberty following his incarceration independent of any state law. As we stated in Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974): \"[A] prisoner is not wholly stripped of constitutional protections when he is imprisoned for crime. There is no iron curtain drawn between the Constitution and the prisons *252 of this country. . . . [Prisoners] may not be deprived of life, liberty, or property without due process of law.\"\\nIn determining whether a change in the conditions of imprisonment implicates a prisoner\\'s retained liberty interest, the relevant question is whether the change constitutes a sufficiently \"grievous loss\" to trigger the protection of due process. Vitek v. Jones, 445 U. S. 480, 488 (1980). See Morrissey v. Brewer, 408 U. S. 471, 481 (1972), citing Joint Anti-Fascist Refugee Committee v. McGrath, 341 U. S. 123, 168 (1951) (Frankfurter, J., concurring). The answer depends in part on a comparison of \"the treatment of the particular prisoner with the customary, habitual treatment of the population of the prison as a whole.\" Hewitt v. Helms, 459 U. S. 460, 486 (1983) (STEVENS, J., dissenting). This principle was established in our decision in Vitek, which held that the transfer of an inmate from a prison to a mental hospital implicated a liberty interest because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" 445 U. S., at 493. Because a significant qualitative change in the conditions of confinement is not \"within the range of conditions of confinement to which a prison sentence subjects an individual,\" ibid., such a change implicates a prisoner\\'s protected liberty interest.\\nThere can be little doubt that the transfer of Wakinekona from a Hawaii prison to a prison in California represents a substantial qualitative change in the conditions of his confinement. In addition to being incarcerated, which is the ordinary consequence of a criminal conviction and sentence, Wakinekona has in effect been banished from his home, a punishment historically considered to be \"among the severest.\"[1] For an indeterminate period of time, possibly the *253 rest of his life, nearly 2,500 miles of ocean will separate him from his family and friends. As a practical matter, Wakinekona may be entirely cut off from his only contacts with the outside world, just as if he had been imprisoned in an institution which prohibited visits by outsiders. Surely the isolation imposed on him by the transfer is far more drastic than that which normally accompanies imprisonment.\\nI cannot agree with the Court that Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236, 243 (1976), compel the conclusion that Wakinekona\\'s transfer implicates no liberty interest. Ante, at 248. Both cases involved transfers of prisoners between institutions located within the same State in which they were convicted, and the Court expressly phrased its holdings in terms of intrastate transfers.[2] Both decisions rested on the premise that no liberty interest is implicated by an initial decision to place a prisoner in one institution in the State rather than another. See Meachum, supra, at 224; Montanye, supra, at 243. On the basis of that premise, the Court concluded that the subsequent transfer of a prisoner to a different facility within the State likewise implicates no liberty interest. In this case, however, we cannot assume that a State\\'s initial placement of an individual in a prison far removed from his family and residence would raise no due process questions. None of our *254 prior decisions has indicated that such a decision would be immune from scrutiny under the Due Process Clause.\\nActual experience simply does not bear out the Court\\'s assumptions that interstate transfers are routine and that it is \"not unusual\" for a prisoner \"to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced.\" Ante, at 247. In Hawaii less than three percent of the state prisoners were transferred to prisons in other jurisdictions in 1979, and on a nationwide basis less than one percent of the prisoners held in state institutions were transferred to other jurisdictions.[3] Moreover, the vast majority of state prisoners are held in facilities located less than 250 miles from their homes.[4] Measured against these norms, Wakinekona\\'s transfer to a California prison represents a punishment \"qualitively different from the punishment characteristically suffered by a person convicted of crime.\" Vitek v. Jones, supra, at 493.\\nI therefore cannot agree that a State may transfer its prisoners at will, to any place, for any reason, without ever implicating any interest in liberty protected by the Due Process Clause.\\n\\nII\\nNor can I agree with the majority\\'s conclusion that Hawaii\\'s prison regulations do not create a liberty interest. This Court\\'s prior decisions establish that a liberty interest *255 may be \"created\"[5] by state laws, prison rules, regulations, or practices. State laws that impose substantive criteria which limit or guide the discretion of officials have been held to create a protected liberty interest. See, e. g., Hewitt v. Helms, 459 U. S. 460 (1983); Wolff v. McDonnell, 418 U. S. 539 (1974); Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979); Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). By contrast, a liberty interest is not created by a law which \"imposes no conditions on [prison officials\\'] discretionary power,\" Montanye, supra, at 243, authorizes prison officials to act \"for whatever reason or for no reason at all,\" Meachum, supra, at 228, or accords officials \"unfettered discretion,\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 466 (1981).\\nThe Court misapplies these principles in concluding that Hawaii\\'s prison regulations leave prison officials with unfettered discretion to transfer inmates. Ante, at 249-250. Rule IV establishes a scheme under which inmates are classified upon initial placement in an institution, and must subsequently be reclassified before they can be transferred to another institution. Under the Rule the standard for classifying inmates is their \"optimum placement within the Corrections Division\" in light of the \"best interests of the individual, the State, and the community.\"[6] In classifying inmates, the Program *256 Committee may not consider punitive aims. It may consider only factors relevant to determining where the individual will be \"best situated,\" such as \"his history, his changing needs, the resources and facilities available to the Corrections Divisions, the other inmates/wards, the exigencies of the community, and any other relevant factors.\" Paragraph 3 of Rule IV establishes a detailed set of procedures applicable when, as in this case, the reclassification of a prisoner may lead to a transfer involving a \"grievous loss,\" a phrase contained in the Rule itself.[7] The procedural rules are cast in mandatory language, and cover such matters as notice, access to information, hearing, confrontation and cross-examination, and the basis on which the Committee is to make its recommendation to the facility administrator.\\nThe limitations imposed by Rule IV are at least as substantial as those found sufficient to create a liberty interest in Hewitt v. Helms, supra, decided earlier this Term. In Hewitt an inmate contended that his confinement in administrative custody implicated an interest in liberty protected by the Due Process Clause. State law provided that a prison official could place inmates in administrative custody \"upon his assessment of the situation and the need for control,\" or \"where it has been determined that there is a threat of a serious disturbance, or a serious threat to the individual or others,\" and mandated certain procedures such as notice and a *257 hearing.[8] This Court construed the phrases \" `the need for control,\\' or `the threat of a serious disturbance,\\' \" as \"substantive predicates\" which restricted official discretion. Id., at 472. These restrictions, in combination with the mandatory procedural safeguards, \"deman[ded] a conclusion that the State has created a protected liberty interest.\" Ibid.\\nRule IV is not distinguishable in any meaningful respect from the provisions at issue in Helms. The procedural requirements contained in Rule IV are, if anything, far more elaborate than those involved in Helms, and are likewise couched in \"language of an unmistakably mandatory character.\" Id., at 471. Moreover, Rule IV, to no less an extent than the state law at issue in Helms, imposes substantive criteria restricting official discretion. In Helms this Court held that a statutory phrase such as \"the need for control\" constituted a limitation on the discretion of prison officials to place inmates in administrative custody. In my view Rule IV, which states that transfers are intended to ensure an inmate\\'s \"optimum placement\" in accordance with considerations which include \"his changing needs [and] the resources and facilities available to the Corrections Division,\" also restricts official discretion in ordering transfers.[9]\\nThe Court suggests that, even if the Program Committee does not have unlimited discretion in making recommendations for classifications and transfers, this cannot give rise to a state-created liberty interest because the prison Administrator retains \"completely unfettered\" \"discretion to transfer *258 an inmate,\" ante, at 249. I disagree. Rule IV, ¶ 3(d)(3), provides for review by the prison Administrator of recommendations forwarded to him by the Program Committee.[10] Even if this provision must be construed as authorizing the Administrator to transfer a prisoner for wholly arbitrary reasons,[11] that mere possibility does not defeat the protectible expectation otherwise created by Hawaii\\'s reclassification and transfer scheme that transfers will take place only if required to ensure an inmate\\'s optimum placement. In Helms a prison regulation also left open the possibility that the Superintendent could decide, for any reason or no reason at all, whether an inmate should be confined in administrative custody.[12] This Court nevertheless held that the state scheme as a whole created an interest in liberty protected by the Due Process Clause. 459 U. S., at 471-472. Helms thus necessarily rejects the view that state laws which impose substantive *259 limitations and elaborate procedural requirements on official conduct create no liberty interest solely because there remains the possibility that an official will act in an arbitrary manner at the end of the process.[13]\\nFor the foregoing reasons, I dissent.\\nNOTES\\n[*]  Briefs of amici curiae urging reversal were filed for the State of Alaska et al. by Paul L. Douglas, Attorney General of Nebraska, J. Kirk Brown, Assistant Attorney General, Judith W. Rogers, Corporation Counsel of the District of Columbia, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William J. Guste, Jr., of Louisiana, William A. Allain of Mississippi, Michael T. Greely of Montana, Richard H. Bryan of Nevada, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Gerald L. Baliles of Virginia, Kenneth O. Eikenberry of Washington, Chauncey H. Browning of West Virginia, Bronson C. La Follette of Wisconsin, and Steven F. Freudenthal of Wyoming; and for the Commonwealth of Massachusetts et al. by Francis X. Bellotti, Attorney General of Massachusetts, Stephen R. Delinsky, Barbara A. H. Smith, and Leo J. Cushing, Assistant Attorneys General, Anthony Ching, Solicitor General of Arizona, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William A. Allain of Mississippi, Michael T. Greely of Montana, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert O. Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Chauncey H. Browning of West Virginia, and Bronson C. La Follette of Wisconsin.\\n[1]  Paragraph 1 of Rule IV states:\\n\\n\"An inmate\\'s . . . classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates . . . , the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[2]  Petitioners concede, \"for purposes of the argument,\" that respondent suffered a \"grievous loss\" within the meaning of Rule IV when he was transferred from Hawaii to the mainland. Tr. of Oral Arg. 9, 25.\\n[3]  Rule V provides that an inmate may retain legal counsel if his hearing concerns a \"potential Interstate transfer.\" App. 25.\\n[4]  Respondent also had alleged that the transfer violated the Hawaii Constitution and state regulations and statutes. In light of its dismissal of respondent\\'s federal claims, the District Court declined to exercise pendent jurisdiction over these state-law claims. 459 F. Supp., at 476.\\n[5]  Several months before the Court of Appeals handed down its decision, the Supreme Court of Hawaii had held that because Hawaii\\'s prison regulations do not limit the Administrator\\'s discretion to transfer prisoners to the mainland, they do not create any liberty interest. Lono v. Ariyoshi, 63 Haw. 138, 621 P. 2d 976 (1981). In a petition for rehearing in the present case, petitioners directed the Ninth Circuit\\'s attention to the Lono decision. See 664 F. 2d, at 714. The Court of Appeals, however, concluded that the Hawaii court\\'s interpretation of the regulations was not different from its own; the Hawaii court merely had reached a different result on the \"federal question.\" The Court of Appeals thus adhered to its resolution of the case. Id., at 714-715.\\n[6]  Indeed, in Vitek itself the Court did not read Meachum and Montanye as stating a rule applicable only to intrastate transfers. The Court stated: \"In Meachum v. Fano . . . and Montanye v. Haymes . . . we held that the transfer of a prisoner from one prison to another does not infringe a protected liberty interest.\" 445 U. S., at 489 (emphasis added). The Court\\'s other cases describing Meachum and Montanye also have eschewed the narrow reading respondent now proposes. See Hewitt v. Helms, 459 U. S. 460, 467-468 (1983); Moody v. Daggett, 429 U. S. 78, 88, n. 9 (1976).\\n[7]  This statute has been invoked to transfer prisoners from Hawaii state facilities to federal prisons on the mainland. See Anthony v. Wilkinson, 637 F. 2d 1130 (CA7 1980), vacated and remanded sub nom. Hawaii v. Mederios, 453 U. S. 902 (1981).\\n[8]  After the decisions in Meachum and Montanye, courts almost uniformly have held that an inmate has no entitlement to remain in a prison in his home State. See Beshaw v. Fenton, 635 F. 2d 239, 246-247 (CA3 1980), cert. denied, 453 U. S. 912 (1981); Cofone v. Manson, 594 F. 2d 934, 937, n. 4 (CA2 1979); Sisbarro v. Warden, 592 F. 2d 1, 3 (CA1), cert. denied, 444 U. S. 849 (1979); Fletcher v. Warden, 467 F. Supp. 777, 779-780 (Kan. 1979); Curry-Bey v. Jackson, 422 F. Supp. 926, 931-933 (DC 1976); McDonnell v. United States Attorney General, 420 F. Supp. 217, 220 (ED Ill. 1976); Goodnow v. Perrin, 120 N. H. 669, 671, 421 A. 2d 1008, 1010 (1980); Girouard v. Hogan, 135 Vt. 448, 449-450, 378 A. 2d 105, 106-107 (1977); In re Young, 95 Wash. 2d 216, 227-228, 622 P. 2d 373, 379 (1980); cf. Fajeriak v. McGinnis, 493 F. 2d 468 (CA9 1974) (pre-Meachum transfers from Alaska to other States); Hillen v. Director of Department of Social Services, 455 F. 2d 510 (CA9), cert. denied, 409 U. S. 989 (1972) (pre-Meachum transfer from Hawaii to California). But see In re Young, 95 Wash. 2d, at 233, 622 P. 2d, at 382 (concurring opinion); State ex rel. Olson v. Maxwell, 259 N. W. 2d 621 (N. D. 1977); cf. Tai v. Thompson, 387 F. Supp. 912 (Haw. 1975) (pre-Meachum transfer).\\n[9]  Respondent\\'s argument to the contrary is unpersuasive. The Court in Montanye took note that among the hardships that may result from a prison transfer are separation of the inmate from home and family, separation from inmate friends, placement in a new and possibly hostile environment, difficulty in making contact with counsel, and interruption of educational and rehabilitative programs. 427 U. S., at 241, n. 4. These are the same hardships respondent faces as a result of his transfer from Hawaii to California.\\n\\nRespondent attempts to analogize his transfer to banishment in the English sense of \"beyond the seas,\" arguing that banishment surely is not within the range of confinement justified by his sentence. But respondent in no sense has been banished; his conviction, not the transfer, deprived him of his right freely to inhabit the State. The fact that his confinement takes place outside Hawaii is merely a fortuitous consequence of the fact that he must be confined, not an additional element of his punishment. See Girouard v. Hogan, 135 Vt., at 449-450, 378 A. 2d, at 106-107. Moreover, respondent has not been exiled; he remains within the United States.\\nIn essence, respondent\\'s banishment argument simply restates his claim that a transfer from Hawaii to the mainland is different in kind from other transfers. As has been shown in the text, however, respondent\\'s transfer was authorized by his conviction. A conviction, whether in Hawaii, Alaska, or one of the contiguous 48 States, empowers the State to confine the inmate in any penal institution in any State unless there is state law to the contrary or the reason for confining the inmate in a particular institution is itself constitutionally impermissible. See Montanye, 427 U. S., at 242; id., at 244 (dissenting opinion); Cruz v. Beto, 405 U. S. 319 (1972); Fajeriak v. McGinnis, 493 F. 2d, at 470.\\n[10]  In Hewitt v. Helms, 459 U. S. 460 (1983), unlike this case, state law limited the decisionmakers\\' discretion. To the extent the dissent doubts that the Administrator\\'s discretion under Rule IV is truly unfettered, post, at 258, and n. 11, it doubts the ability or authority of the Hawaii Supreme Court to construe state law.\\n[11]  In Meachum itself, the Court of Appeals had interpreted the applicable regulations as entitling inmates to a pretransfer hearing, see Fano v. Meachum, 520 F. 2d 374, 379-380 (CA1 1975), but this Court held that state law created no liberty interest.\\n[12]  Other courts agree that an expectation of receiving process is not, without more, a liberty interest protected by the Due Process Clause. See, e. g., United States v. Jiles, 658 F. 2d 194, 200 (CA3 1981), cert. denied, 455 U. S. 923 (1982); Bills v. Henderson, 631 F. 2d 1287, 1298-1299 (CA6 1980); Pugliese v. Nelson, 617 F. 2d 916, 924-925 (CA2 1980); Cofone v. Manson, 594 F. 2d, at 938; Lombardo v. Meachum, 548 F. 2d 13, 14-16 (CA1 1977); Adams v. Wainwright, 512 F. Supp. 948, 953 (ND Fla. 1981); Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981.\\n[13]  Petitioners assert that the hearings required by Rule IV not only enable the officials to gather information and thereby to exercise their discretion intelligently, but also have a therapeutic purpose: inmate participation in the decisionmaking process, it is hoped, reduces tension in the prison. See Tr. of Oral Arg. 52-53.\\n[14]  In light of this conclusion, respondent\\'s claim of bias in the composition of the prison Program Committee becomes irrelevant.\\n[1]  4 J. Elliott, Debates on the Federal Constitution 555 (1836). Whether it is called banishment, exile, deportation, relegation, or transportation, compelling a person \"to quit a city, place, or country, for a specified period of time, or for life,\" has long been considered a unique and severe deprivation, and was specifically outlawed by \"[t]he twelfth section of the English Habeas Corpus Act, 31 Car. II, one of the three great muniments of English liberty.\" United States v. Ju Toy, 198 U. S. 253, 269-270 (1905) (Brewer, J., dissenting).\\n[2]  Thus in Meachum the Court stated that the State, by convicting the defendant, was \"empower[ed] to confine him in any of its prisons,\" 427 U. S., at 224 (emphasis deleted), that a \"transfer from one institution to another within the state prison system\" implicated no due process interest, id., at 225, and that \"[c]onfinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Ibid. See also Montanye, 427 U. S., at 242 (\"We held in Meachum v. Fano, that no Due Process Clause liberty interest of a duly convicted prison inmate is infringed when he is transferred from one prison to another within the State\").\\n[3]  U. S. Dept. of Justice, Bureau of Justice Statistics, Sourcebook of Criminal Justice Statistics \\x97 1981, Table 6.27, pp. 478-479 (T. Flanagan, D. Van Alstyne, & M. Gottfredson eds. 1982). These figures reflect \"all inmates who were transferred from one State\\'s jurisdiction to another to continue sentences already in force,\" and \"[d]oes not include the release if [the] State does not relinquish jurisdiction.\" Id., at 590.\\n[4]  U. S. Dept. of Justice, Profile of State Prison Inmates: Sociodemographic Findings from the 1974 Survey of Inmates of State Correctional Facilities 1 (1979). Over 70 percent of state inmates are held in institutions located less than 250 miles from their homes.\\n[5]  But see Hewitt v. Helms, 459 U. S. 460, 488 (1983) (STEVENS, J., dissenting) (Prison regulations \"provide evidentiary support for the conclusion that the transfer affects a constitutionally protected interest in liberty,\" but they \"do not create that interest\" (emphasis in original)).\\n[6]  Paragraph 1 of Rule IV provides:\\n\\n\"An inmate\\'s/ward\\'s classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates/wards, the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[7]  While the term \"grievous loss\" is not explicitly defined, the prison regulations treat a transfer to the mainland as a grievous loss entitling an inmate to the procedural rights established in Rule IV, ¶ 3. This is readily inferred from Rule IV, ¶ 3, which states that intrastate transfers do not involve a grievous loss, and Rule V, which permits inmates to retain counsel only in specified circumstances, one of which is a reclassification that may result in an interstate transfer. App. 25.\\n[8]  See 459 U. S., at 470-471, n. 6.\\n[9]  See also Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). In that case, the District Court held that the language of a prison policy statement, stating that \"[i]nmates may be segregated for medical, psychiatric, disciplinary, or administrative reasons,\" 462 F. Supp., at 403, was sufficient to create a protected expectation that an inmate would not be segregated for arbitrary reasons. See also Bills v. Henderson, 631 F. 2d 1287, 1293 (CA6 1980), cert. denied, 449 U. S. 1093 (1981); Winsett v. McGinnes, 617 F. 2d 996, 107 (CA3 1980) (en banc).\\n[10]  Rule IV, ¶ 3(d)(3), provides:\\n\\n\"The facility administrator will, within a reasonable period of time, review the Program Committee\\'s recommendation. He may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate/ward, other inmates/wards, institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" App. 21.\\n[11]  I doubt that Rule IV would be construed to permit the Administrator to order a transfer for punitive reasons, since Rule IV expressly disallows punitive transfers.\\n[12]  That provision stated: \"All decisions of the Program Review Committee shall be reviewed by the Superintendent for his sustaining the decision or amending or reversing the decision in favor of the inmate.\" Pennsylvania Bureau of Correction Administrative Directive BC-ADM 801, Rule III(H)(7). App. to Brief for Respondent in Hewitt v. Helms, O. T. 1982, No. 81-638, p. 12a. Because an inmate could be confined in administrative custody only if the Program Review Committee determined that such confinement is and continues to be \"appropriate,\" id., at 18a, the Superintendent in Helms was the \"decisionmaker,\" ante, at 249-250, who determined whether inmates would be held in administrative custody.\\n[13]  This view was also implicitly rejected in Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979). The Court held that the Nebraska statute governing the decision whether or not to grant parole created a \"protectible entitlement,\" id., at 12, even though the statute, which listed a number of factors to be considered in the parole decision, also authorized the Parole Board to deny parole on the basis of \"[a]ny other factors the board determines to be relevant.\" Id., at 18.\\n\\nTo the extent that Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981), on which the majority relies, ante, at 249, suggests that no liberty interest is created as state law has not entirely eliminated the possibility of arbitrary action, it is inconsistent with both Helms and Greenholtz.\\n'},\n",
       " {'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "   'case_ID': '129238.json',\n",
       "   'date_created': '2010-04-28T17:26:41Z'},\n",
       "  'text': '538 U.S. 1002\\nBURTONv.DORMIRE, SUPERINTENDENT, JEFFERSON CITY CORRECTIONAL CENTER, ET AL.\\nNo. 02-9170.\\nSupreme Court of United States.\\nApril 28, 2003.\\n\\n1\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE EIGHTH CIRCUIT.\\n\\n\\n2\\nC. A. 8th Cir. Certiorari denied. Reported below: 295 F. 3d 839.\\n\\n'},\n",
       " {'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "   'case_ID': '131217.json',\n",
       "   'date_created': '2010-04-28T17:27:29Z'},\n",
       "  'text': '540 U.S. 808\\nSTRABLEv.STRABLE.\\nNo. 02-9903.\\nSupreme Court of United States.\\nOctober 6, 2003.\\n\\n1\\nAppeal from the Ct. App. S. C.\\n\\n\\n2\\nMotion of petitioner for reconsideration of order denying leave to proceed in forma pauperis [539 U. S. 913] denied.\\n\\n'},\n",
       " {'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "   'case_ID': '86060.json',\n",
       "   'date_created': '2010-04-28T16:00:04Z'},\n",
       "  'text': '37 U.S. 507\\n12 Pet. 507\\n9 L.Ed. 1174\\nPIERRE CHOTEAU, SENIOR, PLAINTIFF IN ERRORv.MARGUERITE, A WOMAN OF COLOUR, DEFENDANT.\\nJanuary Term, 1838\\n\\nERROR to the supreme court of the third judicial district of the state of Missouri.\\nIn 1825, Marguerite, a woman of colour, by her next friend, Pierre Barrebeau, filed a declaration in the circuit court for the county of Jefferson, in the state of Missouri, alleging that Pierre Choteau, sr., had beat and bruised her, and unlawfully detained her in prison, against her will, &c. The object of this proceeding was to establish that the complainant, the descendant of an Indian woman, Marie Scipion, was free, and was unlawfully held as a slave by the defendant.\\nPierre Choteau appeared to the suit, and pleaded that Marguerite was a slave, in his lawful possession, and so detained by him.\\nThe case was submitted to a jury in Jefferson county, and a verdict was found for the plaintiff; which was afterwards set aside by the court, and a new trial ordered. The suit was afterwards tried before the same court, and a verdict was given for the defendant. The plaintiff filed a bill of exceptions; and on a writ of error to the supreme court of Missouri, the judgment of the circuit court was reversed, and the cause was remanded to that court. It was afterwards remanded to the circuit court of St. Charles county, and was there tried again before a jury; and a verdict and judgment were rendered in favor of the plaintiff. The defendant, on the trial, moved the court to instruct the jury:1st. If the jury find, from the evidence, that the mother of Marie Scipion was an Indian woman, of the Natchez nation, taken captive in war by the French; and that she and her descendants were publicly and notoriously held as slaves, in the province of Louisiana, while the same was held by the French, prior to the year 1769; and that she and her descendants were so publicly and notoriously held as slaves, without interruption, in the said province, until the 30th April, 1803, and thence to the time of the commencement of this suit; the jury ought to find for the defendant.\\n2d. If the jury find, from the evidence, that the mother of Marie Scipion was an Indian woman, taken captive in war, and reduced to slavery by the French; and that from the time of her capture she and her descendants were publicly and notoriously held as slaves, in the province of Louisiana, while the same was held by the French, before the year 1769, and afterwards, while the same province was in the possession of, and held by Spain and France, until the 30th day of April, 1803, and thence until the commencement of this suit; they ought to find for the defendant.\\n3d. That Indians taken captive in war by the French, might, lawfully, be reduced and held in slavery in the province of Louisiana; whilst it was held by the crown of France.\\n4th. If the jury find, from the evidence, that the said Marie Scipion was born while her mother was so held in slavery, within the province of Louisiana, while the same was held by the French, prior to the year 1769; that the said mother was held in slavery, in the province of Louisiana, from the time of her birth until the 30th April, 1803, and thence until the time of her death; then the jury ought to find for the defendant.\\n5th. If the jury find, from the evidence, that Marie Scipion was born while her mother was held in slavery, and that she, she said Marie Scipion, was publicly and notoriously held as a slave, from the time of her birth until her death, within the territory ceded to the United States, by the treaty between the United States of America and the French Republic, bearing date the 30th April, 1803, and that, at the date of said treaty, the said Marie Scipion was so held as a slave, within the said ceded territory, by an inhabitant thereof; then the jury ought to find for the defendant.\\nThe court refused to give these instructions: and the defendant sued out a writ of error to the supreme court of Missouri, where the judgment of the circuit court of Jefferson county was affirmed.\\nThe defendant then sued out the writ of error to the Supreme Court of the United States, under the 25th section of the judiciary act of 1789, to the supreme court of Missouri.\\nMr. Butler, for the defendant in error, moved to dismiss the writ of error on the ground that the case is not within the provisions of the 25th section of the judiciary act.\\nHe contended that no question had arisen in the case, in which this Court could be called on to interfere with its revising powers. The plaintiff in error claimed that the treaty of Louisiana, of 30th April, 1803, protected him in his property in the defendant, as she was his slave. The question before the circuit court, and which was submitted to the jury, was, whether the plaintiff was a slave; and the jury found that she was free.\\nUnder the 25th sec. of the judiciary act, the jurisdiction of this Court in writs of error to the supreme courts of the state, prevails in those cases in which a treaty of the United States has been drawn in question, and has been misconstrued; or a statute of the United States has been misconstrued and disregarded.\\nIt has been supposed that this suit is within the class of cases cognizable in the Supreme Court of the United States; as the defendant claimed Marguerite as a slave, under the Louisiana treaty.\\nThe first instruction has no reference to the treaty. The counsel sought to have the instructions of the court, that if the plaintiff was always held as a slave, up to the time of the treaty, she continued such. The court held that she could not be a slave. Whether this opinion was right or not, the construction of the treaty was not drawn in question. The protection of the treaty was not denied; and the decision of the court was such as did not make the case within its provisions. The plaintiff had no property in Marguerite, which the treaty operated upon.\\nBut this Court decided that the general provisions of the ordinance of 1787, could not give to the Supreme Court jurisdiction, where rights of property were asserted to have been violated by the decision of a state court. Menard v. Aspasia, 5 Peters, 525.\\nIn the case of Crowell v. Randall, 10 Peters, 368, there is a review of all the cases on the question of the jurisdiction of this Court, in cases from the highest court of the states of the United States. In that, and in all the other cases, the law is laid down to be, that the appellate jurisdiction of this Court can only be sustained when it appears that the question over which the jurisdiction exists must appear to have been brought before the Court, and decided according to the provisions of the twenty-fifth section; or that by clear and necessary intendment, the question must have arisen and must have been decided.\\nThe very point involved in this case has been decided. In the case of the Mayor of New Orleans v. De Armas, it was held that the protection of the treaty existed, and its provisions were applicable and would be enforced by the courts of the United States, until the territory became a state; afterwards, that protection was given by the constitution and laws of the state. If such a case as this could be entertained, then all questions of property, arising in the states erected in the country acquired by the United States, by the Louisiana treaty, could be brought here; as the guaranty of the treaty applies to all property.\\nMr. Key, with whom was Mr. Benton, opposed the motion. He contended that the decision of this Court, in Crowell v. Randall, 10 Peters, 368, did not in any way enlarge the principles which had prevailed before. All the Court are required to do before they take jurisdiction, is to see that the case is such as presented a question cognizable by the Court. The Court, if its consideration was essential to the decision of the cause, will hold that it did arise, and was decided. He argued that the treaty of Louisiana must have been considered by the supreme court of Louisiana in this case.\\nMr. Justice STORY said that it had been thought that the decisions of the Court had been misunderstood:\\n\\n\\n1\\nand the Court, in the case of Crowell v. Randall, 10 Peters, had revised all the cases; and had laid down the law as they wished it should be universally understood.\\n\\n\\n2\\nThe motion to dismiss the case was sustained.\\n\\n'},\n",
       " {'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "   'case_ID': '143412.json',\n",
       "   'date_created': '2010-04-28T17:54:44Z'},\n",
       "  'text': '544 U.S. 944\\nWALLACEv.PLILER, WARDEN.\\nNo. 04-6897.\\nSupreme Court of United States.\\nMarch 21, 2005.\\n\\n1\\n543 U.S. 1062. Petition for rehearing denied.\\n\\n'}]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_head = pubmed_dataset_streamed.take(5)\n",
    "list(dataset_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21634f5d",
   "metadata": {},
   "source": [
    "Similarly, you can use the `IterableDataset.skip()` function to create training and validation splits from a shuffled dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "78a27d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip the first 1,000 examples and include the rest in the training set\n",
    "train_dataset = shuffled_dataset.skip(1000)\n",
    "# Take the first 1,000 examples for the validation set\n",
    "validation_dataset = shuffled_dataset.take(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e81f9",
   "metadata": {},
   "source": [
    "Let's round out our exploration of dataset streaming with a common application: combining multiple datasets together to create a single corpus. 🤗 Datasets provides an `interleave_datasets()` function that converts a list of `IterableDataset` objects into a single `IterableDataset`, where the elements of the new dataset are obtained by alternating among the source examples. This function is especially useful when you're trying to combine large datasets, so as an example let's stream the FreeLaw subset of the Pile, which is a 51 GB dataset of legal opinions from US courts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a3aeac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ecdac2973eb354f0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "  'case_ID': '110921.json',\n",
       "  'date_created': '2010-04-28T17:12:49Z'},\n",
       " 'text': '\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General.\\nRobert Gilbert Johnston argued the cause for respondent. With him on the brief was Clayton C. Ikei.[*]\\n*240 JUSTICE BLACKMUN delivered the opinion of the Court.\\nThe issue in this case is whether the transfer of a prisoner from a state prison in Hawaii to one in California implicates a liberty interest within the meaning of the Due Process Clause of the Fourteenth Amendment.\\n\\nI\\n\\nA\\nRespondent Delbert Kaahanui Wakinekona is serving a sentence of life imprisonment without the possibility of parole as a result of his murder conviction in a Hawaii state court. He also is serving sentences for various other crimes, including rape, robbery, and escape. At the Hawaii State Prison outside Honolulu, respondent was classified as a maximum security risk and placed in the maximum control unit.\\nPetitioner Antone Olim is the Administrator of the Hawaii State Prison. The other petitioners constituted a prison \"Program Committee.\" On August 2, 1976, the Committee held hearings to determine the reasons for a breakdown in discipline and the failure of certain programs within the prison\\'s maximum control unit. Inmates of the unit appeared at these hearings. The Committee singled out respondent and another inmate as troublemakers. On August 5, respondent received notice that the Committee, at a hearing to be held on August 10, would review his correctional program to determine whether his classification within the system should be changed and whether he should be transferred to another Hawaii facility or to a mainland institution.\\n*241 The August 10 hearing was conducted by the same persons who had presided over the hearings on August 2. Respondent retained counsel to represent him. The Committee recommended that respondent\\'s classification as a maximum security risk be continued and that he be transferred to a prison on the mainland. He received the following explanation from the Committee:\\n\"The Program Committee, having reviewed your entire file, your testimony and arguments by your counsel, concluded that your control classification remains at Maximum. You are still considered a security risk in view of your escapes and subsequent convictions for serious felonies. The Committee noted the progress you made in vocational training and your expressed desire to continue in this endeavor. However your relationship with staff, who reported that you threaten and intimidate them, raises grave concerns regarding your potential for further disruptive and violent behavior. Since there is no other Maximum security prison in Hawaii which can offer you the correctional programs you require and you cannot remain at [the maximum control unit] because of impending construction of a new facility, the Program Committee recommends your transfer to an institution on the mainland.\" App. 7-8.\\nPetitioner Olim, as Administrator, accepted the Committee\\'s recommendation, and a few days later respondent was transferred to Folsom State Prison in California.\\n\\nB\\nRule IV of the Supplementary Rules and Regulations of the Corrections Division, Department of Social Services and Housing, State of Hawaii, approved in June 1976, recites that the inmate classification process is not concerned with punishment. Rather, it is intended to promote the best interests *242 of the inmate, the State, and the prison community.[1] Paragraph 3 of Rule IV requires a hearing prior to a prison transfer involving \"a grievous loss to the inmate,\" which the Rule defines \"generally\" as \"a serious loss to a reasonable man.\" App. 21.[2] The Administrator, under ¶ 2 of the Rule, is required to establish \"an impartial Program Committee\" to conduct such a hearing, the Committee to be \"composed of at least three members who were not actively involved in the process by which the inmate . . . was brought before the Committee.\" App. 20. Under ¶ 3, the Committee must give the inmate written notice of the hearing, permit him, with certain stated exceptions, to confront and cross-examine witnesses, afford him an opportunity to be heard, and apprise him of the Committee\\'s findings. App. 21-24.[3]\\nThe Committee is directed to make a recommendation to the Administrator, who then decides what action to take:\\n\"[The Administrator] may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate *243. . . , other inmates . . . , institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" Rule IV, ¶ 3d(3), App. 24.\\nThe regulations contain no standards governing the Administrator\\'s exercise of his discretion. See Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981).\\n\\nC\\nRespondent filed suit under 42 U. S. C. § 1983 against petitioners as the state officials who caused his transfer. He alleged that he had been denied procedural due process because the Committee that recommended his transfer consisted of the same persons who had initiated the hearing, this being in specific violation of Rule IV, ¶ 2, and because the Committee was biased against him. The United States District Court for the District of Hawaii dismissed the complaint, holding that the Hawaii regulations governing prison transfers do not create a substantive liberty interest protected by the Due Process Clause. 459 F. Supp. 473 (1978).[4]\\nThe United States Court of Appeals for the Ninth Circuit, by a divided vote, reversed. 664 F. 2d 708 (1981). It held that Hawaii had created a constitutionally protected liberty interest by promulgating Rule IV. In so doing, the court declined to follow cases from other Courts of Appeals holding that certain procedures mandated by prison transfer regulations do not create a liberty interest. See, e. g., Cofone v. Manson, 594 F. 2d 934 (CA2 1979); Lombardo v. Meachum, 548 F. 2d 13 (CA1 1977). The court reasoned that Rule IV gives Hawaii prisoners a justifiable expectation that they will not be transferred to the mainland absent a hearing, before an impartial committee, concerning the facts alleged in the *244 prehearing notice.[5] Because the Court of Appeals\\' decision created a conflict among the Circuits, and because the case presents the further question whether the Due Process Clause in and of itself protects against interstate prison transfers, we granted certiorari. 456 U. S. 1005 (1982).\\n\\nII\\nIn Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236 (1976), this Court held that an intrastate prison transfer does not directly implicate the Due Process Clause of the Fourteenth Amendment. In Meachum, inmates at a Massachusetts medium security prison had been transferred to a maximum security prison in that Commonwealth. In Montanye, a companion case, an inmate had been transferred from one maximum security New York prison to another as punishment for a breach of prison rules. This Court rejected \"the notion that any grievous loss visited upon a person by the State is sufficient to invoke the procedural protections of the Due Process Clause.\" Meachum, 427 U. S., at 224 (emphasis in original). It went on to state:\\n\"The initial decision to assign the convict to a particular institution is not subject to audit under the Due Process Clause, although the degree of confinement in one prison may be quite different from that in another. The conviction has sufficiently extinguished the defendant\\'s liberty *245 interest to empower the State to confine him in any of its prisons.\\n\"Neither, in our view, does the Due Process Clause in and of itself protect a duly convicted prisoner against transfer from one institution to another within the state prison system. Confinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Id., at 224-225 (emphasis in original).\\nThe Court observed that, although prisoners retain a residuum of liberty, see Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974), a holding that \"any substantial deprivation imposed by prison authorities triggers the procedural protections of the Due Process Clause would subject to judicial review a wide spectrum of discretionary actions that traditionally have been the business of prison administrators rather than of the federal courts.\" 427 U. S., at 225 (emphasis in original).\\nApplying the Meachum and Montanye principles in Vitek v. Jones, 445 U. S. 480 (1980), this Court held that the transfer of an inmate from a prison to a mental hospital did implicate a liberty interest. Placement in the mental hospital was \"not within the range of conditions of confinement to which a prison sentence subjects an individual,\" because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" Id., at 493. Respondent argues that the same is true of confinement of a Hawaii prisoner on the mainland, and that Vitek therefore controls.\\nWe do not agree. Just as an inmate has no justifiable expectation that he will be incarcerated in any particular prison within a State, he has no justifiable expectation that he will be incarcerated in any particular State.[6] Often, confinement *246 in the inmate\\'s home State will not be possible. A person convicted of a federal crime in a State without a federal correctional facility usually will serve his sentence in another State. Overcrowding and the need to separate particular prisoners may necessitate interstate transfers. For any number of reasons, a State may lack prison facilities capable of providing appropriate correctional programs for all offenders.\\nStatutes and interstate agreements recognize that, from time to time, it is necessary to transfer inmates to prisons in other States. On the federal level, 18 U. S. C. § 5003(a) authorizes the Attorney General to contract with a State for the transfer of a state prisoner to a federal prison, whether in that State or another. See Howe v. Smith, 452 U. S. 473 (1981).[7] Title 18 U. S. C. § 4002 (1976 ed. and Supp. V) permits the Attorney General to contract with any State for the placement of a federal prisoner in state custody for up to three years. Neither statute requires that the prisoner remain in the State in which he was convicted and sentenced.\\nOn the state level, many States have statutes providing for the transfer of a state prisoner to a federal prison, e. g., Haw. Rev. Stat. § 353-18 (1976), or another State\\'s prison, e. g., Alaska Stat. Ann. § 33.30.100 (1982). Corrections compacts between States, implemented by statutes, authorize incarceration of a prisoner of one State in another State\\'s prison. See, e. g., Cal. Penal Code Ann. § 11189 (West 1982) (codifying Interstate Corrections Compact); § 11190 (codifying Western Interstate Corrections Compact); Conn. Gen. *247 Stat. § 18-102 (1981) (codifying New England Interstate Corrections Compact); § 18-106 (codifying Interstate Corrections Compact); Haw. Rev. Stat. § 355-1 (1976) (codifying Western Interstate Corrections Compact); Idaho Code § 20-701 (1979) (codifying Interstate Corrections Compact); Ky. Rev. Stat. § 196.610 (1982) (same). And prison regulations such as Hawaii\\'s Rule IV anticipate that inmates sometimes will be transferred to prisons in other States.\\nIn short, it is neither unreasonable nor unusual for an inmate to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced, or to be transferred to an out-of-state prison after serving a portion of his sentence in his home State. Confinement in another State, unlike confinement in a mental institution, is \"within the normal limits or range of custody which the conviction has authorized the State to impose.\" Meachum, 427 U. S., at 225.[8] Even when, as here, the transfer involves long distances and an ocean crossing, the confinement remains within constitutional limits. The difference between such a transfer and an intrastate or interstate transfer of *248 shorter distance is a matter of degree, not of kind,[9] and Meachum instructs that \"the determining factor is the nature of the interest involved rather than its weight.\" 427 U. S., at 224. The reasoning of Meachum and Montanye compels the conclusion that an interstate prison transfer, including one from Hawaii to California, does not deprive an inmate of any liberty interest protected by the Due Process Clause in and of itself.\\n\\nIII\\nThe Court of Appeals held that Hawaii\\'s prison regulations create a constitutionally protected liberty interest. In Meachum, however, the State had \"conferred no right on the *249 prisoner to remain in the prison to which he was initially assigned, defeasible only upon proof of specific acts of misconduct,\" 427 U. S., at 226, and \"ha[d] not represented that transfers [would] occur only on the occurrence of certain events,\" id., at 228. Because the State had retained \"discretion to transfer [the prisoner] for whatever reason or for no reason at all,\" ibid., the Court found that the State had not created a constitutionally protected liberty interest. Similarly, because the state law at issue in Montanye \"impose[d] no conditions on the discretionary power to transfer,\" 427 U. S., at 243, there was no basis for invoking the protections of the Due Process Clause.\\nThese cases demonstrate that a State creates a protected liberty interest by placing substantive limitations on official discretion. An inmate must show \"that particularized standards or criteria guide the State\\'s decisionmakers.\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 467 (1981) (BRENNAN, J., concurring). If the decisionmaker is not \"required to base its decisions on objective and defined criteria,\" but instead \"can deny the requested relief for any constitutionally permissible reason or for no reason at all,\" ibid., the State has not created a constitutionally protected liberty interest. See id., at 466-467 (opinion of the Court); see also Vitek v. Jones, 445 U. S., at 488-491 (summarizing cases).\\nHawaii\\'s prison regulations place no substantive limitations on official discretion and thus create no liberty interest entitled to protection under the Due Process Clause. As Rule IV itself makes clear, and as the Supreme Court of Hawaii has held in Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981, the prison Administrator\\'s discretion to transfer an inmate is completely unfettered. No standards govern or restrict the Administrator\\'s determination. Because the Administrator is the only decisionmaker under Rule IV, we need not decide whether the introductory paragraph *250 of Rule IV, see n. 1, supra, places any substantive limitations on the purely advisory Program Committee.[10]\\nThe Court of Appeals thus erred in attributing significance to the fact that the prison regulations require a particular kind of hearing before the Administrator can exercise his unfettered discretion.[11] As the United States Court of Appeals for the Seventh Circuit recently stated in Shango v. Jurich, 681 F. 2d 1091, 1100-1101 (1982), \"[a] liberty interest is of course a substantive interest of an individual; it cannot be the right to demand needless formality.\"[12] Process is not an end in itself. Its constitutional purpose is to protect a substantive interest to which the individual has a legitimate claim of entitlement. See generally Simon, Liberty and Property in the Supreme Court: A Defense of Roth and Perry, 71 Calif. L. Rev. 146, 186 (1983). If officials may transfer a prisoner \"for whatever reason or for no reason at all,\" Meachum, 427 U. S., at 228, there is no such interest for process to protect. The State may choose to require procedures for reasons other than protection against deprivation of substantive *251 rights, of course,[13] but in making that choice the State does not create an independent substantive right. See Hewitt v. Helms, 459 U. S. 460, 471 (1983).\\n\\nIV\\nIn sum, we hold that the transfer of respondent from Hawaii to California did not implicate the Due Process Clause directly, and that Hawaii\\'s prison regulations do not create a protected liberty interest.[14] Accordingly, the judgment of the Court of Appeals is\\nReversed.\\nJUSTICE MARSHALL, with whom JUSTICE BRENNAN joins, and with whom JUSTICE STEVENS joins as to Part I, dissenting.\\nIn my view, the transfer of respondent Delbert Kaahanui Wakinekona from a prison in Hawaii to a prison in California implicated an interest in liberty protected by the Due Process Clause of the Fourteenth Amendment. I respectfully dissent.\\n\\nI\\nAn inmate\\'s liberty interest is not limited to whatever a State chooses to bestow upon him. An inmate retains a significant residuum of constitutionally protected liberty following his incarceration independent of any state law. As we stated in Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974): \"[A] prisoner is not wholly stripped of constitutional protections when he is imprisoned for crime. There is no iron curtain drawn between the Constitution and the prisons *252 of this country. . . . [Prisoners] may not be deprived of life, liberty, or property without due process of law.\"\\nIn determining whether a change in the conditions of imprisonment implicates a prisoner\\'s retained liberty interest, the relevant question is whether the change constitutes a sufficiently \"grievous loss\" to trigger the protection of due process. Vitek v. Jones, 445 U. S. 480, 488 (1980). See Morrissey v. Brewer, 408 U. S. 471, 481 (1972), citing Joint Anti-Fascist Refugee Committee v. McGrath, 341 U. S. 123, 168 (1951) (Frankfurter, J., concurring). The answer depends in part on a comparison of \"the treatment of the particular prisoner with the customary, habitual treatment of the population of the prison as a whole.\" Hewitt v. Helms, 459 U. S. 460, 486 (1983) (STEVENS, J., dissenting). This principle was established in our decision in Vitek, which held that the transfer of an inmate from a prison to a mental hospital implicated a liberty interest because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" 445 U. S., at 493. Because a significant qualitative change in the conditions of confinement is not \"within the range of conditions of confinement to which a prison sentence subjects an individual,\" ibid., such a change implicates a prisoner\\'s protected liberty interest.\\nThere can be little doubt that the transfer of Wakinekona from a Hawaii prison to a prison in California represents a substantial qualitative change in the conditions of his confinement. In addition to being incarcerated, which is the ordinary consequence of a criminal conviction and sentence, Wakinekona has in effect been banished from his home, a punishment historically considered to be \"among the severest.\"[1] For an indeterminate period of time, possibly the *253 rest of his life, nearly 2,500 miles of ocean will separate him from his family and friends. As a practical matter, Wakinekona may be entirely cut off from his only contacts with the outside world, just as if he had been imprisoned in an institution which prohibited visits by outsiders. Surely the isolation imposed on him by the transfer is far more drastic than that which normally accompanies imprisonment.\\nI cannot agree with the Court that Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236, 243 (1976), compel the conclusion that Wakinekona\\'s transfer implicates no liberty interest. Ante, at 248. Both cases involved transfers of prisoners between institutions located within the same State in which they were convicted, and the Court expressly phrased its holdings in terms of intrastate transfers.[2] Both decisions rested on the premise that no liberty interest is implicated by an initial decision to place a prisoner in one institution in the State rather than another. See Meachum, supra, at 224; Montanye, supra, at 243. On the basis of that premise, the Court concluded that the subsequent transfer of a prisoner to a different facility within the State likewise implicates no liberty interest. In this case, however, we cannot assume that a State\\'s initial placement of an individual in a prison far removed from his family and residence would raise no due process questions. None of our *254 prior decisions has indicated that such a decision would be immune from scrutiny under the Due Process Clause.\\nActual experience simply does not bear out the Court\\'s assumptions that interstate transfers are routine and that it is \"not unusual\" for a prisoner \"to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced.\" Ante, at 247. In Hawaii less than three percent of the state prisoners were transferred to prisons in other jurisdictions in 1979, and on a nationwide basis less than one percent of the prisoners held in state institutions were transferred to other jurisdictions.[3] Moreover, the vast majority of state prisoners are held in facilities located less than 250 miles from their homes.[4] Measured against these norms, Wakinekona\\'s transfer to a California prison represents a punishment \"qualitively different from the punishment characteristically suffered by a person convicted of crime.\" Vitek v. Jones, supra, at 493.\\nI therefore cannot agree that a State may transfer its prisoners at will, to any place, for any reason, without ever implicating any interest in liberty protected by the Due Process Clause.\\n\\nII\\nNor can I agree with the majority\\'s conclusion that Hawaii\\'s prison regulations do not create a liberty interest. This Court\\'s prior decisions establish that a liberty interest *255 may be \"created\"[5] by state laws, prison rules, regulations, or practices. State laws that impose substantive criteria which limit or guide the discretion of officials have been held to create a protected liberty interest. See, e. g., Hewitt v. Helms, 459 U. S. 460 (1983); Wolff v. McDonnell, 418 U. S. 539 (1974); Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979); Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). By contrast, a liberty interest is not created by a law which \"imposes no conditions on [prison officials\\'] discretionary power,\" Montanye, supra, at 243, authorizes prison officials to act \"for whatever reason or for no reason at all,\" Meachum, supra, at 228, or accords officials \"unfettered discretion,\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 466 (1981).\\nThe Court misapplies these principles in concluding that Hawaii\\'s prison regulations leave prison officials with unfettered discretion to transfer inmates. Ante, at 249-250. Rule IV establishes a scheme under which inmates are classified upon initial placement in an institution, and must subsequently be reclassified before they can be transferred to another institution. Under the Rule the standard for classifying inmates is their \"optimum placement within the Corrections Division\" in light of the \"best interests of the individual, the State, and the community.\"[6] In classifying inmates, the Program *256 Committee may not consider punitive aims. It may consider only factors relevant to determining where the individual will be \"best situated,\" such as \"his history, his changing needs, the resources and facilities available to the Corrections Divisions, the other inmates/wards, the exigencies of the community, and any other relevant factors.\" Paragraph 3 of Rule IV establishes a detailed set of procedures applicable when, as in this case, the reclassification of a prisoner may lead to a transfer involving a \"grievous loss,\" a phrase contained in the Rule itself.[7] The procedural rules are cast in mandatory language, and cover such matters as notice, access to information, hearing, confrontation and cross-examination, and the basis on which the Committee is to make its recommendation to the facility administrator.\\nThe limitations imposed by Rule IV are at least as substantial as those found sufficient to create a liberty interest in Hewitt v. Helms, supra, decided earlier this Term. In Hewitt an inmate contended that his confinement in administrative custody implicated an interest in liberty protected by the Due Process Clause. State law provided that a prison official could place inmates in administrative custody \"upon his assessment of the situation and the need for control,\" or \"where it has been determined that there is a threat of a serious disturbance, or a serious threat to the individual or others,\" and mandated certain procedures such as notice and a *257 hearing.[8] This Court construed the phrases \" `the need for control,\\' or `the threat of a serious disturbance,\\' \" as \"substantive predicates\" which restricted official discretion. Id., at 472. These restrictions, in combination with the mandatory procedural safeguards, \"deman[ded] a conclusion that the State has created a protected liberty interest.\" Ibid.\\nRule IV is not distinguishable in any meaningful respect from the provisions at issue in Helms. The procedural requirements contained in Rule IV are, if anything, far more elaborate than those involved in Helms, and are likewise couched in \"language of an unmistakably mandatory character.\" Id., at 471. Moreover, Rule IV, to no less an extent than the state law at issue in Helms, imposes substantive criteria restricting official discretion. In Helms this Court held that a statutory phrase such as \"the need for control\" constituted a limitation on the discretion of prison officials to place inmates in administrative custody. In my view Rule IV, which states that transfers are intended to ensure an inmate\\'s \"optimum placement\" in accordance with considerations which include \"his changing needs [and] the resources and facilities available to the Corrections Division,\" also restricts official discretion in ordering transfers.[9]\\nThe Court suggests that, even if the Program Committee does not have unlimited discretion in making recommendations for classifications and transfers, this cannot give rise to a state-created liberty interest because the prison Administrator retains \"completely unfettered\" \"discretion to transfer *258 an inmate,\" ante, at 249. I disagree. Rule IV, ¶ 3(d)(3), provides for review by the prison Administrator of recommendations forwarded to him by the Program Committee.[10] Even if this provision must be construed as authorizing the Administrator to transfer a prisoner for wholly arbitrary reasons,[11] that mere possibility does not defeat the protectible expectation otherwise created by Hawaii\\'s reclassification and transfer scheme that transfers will take place only if required to ensure an inmate\\'s optimum placement. In Helms a prison regulation also left open the possibility that the Superintendent could decide, for any reason or no reason at all, whether an inmate should be confined in administrative custody.[12] This Court nevertheless held that the state scheme as a whole created an interest in liberty protected by the Due Process Clause. 459 U. S., at 471-472. Helms thus necessarily rejects the view that state laws which impose substantive *259 limitations and elaborate procedural requirements on official conduct create no liberty interest solely because there remains the possibility that an official will act in an arbitrary manner at the end of the process.[13]\\nFor the foregoing reasons, I dissent.\\nNOTES\\n[*]  Briefs of amici curiae urging reversal were filed for the State of Alaska et al. by Paul L. Douglas, Attorney General of Nebraska, J. Kirk Brown, Assistant Attorney General, Judith W. Rogers, Corporation Counsel of the District of Columbia, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William J. Guste, Jr., of Louisiana, William A. Allain of Mississippi, Michael T. Greely of Montana, Richard H. Bryan of Nevada, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Gerald L. Baliles of Virginia, Kenneth O. Eikenberry of Washington, Chauncey H. Browning of West Virginia, Bronson C. La Follette of Wisconsin, and Steven F. Freudenthal of Wyoming; and for the Commonwealth of Massachusetts et al. by Francis X. Bellotti, Attorney General of Massachusetts, Stephen R. Delinsky, Barbara A. H. Smith, and Leo J. Cushing, Assistant Attorneys General, Anthony Ching, Solicitor General of Arizona, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William A. Allain of Mississippi, Michael T. Greely of Montana, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert O. Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Chauncey H. Browning of West Virginia, and Bronson C. La Follette of Wisconsin.\\n[1]  Paragraph 1 of Rule IV states:\\n\\n\"An inmate\\'s . . . classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates . . . , the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[2]  Petitioners concede, \"for purposes of the argument,\" that respondent suffered a \"grievous loss\" within the meaning of Rule IV when he was transferred from Hawaii to the mainland. Tr. of Oral Arg. 9, 25.\\n[3]  Rule V provides that an inmate may retain legal counsel if his hearing concerns a \"potential Interstate transfer.\" App. 25.\\n[4]  Respondent also had alleged that the transfer violated the Hawaii Constitution and state regulations and statutes. In light of its dismissal of respondent\\'s federal claims, the District Court declined to exercise pendent jurisdiction over these state-law claims. 459 F. Supp., at 476.\\n[5]  Several months before the Court of Appeals handed down its decision, the Supreme Court of Hawaii had held that because Hawaii\\'s prison regulations do not limit the Administrator\\'s discretion to transfer prisoners to the mainland, they do not create any liberty interest. Lono v. Ariyoshi, 63 Haw. 138, 621 P. 2d 976 (1981). In a petition for rehearing in the present case, petitioners directed the Ninth Circuit\\'s attention to the Lono decision. See 664 F. 2d, at 714. The Court of Appeals, however, concluded that the Hawaii court\\'s interpretation of the regulations was not different from its own; the Hawaii court merely had reached a different result on the \"federal question.\" The Court of Appeals thus adhered to its resolution of the case. Id., at 714-715.\\n[6]  Indeed, in Vitek itself the Court did not read Meachum and Montanye as stating a rule applicable only to intrastate transfers. The Court stated: \"In Meachum v. Fano . . . and Montanye v. Haymes . . . we held that the transfer of a prisoner from one prison to another does not infringe a protected liberty interest.\" 445 U. S., at 489 (emphasis added). The Court\\'s other cases describing Meachum and Montanye also have eschewed the narrow reading respondent now proposes. See Hewitt v. Helms, 459 U. S. 460, 467-468 (1983); Moody v. Daggett, 429 U. S. 78, 88, n. 9 (1976).\\n[7]  This statute has been invoked to transfer prisoners from Hawaii state facilities to federal prisons on the mainland. See Anthony v. Wilkinson, 637 F. 2d 1130 (CA7 1980), vacated and remanded sub nom. Hawaii v. Mederios, 453 U. S. 902 (1981).\\n[8]  After the decisions in Meachum and Montanye, courts almost uniformly have held that an inmate has no entitlement to remain in a prison in his home State. See Beshaw v. Fenton, 635 F. 2d 239, 246-247 (CA3 1980), cert. denied, 453 U. S. 912 (1981); Cofone v. Manson, 594 F. 2d 934, 937, n. 4 (CA2 1979); Sisbarro v. Warden, 592 F. 2d 1, 3 (CA1), cert. denied, 444 U. S. 849 (1979); Fletcher v. Warden, 467 F. Supp. 777, 779-780 (Kan. 1979); Curry-Bey v. Jackson, 422 F. Supp. 926, 931-933 (DC 1976); McDonnell v. United States Attorney General, 420 F. Supp. 217, 220 (ED Ill. 1976); Goodnow v. Perrin, 120 N. H. 669, 671, 421 A. 2d 1008, 1010 (1980); Girouard v. Hogan, 135 Vt. 448, 449-450, 378 A. 2d 105, 106-107 (1977); In re Young, 95 Wash. 2d 216, 227-228, 622 P. 2d 373, 379 (1980); cf. Fajeriak v. McGinnis, 493 F. 2d 468 (CA9 1974) (pre-Meachum transfers from Alaska to other States); Hillen v. Director of Department of Social Services, 455 F. 2d 510 (CA9), cert. denied, 409 U. S. 989 (1972) (pre-Meachum transfer from Hawaii to California). But see In re Young, 95 Wash. 2d, at 233, 622 P. 2d, at 382 (concurring opinion); State ex rel. Olson v. Maxwell, 259 N. W. 2d 621 (N. D. 1977); cf. Tai v. Thompson, 387 F. Supp. 912 (Haw. 1975) (pre-Meachum transfer).\\n[9]  Respondent\\'s argument to the contrary is unpersuasive. The Court in Montanye took note that among the hardships that may result from a prison transfer are separation of the inmate from home and family, separation from inmate friends, placement in a new and possibly hostile environment, difficulty in making contact with counsel, and interruption of educational and rehabilitative programs. 427 U. S., at 241, n. 4. These are the same hardships respondent faces as a result of his transfer from Hawaii to California.\\n\\nRespondent attempts to analogize his transfer to banishment in the English sense of \"beyond the seas,\" arguing that banishment surely is not within the range of confinement justified by his sentence. But respondent in no sense has been banished; his conviction, not the transfer, deprived him of his right freely to inhabit the State. The fact that his confinement takes place outside Hawaii is merely a fortuitous consequence of the fact that he must be confined, not an additional element of his punishment. See Girouard v. Hogan, 135 Vt., at 449-450, 378 A. 2d, at 106-107. Moreover, respondent has not been exiled; he remains within the United States.\\nIn essence, respondent\\'s banishment argument simply restates his claim that a transfer from Hawaii to the mainland is different in kind from other transfers. As has been shown in the text, however, respondent\\'s transfer was authorized by his conviction. A conviction, whether in Hawaii, Alaska, or one of the contiguous 48 States, empowers the State to confine the inmate in any penal institution in any State unless there is state law to the contrary or the reason for confining the inmate in a particular institution is itself constitutionally impermissible. See Montanye, 427 U. S., at 242; id., at 244 (dissenting opinion); Cruz v. Beto, 405 U. S. 319 (1972); Fajeriak v. McGinnis, 493 F. 2d, at 470.\\n[10]  In Hewitt v. Helms, 459 U. S. 460 (1983), unlike this case, state law limited the decisionmakers\\' discretion. To the extent the dissent doubts that the Administrator\\'s discretion under Rule IV is truly unfettered, post, at 258, and n. 11, it doubts the ability or authority of the Hawaii Supreme Court to construe state law.\\n[11]  In Meachum itself, the Court of Appeals had interpreted the applicable regulations as entitling inmates to a pretransfer hearing, see Fano v. Meachum, 520 F. 2d 374, 379-380 (CA1 1975), but this Court held that state law created no liberty interest.\\n[12]  Other courts agree that an expectation of receiving process is not, without more, a liberty interest protected by the Due Process Clause. See, e. g., United States v. Jiles, 658 F. 2d 194, 200 (CA3 1981), cert. denied, 455 U. S. 923 (1982); Bills v. Henderson, 631 F. 2d 1287, 1298-1299 (CA6 1980); Pugliese v. Nelson, 617 F. 2d 916, 924-925 (CA2 1980); Cofone v. Manson, 594 F. 2d, at 938; Lombardo v. Meachum, 548 F. 2d 13, 14-16 (CA1 1977); Adams v. Wainwright, 512 F. Supp. 948, 953 (ND Fla. 1981); Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981.\\n[13]  Petitioners assert that the hearings required by Rule IV not only enable the officials to gather information and thereby to exercise their discretion intelligently, but also have a therapeutic purpose: inmate participation in the decisionmaking process, it is hoped, reduces tension in the prison. See Tr. of Oral Arg. 52-53.\\n[14]  In light of this conclusion, respondent\\'s claim of bias in the composition of the prison Program Committee becomes irrelevant.\\n[1]  4 J. Elliott, Debates on the Federal Constitution 555 (1836). Whether it is called banishment, exile, deportation, relegation, or transportation, compelling a person \"to quit a city, place, or country, for a specified period of time, or for life,\" has long been considered a unique and severe deprivation, and was specifically outlawed by \"[t]he twelfth section of the English Habeas Corpus Act, 31 Car. II, one of the three great muniments of English liberty.\" United States v. Ju Toy, 198 U. S. 253, 269-270 (1905) (Brewer, J., dissenting).\\n[2]  Thus in Meachum the Court stated that the State, by convicting the defendant, was \"empower[ed] to confine him in any of its prisons,\" 427 U. S., at 224 (emphasis deleted), that a \"transfer from one institution to another within the state prison system\" implicated no due process interest, id., at 225, and that \"[c]onfinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Ibid. See also Montanye, 427 U. S., at 242 (\"We held in Meachum v. Fano, that no Due Process Clause liberty interest of a duly convicted prison inmate is infringed when he is transferred from one prison to another within the State\").\\n[3]  U. S. Dept. of Justice, Bureau of Justice Statistics, Sourcebook of Criminal Justice Statistics \\x97 1981, Table 6.27, pp. 478-479 (T. Flanagan, D. Van Alstyne, & M. Gottfredson eds. 1982). These figures reflect \"all inmates who were transferred from one State\\'s jurisdiction to another to continue sentences already in force,\" and \"[d]oes not include the release if [the] State does not relinquish jurisdiction.\" Id., at 590.\\n[4]  U. S. Dept. of Justice, Profile of State Prison Inmates: Sociodemographic Findings from the 1974 Survey of Inmates of State Correctional Facilities 1 (1979). Over 70 percent of state inmates are held in institutions located less than 250 miles from their homes.\\n[5]  But see Hewitt v. Helms, 459 U. S. 460, 488 (1983) (STEVENS, J., dissenting) (Prison regulations \"provide evidentiary support for the conclusion that the transfer affects a constitutionally protected interest in liberty,\" but they \"do not create that interest\" (emphasis in original)).\\n[6]  Paragraph 1 of Rule IV provides:\\n\\n\"An inmate\\'s/ward\\'s classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates/wards, the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[7]  While the term \"grievous loss\" is not explicitly defined, the prison regulations treat a transfer to the mainland as a grievous loss entitling an inmate to the procedural rights established in Rule IV, ¶ 3. This is readily inferred from Rule IV, ¶ 3, which states that intrastate transfers do not involve a grievous loss, and Rule V, which permits inmates to retain counsel only in specified circumstances, one of which is a reclassification that may result in an interstate transfer. App. 25.\\n[8]  See 459 U. S., at 470-471, n. 6.\\n[9]  See also Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). In that case, the District Court held that the language of a prison policy statement, stating that \"[i]nmates may be segregated for medical, psychiatric, disciplinary, or administrative reasons,\" 462 F. Supp., at 403, was sufficient to create a protected expectation that an inmate would not be segregated for arbitrary reasons. See also Bills v. Henderson, 631 F. 2d 1287, 1293 (CA6 1980), cert. denied, 449 U. S. 1093 (1981); Winsett v. McGinnes, 617 F. 2d 996, 107 (CA3 1980) (en banc).\\n[10]  Rule IV, ¶ 3(d)(3), provides:\\n\\n\"The facility administrator will, within a reasonable period of time, review the Program Committee\\'s recommendation. He may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate/ward, other inmates/wards, institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" App. 21.\\n[11]  I doubt that Rule IV would be construed to permit the Administrator to order a transfer for punitive reasons, since Rule IV expressly disallows punitive transfers.\\n[12]  That provision stated: \"All decisions of the Program Review Committee shall be reviewed by the Superintendent for his sustaining the decision or amending or reversing the decision in favor of the inmate.\" Pennsylvania Bureau of Correction Administrative Directive BC-ADM 801, Rule III(H)(7). App. to Brief for Respondent in Hewitt v. Helms, O. T. 1982, No. 81-638, p. 12a. Because an inmate could be confined in administrative custody only if the Program Review Committee determined that such confinement is and continues to be \"appropriate,\" id., at 18a, the Superintendent in Helms was the \"decisionmaker,\" ante, at 249-250, who determined whether inmates would be held in administrative custody.\\n[13]  This view was also implicitly rejected in Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979). The Court held that the Nebraska statute governing the decision whether or not to grant parole created a \"protectible entitlement,\" id., at 12, even though the statute, which listed a number of factors to be considered in the parole decision, also authorized the Parole Board to deny parole on the basis of \"[a]ny other factors the board determines to be relevant.\" Id., at 18.\\n\\nTo the extent that Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981), on which the majority relies, ante, at 249, suggests that no liberty interest is created as state law has not entirely eliminated the possibility of arbitrary action, it is inconsistent with both Helms and Greenholtz.\\n'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "law_dataset_streamed = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"https://mystic.the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst\",\n",
    "    split=\"train\",\n",
    "    streaming=True,\n",
    ")\n",
    "next(iter(law_dataset_streamed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a443d4",
   "metadata": {},
   "source": [
    "This dataset is large enough to stress the RAM of most laptops, yet we've been able to load and access it without breaking a sweat! Let's now combine the examples from the FreeLaw and PubMed Abstracts datasets with the `interleave_datasets()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "913dee1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "   'case_ID': '110921.json',\n",
       "   'date_created': '2010-04-28T17:12:49Z'},\n",
       "  'text': '\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General.\\nRobert Gilbert Johnston argued the cause for respondent. With him on the brief was Clayton C. Ikei.[*]\\n*240 JUSTICE BLACKMUN delivered the opinion of the Court.\\nThe issue in this case is whether the transfer of a prisoner from a state prison in Hawaii to one in California implicates a liberty interest within the meaning of the Due Process Clause of the Fourteenth Amendment.\\n\\nI\\n\\nA\\nRespondent Delbert Kaahanui Wakinekona is serving a sentence of life imprisonment without the possibility of parole as a result of his murder conviction in a Hawaii state court. He also is serving sentences for various other crimes, including rape, robbery, and escape. At the Hawaii State Prison outside Honolulu, respondent was classified as a maximum security risk and placed in the maximum control unit.\\nPetitioner Antone Olim is the Administrator of the Hawaii State Prison. The other petitioners constituted a prison \"Program Committee.\" On August 2, 1976, the Committee held hearings to determine the reasons for a breakdown in discipline and the failure of certain programs within the prison\\'s maximum control unit. Inmates of the unit appeared at these hearings. The Committee singled out respondent and another inmate as troublemakers. On August 5, respondent received notice that the Committee, at a hearing to be held on August 10, would review his correctional program to determine whether his classification within the system should be changed and whether he should be transferred to another Hawaii facility or to a mainland institution.\\n*241 The August 10 hearing was conducted by the same persons who had presided over the hearings on August 2. Respondent retained counsel to represent him. The Committee recommended that respondent\\'s classification as a maximum security risk be continued and that he be transferred to a prison on the mainland. He received the following explanation from the Committee:\\n\"The Program Committee, having reviewed your entire file, your testimony and arguments by your counsel, concluded that your control classification remains at Maximum. You are still considered a security risk in view of your escapes and subsequent convictions for serious felonies. The Committee noted the progress you made in vocational training and your expressed desire to continue in this endeavor. However your relationship with staff, who reported that you threaten and intimidate them, raises grave concerns regarding your potential for further disruptive and violent behavior. Since there is no other Maximum security prison in Hawaii which can offer you the correctional programs you require and you cannot remain at [the maximum control unit] because of impending construction of a new facility, the Program Committee recommends your transfer to an institution on the mainland.\" App. 7-8.\\nPetitioner Olim, as Administrator, accepted the Committee\\'s recommendation, and a few days later respondent was transferred to Folsom State Prison in California.\\n\\nB\\nRule IV of the Supplementary Rules and Regulations of the Corrections Division, Department of Social Services and Housing, State of Hawaii, approved in June 1976, recites that the inmate classification process is not concerned with punishment. Rather, it is intended to promote the best interests *242 of the inmate, the State, and the prison community.[1] Paragraph 3 of Rule IV requires a hearing prior to a prison transfer involving \"a grievous loss to the inmate,\" which the Rule defines \"generally\" as \"a serious loss to a reasonable man.\" App. 21.[2] The Administrator, under ¶ 2 of the Rule, is required to establish \"an impartial Program Committee\" to conduct such a hearing, the Committee to be \"composed of at least three members who were not actively involved in the process by which the inmate . . . was brought before the Committee.\" App. 20. Under ¶ 3, the Committee must give the inmate written notice of the hearing, permit him, with certain stated exceptions, to confront and cross-examine witnesses, afford him an opportunity to be heard, and apprise him of the Committee\\'s findings. App. 21-24.[3]\\nThe Committee is directed to make a recommendation to the Administrator, who then decides what action to take:\\n\"[The Administrator] may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate *243. . . , other inmates . . . , institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" Rule IV, ¶ 3d(3), App. 24.\\nThe regulations contain no standards governing the Administrator\\'s exercise of his discretion. See Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981).\\n\\nC\\nRespondent filed suit under 42 U. S. C. § 1983 against petitioners as the state officials who caused his transfer. He alleged that he had been denied procedural due process because the Committee that recommended his transfer consisted of the same persons who had initiated the hearing, this being in specific violation of Rule IV, ¶ 2, and because the Committee was biased against him. The United States District Court for the District of Hawaii dismissed the complaint, holding that the Hawaii regulations governing prison transfers do not create a substantive liberty interest protected by the Due Process Clause. 459 F. Supp. 473 (1978).[4]\\nThe United States Court of Appeals for the Ninth Circuit, by a divided vote, reversed. 664 F. 2d 708 (1981). It held that Hawaii had created a constitutionally protected liberty interest by promulgating Rule IV. In so doing, the court declined to follow cases from other Courts of Appeals holding that certain procedures mandated by prison transfer regulations do not create a liberty interest. See, e. g., Cofone v. Manson, 594 F. 2d 934 (CA2 1979); Lombardo v. Meachum, 548 F. 2d 13 (CA1 1977). The court reasoned that Rule IV gives Hawaii prisoners a justifiable expectation that they will not be transferred to the mainland absent a hearing, before an impartial committee, concerning the facts alleged in the *244 prehearing notice.[5] Because the Court of Appeals\\' decision created a conflict among the Circuits, and because the case presents the further question whether the Due Process Clause in and of itself protects against interstate prison transfers, we granted certiorari. 456 U. S. 1005 (1982).\\n\\nII\\nIn Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236 (1976), this Court held that an intrastate prison transfer does not directly implicate the Due Process Clause of the Fourteenth Amendment. In Meachum, inmates at a Massachusetts medium security prison had been transferred to a maximum security prison in that Commonwealth. In Montanye, a companion case, an inmate had been transferred from one maximum security New York prison to another as punishment for a breach of prison rules. This Court rejected \"the notion that any grievous loss visited upon a person by the State is sufficient to invoke the procedural protections of the Due Process Clause.\" Meachum, 427 U. S., at 224 (emphasis in original). It went on to state:\\n\"The initial decision to assign the convict to a particular institution is not subject to audit under the Due Process Clause, although the degree of confinement in one prison may be quite different from that in another. The conviction has sufficiently extinguished the defendant\\'s liberty *245 interest to empower the State to confine him in any of its prisons.\\n\"Neither, in our view, does the Due Process Clause in and of itself protect a duly convicted prisoner against transfer from one institution to another within the state prison system. Confinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Id., at 224-225 (emphasis in original).\\nThe Court observed that, although prisoners retain a residuum of liberty, see Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974), a holding that \"any substantial deprivation imposed by prison authorities triggers the procedural protections of the Due Process Clause would subject to judicial review a wide spectrum of discretionary actions that traditionally have been the business of prison administrators rather than of the federal courts.\" 427 U. S., at 225 (emphasis in original).\\nApplying the Meachum and Montanye principles in Vitek v. Jones, 445 U. S. 480 (1980), this Court held that the transfer of an inmate from a prison to a mental hospital did implicate a liberty interest. Placement in the mental hospital was \"not within the range of conditions of confinement to which a prison sentence subjects an individual,\" because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" Id., at 493. Respondent argues that the same is true of confinement of a Hawaii prisoner on the mainland, and that Vitek therefore controls.\\nWe do not agree. Just as an inmate has no justifiable expectation that he will be incarcerated in any particular prison within a State, he has no justifiable expectation that he will be incarcerated in any particular State.[6] Often, confinement *246 in the inmate\\'s home State will not be possible. A person convicted of a federal crime in a State without a federal correctional facility usually will serve his sentence in another State. Overcrowding and the need to separate particular prisoners may necessitate interstate transfers. For any number of reasons, a State may lack prison facilities capable of providing appropriate correctional programs for all offenders.\\nStatutes and interstate agreements recognize that, from time to time, it is necessary to transfer inmates to prisons in other States. On the federal level, 18 U. S. C. § 5003(a) authorizes the Attorney General to contract with a State for the transfer of a state prisoner to a federal prison, whether in that State or another. See Howe v. Smith, 452 U. S. 473 (1981).[7] Title 18 U. S. C. § 4002 (1976 ed. and Supp. V) permits the Attorney General to contract with any State for the placement of a federal prisoner in state custody for up to three years. Neither statute requires that the prisoner remain in the State in which he was convicted and sentenced.\\nOn the state level, many States have statutes providing for the transfer of a state prisoner to a federal prison, e. g., Haw. Rev. Stat. § 353-18 (1976), or another State\\'s prison, e. g., Alaska Stat. Ann. § 33.30.100 (1982). Corrections compacts between States, implemented by statutes, authorize incarceration of a prisoner of one State in another State\\'s prison. See, e. g., Cal. Penal Code Ann. § 11189 (West 1982) (codifying Interstate Corrections Compact); § 11190 (codifying Western Interstate Corrections Compact); Conn. Gen. *247 Stat. § 18-102 (1981) (codifying New England Interstate Corrections Compact); § 18-106 (codifying Interstate Corrections Compact); Haw. Rev. Stat. § 355-1 (1976) (codifying Western Interstate Corrections Compact); Idaho Code § 20-701 (1979) (codifying Interstate Corrections Compact); Ky. Rev. Stat. § 196.610 (1982) (same). And prison regulations such as Hawaii\\'s Rule IV anticipate that inmates sometimes will be transferred to prisons in other States.\\nIn short, it is neither unreasonable nor unusual for an inmate to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced, or to be transferred to an out-of-state prison after serving a portion of his sentence in his home State. Confinement in another State, unlike confinement in a mental institution, is \"within the normal limits or range of custody which the conviction has authorized the State to impose.\" Meachum, 427 U. S., at 225.[8] Even when, as here, the transfer involves long distances and an ocean crossing, the confinement remains within constitutional limits. The difference between such a transfer and an intrastate or interstate transfer of *248 shorter distance is a matter of degree, not of kind,[9] and Meachum instructs that \"the determining factor is the nature of the interest involved rather than its weight.\" 427 U. S., at 224. The reasoning of Meachum and Montanye compels the conclusion that an interstate prison transfer, including one from Hawaii to California, does not deprive an inmate of any liberty interest protected by the Due Process Clause in and of itself.\\n\\nIII\\nThe Court of Appeals held that Hawaii\\'s prison regulations create a constitutionally protected liberty interest. In Meachum, however, the State had \"conferred no right on the *249 prisoner to remain in the prison to which he was initially assigned, defeasible only upon proof of specific acts of misconduct,\" 427 U. S., at 226, and \"ha[d] not represented that transfers [would] occur only on the occurrence of certain events,\" id., at 228. Because the State had retained \"discretion to transfer [the prisoner] for whatever reason or for no reason at all,\" ibid., the Court found that the State had not created a constitutionally protected liberty interest. Similarly, because the state law at issue in Montanye \"impose[d] no conditions on the discretionary power to transfer,\" 427 U. S., at 243, there was no basis for invoking the protections of the Due Process Clause.\\nThese cases demonstrate that a State creates a protected liberty interest by placing substantive limitations on official discretion. An inmate must show \"that particularized standards or criteria guide the State\\'s decisionmakers.\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 467 (1981) (BRENNAN, J., concurring). If the decisionmaker is not \"required to base its decisions on objective and defined criteria,\" but instead \"can deny the requested relief for any constitutionally permissible reason or for no reason at all,\" ibid., the State has not created a constitutionally protected liberty interest. See id., at 466-467 (opinion of the Court); see also Vitek v. Jones, 445 U. S., at 488-491 (summarizing cases).\\nHawaii\\'s prison regulations place no substantive limitations on official discretion and thus create no liberty interest entitled to protection under the Due Process Clause. As Rule IV itself makes clear, and as the Supreme Court of Hawaii has held in Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981, the prison Administrator\\'s discretion to transfer an inmate is completely unfettered. No standards govern or restrict the Administrator\\'s determination. Because the Administrator is the only decisionmaker under Rule IV, we need not decide whether the introductory paragraph *250 of Rule IV, see n. 1, supra, places any substantive limitations on the purely advisory Program Committee.[10]\\nThe Court of Appeals thus erred in attributing significance to the fact that the prison regulations require a particular kind of hearing before the Administrator can exercise his unfettered discretion.[11] As the United States Court of Appeals for the Seventh Circuit recently stated in Shango v. Jurich, 681 F. 2d 1091, 1100-1101 (1982), \"[a] liberty interest is of course a substantive interest of an individual; it cannot be the right to demand needless formality.\"[12] Process is not an end in itself. Its constitutional purpose is to protect a substantive interest to which the individual has a legitimate claim of entitlement. See generally Simon, Liberty and Property in the Supreme Court: A Defense of Roth and Perry, 71 Calif. L. Rev. 146, 186 (1983). If officials may transfer a prisoner \"for whatever reason or for no reason at all,\" Meachum, 427 U. S., at 228, there is no such interest for process to protect. The State may choose to require procedures for reasons other than protection against deprivation of substantive *251 rights, of course,[13] but in making that choice the State does not create an independent substantive right. See Hewitt v. Helms, 459 U. S. 460, 471 (1983).\\n\\nIV\\nIn sum, we hold that the transfer of respondent from Hawaii to California did not implicate the Due Process Clause directly, and that Hawaii\\'s prison regulations do not create a protected liberty interest.[14] Accordingly, the judgment of the Court of Appeals is\\nReversed.\\nJUSTICE MARSHALL, with whom JUSTICE BRENNAN joins, and with whom JUSTICE STEVENS joins as to Part I, dissenting.\\nIn my view, the transfer of respondent Delbert Kaahanui Wakinekona from a prison in Hawaii to a prison in California implicated an interest in liberty protected by the Due Process Clause of the Fourteenth Amendment. I respectfully dissent.\\n\\nI\\nAn inmate\\'s liberty interest is not limited to whatever a State chooses to bestow upon him. An inmate retains a significant residuum of constitutionally protected liberty following his incarceration independent of any state law. As we stated in Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974): \"[A] prisoner is not wholly stripped of constitutional protections when he is imprisoned for crime. There is no iron curtain drawn between the Constitution and the prisons *252 of this country. . . . [Prisoners] may not be deprived of life, liberty, or property without due process of law.\"\\nIn determining whether a change in the conditions of imprisonment implicates a prisoner\\'s retained liberty interest, the relevant question is whether the change constitutes a sufficiently \"grievous loss\" to trigger the protection of due process. Vitek v. Jones, 445 U. S. 480, 488 (1980). See Morrissey v. Brewer, 408 U. S. 471, 481 (1972), citing Joint Anti-Fascist Refugee Committee v. McGrath, 341 U. S. 123, 168 (1951) (Frankfurter, J., concurring). The answer depends in part on a comparison of \"the treatment of the particular prisoner with the customary, habitual treatment of the population of the prison as a whole.\" Hewitt v. Helms, 459 U. S. 460, 486 (1983) (STEVENS, J., dissenting). This principle was established in our decision in Vitek, which held that the transfer of an inmate from a prison to a mental hospital implicated a liberty interest because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" 445 U. S., at 493. Because a significant qualitative change in the conditions of confinement is not \"within the range of conditions of confinement to which a prison sentence subjects an individual,\" ibid., such a change implicates a prisoner\\'s protected liberty interest.\\nThere can be little doubt that the transfer of Wakinekona from a Hawaii prison to a prison in California represents a substantial qualitative change in the conditions of his confinement. In addition to being incarcerated, which is the ordinary consequence of a criminal conviction and sentence, Wakinekona has in effect been banished from his home, a punishment historically considered to be \"among the severest.\"[1] For an indeterminate period of time, possibly the *253 rest of his life, nearly 2,500 miles of ocean will separate him from his family and friends. As a practical matter, Wakinekona may be entirely cut off from his only contacts with the outside world, just as if he had been imprisoned in an institution which prohibited visits by outsiders. Surely the isolation imposed on him by the transfer is far more drastic than that which normally accompanies imprisonment.\\nI cannot agree with the Court that Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236, 243 (1976), compel the conclusion that Wakinekona\\'s transfer implicates no liberty interest. Ante, at 248. Both cases involved transfers of prisoners between institutions located within the same State in which they were convicted, and the Court expressly phrased its holdings in terms of intrastate transfers.[2] Both decisions rested on the premise that no liberty interest is implicated by an initial decision to place a prisoner in one institution in the State rather than another. See Meachum, supra, at 224; Montanye, supra, at 243. On the basis of that premise, the Court concluded that the subsequent transfer of a prisoner to a different facility within the State likewise implicates no liberty interest. In this case, however, we cannot assume that a State\\'s initial placement of an individual in a prison far removed from his family and residence would raise no due process questions. None of our *254 prior decisions has indicated that such a decision would be immune from scrutiny under the Due Process Clause.\\nActual experience simply does not bear out the Court\\'s assumptions that interstate transfers are routine and that it is \"not unusual\" for a prisoner \"to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced.\" Ante, at 247. In Hawaii less than three percent of the state prisoners were transferred to prisons in other jurisdictions in 1979, and on a nationwide basis less than one percent of the prisoners held in state institutions were transferred to other jurisdictions.[3] Moreover, the vast majority of state prisoners are held in facilities located less than 250 miles from their homes.[4] Measured against these norms, Wakinekona\\'s transfer to a California prison represents a punishment \"qualitively different from the punishment characteristically suffered by a person convicted of crime.\" Vitek v. Jones, supra, at 493.\\nI therefore cannot agree that a State may transfer its prisoners at will, to any place, for any reason, without ever implicating any interest in liberty protected by the Due Process Clause.\\n\\nII\\nNor can I agree with the majority\\'s conclusion that Hawaii\\'s prison regulations do not create a liberty interest. This Court\\'s prior decisions establish that a liberty interest *255 may be \"created\"[5] by state laws, prison rules, regulations, or practices. State laws that impose substantive criteria which limit or guide the discretion of officials have been held to create a protected liberty interest. See, e. g., Hewitt v. Helms, 459 U. S. 460 (1983); Wolff v. McDonnell, 418 U. S. 539 (1974); Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979); Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). By contrast, a liberty interest is not created by a law which \"imposes no conditions on [prison officials\\'] discretionary power,\" Montanye, supra, at 243, authorizes prison officials to act \"for whatever reason or for no reason at all,\" Meachum, supra, at 228, or accords officials \"unfettered discretion,\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 466 (1981).\\nThe Court misapplies these principles in concluding that Hawaii\\'s prison regulations leave prison officials with unfettered discretion to transfer inmates. Ante, at 249-250. Rule IV establishes a scheme under which inmates are classified upon initial placement in an institution, and must subsequently be reclassified before they can be transferred to another institution. Under the Rule the standard for classifying inmates is their \"optimum placement within the Corrections Division\" in light of the \"best interests of the individual, the State, and the community.\"[6] In classifying inmates, the Program *256 Committee may not consider punitive aims. It may consider only factors relevant to determining where the individual will be \"best situated,\" such as \"his history, his changing needs, the resources and facilities available to the Corrections Divisions, the other inmates/wards, the exigencies of the community, and any other relevant factors.\" Paragraph 3 of Rule IV establishes a detailed set of procedures applicable when, as in this case, the reclassification of a prisoner may lead to a transfer involving a \"grievous loss,\" a phrase contained in the Rule itself.[7] The procedural rules are cast in mandatory language, and cover such matters as notice, access to information, hearing, confrontation and cross-examination, and the basis on which the Committee is to make its recommendation to the facility administrator.\\nThe limitations imposed by Rule IV are at least as substantial as those found sufficient to create a liberty interest in Hewitt v. Helms, supra, decided earlier this Term. In Hewitt an inmate contended that his confinement in administrative custody implicated an interest in liberty protected by the Due Process Clause. State law provided that a prison official could place inmates in administrative custody \"upon his assessment of the situation and the need for control,\" or \"where it has been determined that there is a threat of a serious disturbance, or a serious threat to the individual or others,\" and mandated certain procedures such as notice and a *257 hearing.[8] This Court construed the phrases \" `the need for control,\\' or `the threat of a serious disturbance,\\' \" as \"substantive predicates\" which restricted official discretion. Id., at 472. These restrictions, in combination with the mandatory procedural safeguards, \"deman[ded] a conclusion that the State has created a protected liberty interest.\" Ibid.\\nRule IV is not distinguishable in any meaningful respect from the provisions at issue in Helms. The procedural requirements contained in Rule IV are, if anything, far more elaborate than those involved in Helms, and are likewise couched in \"language of an unmistakably mandatory character.\" Id., at 471. Moreover, Rule IV, to no less an extent than the state law at issue in Helms, imposes substantive criteria restricting official discretion. In Helms this Court held that a statutory phrase such as \"the need for control\" constituted a limitation on the discretion of prison officials to place inmates in administrative custody. In my view Rule IV, which states that transfers are intended to ensure an inmate\\'s \"optimum placement\" in accordance with considerations which include \"his changing needs [and] the resources and facilities available to the Corrections Division,\" also restricts official discretion in ordering transfers.[9]\\nThe Court suggests that, even if the Program Committee does not have unlimited discretion in making recommendations for classifications and transfers, this cannot give rise to a state-created liberty interest because the prison Administrator retains \"completely unfettered\" \"discretion to transfer *258 an inmate,\" ante, at 249. I disagree. Rule IV, ¶ 3(d)(3), provides for review by the prison Administrator of recommendations forwarded to him by the Program Committee.[10] Even if this provision must be construed as authorizing the Administrator to transfer a prisoner for wholly arbitrary reasons,[11] that mere possibility does not defeat the protectible expectation otherwise created by Hawaii\\'s reclassification and transfer scheme that transfers will take place only if required to ensure an inmate\\'s optimum placement. In Helms a prison regulation also left open the possibility that the Superintendent could decide, for any reason or no reason at all, whether an inmate should be confined in administrative custody.[12] This Court nevertheless held that the state scheme as a whole created an interest in liberty protected by the Due Process Clause. 459 U. S., at 471-472. Helms thus necessarily rejects the view that state laws which impose substantive *259 limitations and elaborate procedural requirements on official conduct create no liberty interest solely because there remains the possibility that an official will act in an arbitrary manner at the end of the process.[13]\\nFor the foregoing reasons, I dissent.\\nNOTES\\n[*]  Briefs of amici curiae urging reversal were filed for the State of Alaska et al. by Paul L. Douglas, Attorney General of Nebraska, J. Kirk Brown, Assistant Attorney General, Judith W. Rogers, Corporation Counsel of the District of Columbia, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William J. Guste, Jr., of Louisiana, William A. Allain of Mississippi, Michael T. Greely of Montana, Richard H. Bryan of Nevada, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Gerald L. Baliles of Virginia, Kenneth O. Eikenberry of Washington, Chauncey H. Browning of West Virginia, Bronson C. La Follette of Wisconsin, and Steven F. Freudenthal of Wyoming; and for the Commonwealth of Massachusetts et al. by Francis X. Bellotti, Attorney General of Massachusetts, Stephen R. Delinsky, Barbara A. H. Smith, and Leo J. Cushing, Assistant Attorneys General, Anthony Ching, Solicitor General of Arizona, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William A. Allain of Mississippi, Michael T. Greely of Montana, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert O. Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Chauncey H. Browning of West Virginia, and Bronson C. La Follette of Wisconsin.\\n[1]  Paragraph 1 of Rule IV states:\\n\\n\"An inmate\\'s . . . classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates . . . , the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[2]  Petitioners concede, \"for purposes of the argument,\" that respondent suffered a \"grievous loss\" within the meaning of Rule IV when he was transferred from Hawaii to the mainland. Tr. of Oral Arg. 9, 25.\\n[3]  Rule V provides that an inmate may retain legal counsel if his hearing concerns a \"potential Interstate transfer.\" App. 25.\\n[4]  Respondent also had alleged that the transfer violated the Hawaii Constitution and state regulations and statutes. In light of its dismissal of respondent\\'s federal claims, the District Court declined to exercise pendent jurisdiction over these state-law claims. 459 F. Supp., at 476.\\n[5]  Several months before the Court of Appeals handed down its decision, the Supreme Court of Hawaii had held that because Hawaii\\'s prison regulations do not limit the Administrator\\'s discretion to transfer prisoners to the mainland, they do not create any liberty interest. Lono v. Ariyoshi, 63 Haw. 138, 621 P. 2d 976 (1981). In a petition for rehearing in the present case, petitioners directed the Ninth Circuit\\'s attention to the Lono decision. See 664 F. 2d, at 714. The Court of Appeals, however, concluded that the Hawaii court\\'s interpretation of the regulations was not different from its own; the Hawaii court merely had reached a different result on the \"federal question.\" The Court of Appeals thus adhered to its resolution of the case. Id., at 714-715.\\n[6]  Indeed, in Vitek itself the Court did not read Meachum and Montanye as stating a rule applicable only to intrastate transfers. The Court stated: \"In Meachum v. Fano . . . and Montanye v. Haymes . . . we held that the transfer of a prisoner from one prison to another does not infringe a protected liberty interest.\" 445 U. S., at 489 (emphasis added). The Court\\'s other cases describing Meachum and Montanye also have eschewed the narrow reading respondent now proposes. See Hewitt v. Helms, 459 U. S. 460, 467-468 (1983); Moody v. Daggett, 429 U. S. 78, 88, n. 9 (1976).\\n[7]  This statute has been invoked to transfer prisoners from Hawaii state facilities to federal prisons on the mainland. See Anthony v. Wilkinson, 637 F. 2d 1130 (CA7 1980), vacated and remanded sub nom. Hawaii v. Mederios, 453 U. S. 902 (1981).\\n[8]  After the decisions in Meachum and Montanye, courts almost uniformly have held that an inmate has no entitlement to remain in a prison in his home State. See Beshaw v. Fenton, 635 F. 2d 239, 246-247 (CA3 1980), cert. denied, 453 U. S. 912 (1981); Cofone v. Manson, 594 F. 2d 934, 937, n. 4 (CA2 1979); Sisbarro v. Warden, 592 F. 2d 1, 3 (CA1), cert. denied, 444 U. S. 849 (1979); Fletcher v. Warden, 467 F. Supp. 777, 779-780 (Kan. 1979); Curry-Bey v. Jackson, 422 F. Supp. 926, 931-933 (DC 1976); McDonnell v. United States Attorney General, 420 F. Supp. 217, 220 (ED Ill. 1976); Goodnow v. Perrin, 120 N. H. 669, 671, 421 A. 2d 1008, 1010 (1980); Girouard v. Hogan, 135 Vt. 448, 449-450, 378 A. 2d 105, 106-107 (1977); In re Young, 95 Wash. 2d 216, 227-228, 622 P. 2d 373, 379 (1980); cf. Fajeriak v. McGinnis, 493 F. 2d 468 (CA9 1974) (pre-Meachum transfers from Alaska to other States); Hillen v. Director of Department of Social Services, 455 F. 2d 510 (CA9), cert. denied, 409 U. S. 989 (1972) (pre-Meachum transfer from Hawaii to California). But see In re Young, 95 Wash. 2d, at 233, 622 P. 2d, at 382 (concurring opinion); State ex rel. Olson v. Maxwell, 259 N. W. 2d 621 (N. D. 1977); cf. Tai v. Thompson, 387 F. Supp. 912 (Haw. 1975) (pre-Meachum transfer).\\n[9]  Respondent\\'s argument to the contrary is unpersuasive. The Court in Montanye took note that among the hardships that may result from a prison transfer are separation of the inmate from home and family, separation from inmate friends, placement in a new and possibly hostile environment, difficulty in making contact with counsel, and interruption of educational and rehabilitative programs. 427 U. S., at 241, n. 4. These are the same hardships respondent faces as a result of his transfer from Hawaii to California.\\n\\nRespondent attempts to analogize his transfer to banishment in the English sense of \"beyond the seas,\" arguing that banishment surely is not within the range of confinement justified by his sentence. But respondent in no sense has been banished; his conviction, not the transfer, deprived him of his right freely to inhabit the State. The fact that his confinement takes place outside Hawaii is merely a fortuitous consequence of the fact that he must be confined, not an additional element of his punishment. See Girouard v. Hogan, 135 Vt., at 449-450, 378 A. 2d, at 106-107. Moreover, respondent has not been exiled; he remains within the United States.\\nIn essence, respondent\\'s banishment argument simply restates his claim that a transfer from Hawaii to the mainland is different in kind from other transfers. As has been shown in the text, however, respondent\\'s transfer was authorized by his conviction. A conviction, whether in Hawaii, Alaska, or one of the contiguous 48 States, empowers the State to confine the inmate in any penal institution in any State unless there is state law to the contrary or the reason for confining the inmate in a particular institution is itself constitutionally impermissible. See Montanye, 427 U. S., at 242; id., at 244 (dissenting opinion); Cruz v. Beto, 405 U. S. 319 (1972); Fajeriak v. McGinnis, 493 F. 2d, at 470.\\n[10]  In Hewitt v. Helms, 459 U. S. 460 (1983), unlike this case, state law limited the decisionmakers\\' discretion. To the extent the dissent doubts that the Administrator\\'s discretion under Rule IV is truly unfettered, post, at 258, and n. 11, it doubts the ability or authority of the Hawaii Supreme Court to construe state law.\\n[11]  In Meachum itself, the Court of Appeals had interpreted the applicable regulations as entitling inmates to a pretransfer hearing, see Fano v. Meachum, 520 F. 2d 374, 379-380 (CA1 1975), but this Court held that state law created no liberty interest.\\n[12]  Other courts agree that an expectation of receiving process is not, without more, a liberty interest protected by the Due Process Clause. See, e. g., United States v. Jiles, 658 F. 2d 194, 200 (CA3 1981), cert. denied, 455 U. S. 923 (1982); Bills v. Henderson, 631 F. 2d 1287, 1298-1299 (CA6 1980); Pugliese v. Nelson, 617 F. 2d 916, 924-925 (CA2 1980); Cofone v. Manson, 594 F. 2d, at 938; Lombardo v. Meachum, 548 F. 2d 13, 14-16 (CA1 1977); Adams v. Wainwright, 512 F. Supp. 948, 953 (ND Fla. 1981); Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981.\\n[13]  Petitioners assert that the hearings required by Rule IV not only enable the officials to gather information and thereby to exercise their discretion intelligently, but also have a therapeutic purpose: inmate participation in the decisionmaking process, it is hoped, reduces tension in the prison. See Tr. of Oral Arg. 52-53.\\n[14]  In light of this conclusion, respondent\\'s claim of bias in the composition of the prison Program Committee becomes irrelevant.\\n[1]  4 J. Elliott, Debates on the Federal Constitution 555 (1836). Whether it is called banishment, exile, deportation, relegation, or transportation, compelling a person \"to quit a city, place, or country, for a specified period of time, or for life,\" has long been considered a unique and severe deprivation, and was specifically outlawed by \"[t]he twelfth section of the English Habeas Corpus Act, 31 Car. II, one of the three great muniments of English liberty.\" United States v. Ju Toy, 198 U. S. 253, 269-270 (1905) (Brewer, J., dissenting).\\n[2]  Thus in Meachum the Court stated that the State, by convicting the defendant, was \"empower[ed] to confine him in any of its prisons,\" 427 U. S., at 224 (emphasis deleted), that a \"transfer from one institution to another within the state prison system\" implicated no due process interest, id., at 225, and that \"[c]onfinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Ibid. See also Montanye, 427 U. S., at 242 (\"We held in Meachum v. Fano, that no Due Process Clause liberty interest of a duly convicted prison inmate is infringed when he is transferred from one prison to another within the State\").\\n[3]  U. S. Dept. of Justice, Bureau of Justice Statistics, Sourcebook of Criminal Justice Statistics \\x97 1981, Table 6.27, pp. 478-479 (T. Flanagan, D. Van Alstyne, & M. Gottfredson eds. 1982). These figures reflect \"all inmates who were transferred from one State\\'s jurisdiction to another to continue sentences already in force,\" and \"[d]oes not include the release if [the] State does not relinquish jurisdiction.\" Id., at 590.\\n[4]  U. S. Dept. of Justice, Profile of State Prison Inmates: Sociodemographic Findings from the 1974 Survey of Inmates of State Correctional Facilities 1 (1979). Over 70 percent of state inmates are held in institutions located less than 250 miles from their homes.\\n[5]  But see Hewitt v. Helms, 459 U. S. 460, 488 (1983) (STEVENS, J., dissenting) (Prison regulations \"provide evidentiary support for the conclusion that the transfer affects a constitutionally protected interest in liberty,\" but they \"do not create that interest\" (emphasis in original)).\\n[6]  Paragraph 1 of Rule IV provides:\\n\\n\"An inmate\\'s/ward\\'s classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates/wards, the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[7]  While the term \"grievous loss\" is not explicitly defined, the prison regulations treat a transfer to the mainland as a grievous loss entitling an inmate to the procedural rights established in Rule IV, ¶ 3. This is readily inferred from Rule IV, ¶ 3, which states that intrastate transfers do not involve a grievous loss, and Rule V, which permits inmates to retain counsel only in specified circumstances, one of which is a reclassification that may result in an interstate transfer. App. 25.\\n[8]  See 459 U. S., at 470-471, n. 6.\\n[9]  See also Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). In that case, the District Court held that the language of a prison policy statement, stating that \"[i]nmates may be segregated for medical, psychiatric, disciplinary, or administrative reasons,\" 462 F. Supp., at 403, was sufficient to create a protected expectation that an inmate would not be segregated for arbitrary reasons. See also Bills v. Henderson, 631 F. 2d 1287, 1293 (CA6 1980), cert. denied, 449 U. S. 1093 (1981); Winsett v. McGinnes, 617 F. 2d 996, 107 (CA3 1980) (en banc).\\n[10]  Rule IV, ¶ 3(d)(3), provides:\\n\\n\"The facility administrator will, within a reasonable period of time, review the Program Committee\\'s recommendation. He may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate/ward, other inmates/wards, institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" App. 21.\\n[11]  I doubt that Rule IV would be construed to permit the Administrator to order a transfer for punitive reasons, since Rule IV expressly disallows punitive transfers.\\n[12]  That provision stated: \"All decisions of the Program Review Committee shall be reviewed by the Superintendent for his sustaining the decision or amending or reversing the decision in favor of the inmate.\" Pennsylvania Bureau of Correction Administrative Directive BC-ADM 801, Rule III(H)(7). App. to Brief for Respondent in Hewitt v. Helms, O. T. 1982, No. 81-638, p. 12a. Because an inmate could be confined in administrative custody only if the Program Review Committee determined that such confinement is and continues to be \"appropriate,\" id., at 18a, the Superintendent in Helms was the \"decisionmaker,\" ante, at 249-250, who determined whether inmates would be held in administrative custody.\\n[13]  This view was also implicitly rejected in Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979). The Court held that the Nebraska statute governing the decision whether or not to grant parole created a \"protectible entitlement,\" id., at 12, even though the statute, which listed a number of factors to be considered in the parole decision, also authorized the Parole Board to deny parole on the basis of \"[a]ny other factors the board determines to be relevant.\" Id., at 18.\\n\\nTo the extent that Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981), on which the majority relies, ante, at 249, suggests that no liberty interest is created as state law has not entirely eliminated the possibility of arbitrary action, it is inconsistent with both Helms and Greenholtz.\\n'},\n",
       " {'meta': {'case_jurisdiction': 'scotus.tar.gz',\n",
       "   'case_ID': '110921.json',\n",
       "   'date_created': '2010-04-28T17:12:49Z'},\n",
       "  'text': '\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General.\\nRobert Gilbert Johnston argued the cause for respondent. With him on the brief was Clayton C. Ikei.[*]\\n*240 JUSTICE BLACKMUN delivered the opinion of the Court.\\nThe issue in this case is whether the transfer of a prisoner from a state prison in Hawaii to one in California implicates a liberty interest within the meaning of the Due Process Clause of the Fourteenth Amendment.\\n\\nI\\n\\nA\\nRespondent Delbert Kaahanui Wakinekona is serving a sentence of life imprisonment without the possibility of parole as a result of his murder conviction in a Hawaii state court. He also is serving sentences for various other crimes, including rape, robbery, and escape. At the Hawaii State Prison outside Honolulu, respondent was classified as a maximum security risk and placed in the maximum control unit.\\nPetitioner Antone Olim is the Administrator of the Hawaii State Prison. The other petitioners constituted a prison \"Program Committee.\" On August 2, 1976, the Committee held hearings to determine the reasons for a breakdown in discipline and the failure of certain programs within the prison\\'s maximum control unit. Inmates of the unit appeared at these hearings. The Committee singled out respondent and another inmate as troublemakers. On August 5, respondent received notice that the Committee, at a hearing to be held on August 10, would review his correctional program to determine whether his classification within the system should be changed and whether he should be transferred to another Hawaii facility or to a mainland institution.\\n*241 The August 10 hearing was conducted by the same persons who had presided over the hearings on August 2. Respondent retained counsel to represent him. The Committee recommended that respondent\\'s classification as a maximum security risk be continued and that he be transferred to a prison on the mainland. He received the following explanation from the Committee:\\n\"The Program Committee, having reviewed your entire file, your testimony and arguments by your counsel, concluded that your control classification remains at Maximum. You are still considered a security risk in view of your escapes and subsequent convictions for serious felonies. The Committee noted the progress you made in vocational training and your expressed desire to continue in this endeavor. However your relationship with staff, who reported that you threaten and intimidate them, raises grave concerns regarding your potential for further disruptive and violent behavior. Since there is no other Maximum security prison in Hawaii which can offer you the correctional programs you require and you cannot remain at [the maximum control unit] because of impending construction of a new facility, the Program Committee recommends your transfer to an institution on the mainland.\" App. 7-8.\\nPetitioner Olim, as Administrator, accepted the Committee\\'s recommendation, and a few days later respondent was transferred to Folsom State Prison in California.\\n\\nB\\nRule IV of the Supplementary Rules and Regulations of the Corrections Division, Department of Social Services and Housing, State of Hawaii, approved in June 1976, recites that the inmate classification process is not concerned with punishment. Rather, it is intended to promote the best interests *242 of the inmate, the State, and the prison community.[1] Paragraph 3 of Rule IV requires a hearing prior to a prison transfer involving \"a grievous loss to the inmate,\" which the Rule defines \"generally\" as \"a serious loss to a reasonable man.\" App. 21.[2] The Administrator, under ¶ 2 of the Rule, is required to establish \"an impartial Program Committee\" to conduct such a hearing, the Committee to be \"composed of at least three members who were not actively involved in the process by which the inmate . . . was brought before the Committee.\" App. 20. Under ¶ 3, the Committee must give the inmate written notice of the hearing, permit him, with certain stated exceptions, to confront and cross-examine witnesses, afford him an opportunity to be heard, and apprise him of the Committee\\'s findings. App. 21-24.[3]\\nThe Committee is directed to make a recommendation to the Administrator, who then decides what action to take:\\n\"[The Administrator] may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate *243. . . , other inmates . . . , institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" Rule IV, ¶ 3d(3), App. 24.\\nThe regulations contain no standards governing the Administrator\\'s exercise of his discretion. See Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981).\\n\\nC\\nRespondent filed suit under 42 U. S. C. § 1983 against petitioners as the state officials who caused his transfer. He alleged that he had been denied procedural due process because the Committee that recommended his transfer consisted of the same persons who had initiated the hearing, this being in specific violation of Rule IV, ¶ 2, and because the Committee was biased against him. The United States District Court for the District of Hawaii dismissed the complaint, holding that the Hawaii regulations governing prison transfers do not create a substantive liberty interest protected by the Due Process Clause. 459 F. Supp. 473 (1978).[4]\\nThe United States Court of Appeals for the Ninth Circuit, by a divided vote, reversed. 664 F. 2d 708 (1981). It held that Hawaii had created a constitutionally protected liberty interest by promulgating Rule IV. In so doing, the court declined to follow cases from other Courts of Appeals holding that certain procedures mandated by prison transfer regulations do not create a liberty interest. See, e. g., Cofone v. Manson, 594 F. 2d 934 (CA2 1979); Lombardo v. Meachum, 548 F. 2d 13 (CA1 1977). The court reasoned that Rule IV gives Hawaii prisoners a justifiable expectation that they will not be transferred to the mainland absent a hearing, before an impartial committee, concerning the facts alleged in the *244 prehearing notice.[5] Because the Court of Appeals\\' decision created a conflict among the Circuits, and because the case presents the further question whether the Due Process Clause in and of itself protects against interstate prison transfers, we granted certiorari. 456 U. S. 1005 (1982).\\n\\nII\\nIn Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236 (1976), this Court held that an intrastate prison transfer does not directly implicate the Due Process Clause of the Fourteenth Amendment. In Meachum, inmates at a Massachusetts medium security prison had been transferred to a maximum security prison in that Commonwealth. In Montanye, a companion case, an inmate had been transferred from one maximum security New York prison to another as punishment for a breach of prison rules. This Court rejected \"the notion that any grievous loss visited upon a person by the State is sufficient to invoke the procedural protections of the Due Process Clause.\" Meachum, 427 U. S., at 224 (emphasis in original). It went on to state:\\n\"The initial decision to assign the convict to a particular institution is not subject to audit under the Due Process Clause, although the degree of confinement in one prison may be quite different from that in another. The conviction has sufficiently extinguished the defendant\\'s liberty *245 interest to empower the State to confine him in any of its prisons.\\n\"Neither, in our view, does the Due Process Clause in and of itself protect a duly convicted prisoner against transfer from one institution to another within the state prison system. Confinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Id., at 224-225 (emphasis in original).\\nThe Court observed that, although prisoners retain a residuum of liberty, see Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974), a holding that \"any substantial deprivation imposed by prison authorities triggers the procedural protections of the Due Process Clause would subject to judicial review a wide spectrum of discretionary actions that traditionally have been the business of prison administrators rather than of the federal courts.\" 427 U. S., at 225 (emphasis in original).\\nApplying the Meachum and Montanye principles in Vitek v. Jones, 445 U. S. 480 (1980), this Court held that the transfer of an inmate from a prison to a mental hospital did implicate a liberty interest. Placement in the mental hospital was \"not within the range of conditions of confinement to which a prison sentence subjects an individual,\" because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" Id., at 493. Respondent argues that the same is true of confinement of a Hawaii prisoner on the mainland, and that Vitek therefore controls.\\nWe do not agree. Just as an inmate has no justifiable expectation that he will be incarcerated in any particular prison within a State, he has no justifiable expectation that he will be incarcerated in any particular State.[6] Often, confinement *246 in the inmate\\'s home State will not be possible. A person convicted of a federal crime in a State without a federal correctional facility usually will serve his sentence in another State. Overcrowding and the need to separate particular prisoners may necessitate interstate transfers. For any number of reasons, a State may lack prison facilities capable of providing appropriate correctional programs for all offenders.\\nStatutes and interstate agreements recognize that, from time to time, it is necessary to transfer inmates to prisons in other States. On the federal level, 18 U. S. C. § 5003(a) authorizes the Attorney General to contract with a State for the transfer of a state prisoner to a federal prison, whether in that State or another. See Howe v. Smith, 452 U. S. 473 (1981).[7] Title 18 U. S. C. § 4002 (1976 ed. and Supp. V) permits the Attorney General to contract with any State for the placement of a federal prisoner in state custody for up to three years. Neither statute requires that the prisoner remain in the State in which he was convicted and sentenced.\\nOn the state level, many States have statutes providing for the transfer of a state prisoner to a federal prison, e. g., Haw. Rev. Stat. § 353-18 (1976), or another State\\'s prison, e. g., Alaska Stat. Ann. § 33.30.100 (1982). Corrections compacts between States, implemented by statutes, authorize incarceration of a prisoner of one State in another State\\'s prison. See, e. g., Cal. Penal Code Ann. § 11189 (West 1982) (codifying Interstate Corrections Compact); § 11190 (codifying Western Interstate Corrections Compact); Conn. Gen. *247 Stat. § 18-102 (1981) (codifying New England Interstate Corrections Compact); § 18-106 (codifying Interstate Corrections Compact); Haw. Rev. Stat. § 355-1 (1976) (codifying Western Interstate Corrections Compact); Idaho Code § 20-701 (1979) (codifying Interstate Corrections Compact); Ky. Rev. Stat. § 196.610 (1982) (same). And prison regulations such as Hawaii\\'s Rule IV anticipate that inmates sometimes will be transferred to prisons in other States.\\nIn short, it is neither unreasonable nor unusual for an inmate to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced, or to be transferred to an out-of-state prison after serving a portion of his sentence in his home State. Confinement in another State, unlike confinement in a mental institution, is \"within the normal limits or range of custody which the conviction has authorized the State to impose.\" Meachum, 427 U. S., at 225.[8] Even when, as here, the transfer involves long distances and an ocean crossing, the confinement remains within constitutional limits. The difference between such a transfer and an intrastate or interstate transfer of *248 shorter distance is a matter of degree, not of kind,[9] and Meachum instructs that \"the determining factor is the nature of the interest involved rather than its weight.\" 427 U. S., at 224. The reasoning of Meachum and Montanye compels the conclusion that an interstate prison transfer, including one from Hawaii to California, does not deprive an inmate of any liberty interest protected by the Due Process Clause in and of itself.\\n\\nIII\\nThe Court of Appeals held that Hawaii\\'s prison regulations create a constitutionally protected liberty interest. In Meachum, however, the State had \"conferred no right on the *249 prisoner to remain in the prison to which he was initially assigned, defeasible only upon proof of specific acts of misconduct,\" 427 U. S., at 226, and \"ha[d] not represented that transfers [would] occur only on the occurrence of certain events,\" id., at 228. Because the State had retained \"discretion to transfer [the prisoner] for whatever reason or for no reason at all,\" ibid., the Court found that the State had not created a constitutionally protected liberty interest. Similarly, because the state law at issue in Montanye \"impose[d] no conditions on the discretionary power to transfer,\" 427 U. S., at 243, there was no basis for invoking the protections of the Due Process Clause.\\nThese cases demonstrate that a State creates a protected liberty interest by placing substantive limitations on official discretion. An inmate must show \"that particularized standards or criteria guide the State\\'s decisionmakers.\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 467 (1981) (BRENNAN, J., concurring). If the decisionmaker is not \"required to base its decisions on objective and defined criteria,\" but instead \"can deny the requested relief for any constitutionally permissible reason or for no reason at all,\" ibid., the State has not created a constitutionally protected liberty interest. See id., at 466-467 (opinion of the Court); see also Vitek v. Jones, 445 U. S., at 488-491 (summarizing cases).\\nHawaii\\'s prison regulations place no substantive limitations on official discretion and thus create no liberty interest entitled to protection under the Due Process Clause. As Rule IV itself makes clear, and as the Supreme Court of Hawaii has held in Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981, the prison Administrator\\'s discretion to transfer an inmate is completely unfettered. No standards govern or restrict the Administrator\\'s determination. Because the Administrator is the only decisionmaker under Rule IV, we need not decide whether the introductory paragraph *250 of Rule IV, see n. 1, supra, places any substantive limitations on the purely advisory Program Committee.[10]\\nThe Court of Appeals thus erred in attributing significance to the fact that the prison regulations require a particular kind of hearing before the Administrator can exercise his unfettered discretion.[11] As the United States Court of Appeals for the Seventh Circuit recently stated in Shango v. Jurich, 681 F. 2d 1091, 1100-1101 (1982), \"[a] liberty interest is of course a substantive interest of an individual; it cannot be the right to demand needless formality.\"[12] Process is not an end in itself. Its constitutional purpose is to protect a substantive interest to which the individual has a legitimate claim of entitlement. See generally Simon, Liberty and Property in the Supreme Court: A Defense of Roth and Perry, 71 Calif. L. Rev. 146, 186 (1983). If officials may transfer a prisoner \"for whatever reason or for no reason at all,\" Meachum, 427 U. S., at 228, there is no such interest for process to protect. The State may choose to require procedures for reasons other than protection against deprivation of substantive *251 rights, of course,[13] but in making that choice the State does not create an independent substantive right. See Hewitt v. Helms, 459 U. S. 460, 471 (1983).\\n\\nIV\\nIn sum, we hold that the transfer of respondent from Hawaii to California did not implicate the Due Process Clause directly, and that Hawaii\\'s prison regulations do not create a protected liberty interest.[14] Accordingly, the judgment of the Court of Appeals is\\nReversed.\\nJUSTICE MARSHALL, with whom JUSTICE BRENNAN joins, and with whom JUSTICE STEVENS joins as to Part I, dissenting.\\nIn my view, the transfer of respondent Delbert Kaahanui Wakinekona from a prison in Hawaii to a prison in California implicated an interest in liberty protected by the Due Process Clause of the Fourteenth Amendment. I respectfully dissent.\\n\\nI\\nAn inmate\\'s liberty interest is not limited to whatever a State chooses to bestow upon him. An inmate retains a significant residuum of constitutionally protected liberty following his incarceration independent of any state law. As we stated in Wolff v. McDonnell, 418 U. S. 539, 555-556 (1974): \"[A] prisoner is not wholly stripped of constitutional protections when he is imprisoned for crime. There is no iron curtain drawn between the Constitution and the prisons *252 of this country. . . . [Prisoners] may not be deprived of life, liberty, or property without due process of law.\"\\nIn determining whether a change in the conditions of imprisonment implicates a prisoner\\'s retained liberty interest, the relevant question is whether the change constitutes a sufficiently \"grievous loss\" to trigger the protection of due process. Vitek v. Jones, 445 U. S. 480, 488 (1980). See Morrissey v. Brewer, 408 U. S. 471, 481 (1972), citing Joint Anti-Fascist Refugee Committee v. McGrath, 341 U. S. 123, 168 (1951) (Frankfurter, J., concurring). The answer depends in part on a comparison of \"the treatment of the particular prisoner with the customary, habitual treatment of the population of the prison as a whole.\" Hewitt v. Helms, 459 U. S. 460, 486 (1983) (STEVENS, J., dissenting). This principle was established in our decision in Vitek, which held that the transfer of an inmate from a prison to a mental hospital implicated a liberty interest because it brought about \"consequences . . . qualitatively different from the punishment characteristically suffered by a person convicted of crime.\" 445 U. S., at 493. Because a significant qualitative change in the conditions of confinement is not \"within the range of conditions of confinement to which a prison sentence subjects an individual,\" ibid., such a change implicates a prisoner\\'s protected liberty interest.\\nThere can be little doubt that the transfer of Wakinekona from a Hawaii prison to a prison in California represents a substantial qualitative change in the conditions of his confinement. In addition to being incarcerated, which is the ordinary consequence of a criminal conviction and sentence, Wakinekona has in effect been banished from his home, a punishment historically considered to be \"among the severest.\"[1] For an indeterminate period of time, possibly the *253 rest of his life, nearly 2,500 miles of ocean will separate him from his family and friends. As a practical matter, Wakinekona may be entirely cut off from his only contacts with the outside world, just as if he had been imprisoned in an institution which prohibited visits by outsiders. Surely the isolation imposed on him by the transfer is far more drastic than that which normally accompanies imprisonment.\\nI cannot agree with the Court that Meachum v. Fano, 427 U. S. 215 (1976), and Montanye v. Haymes, 427 U. S. 236, 243 (1976), compel the conclusion that Wakinekona\\'s transfer implicates no liberty interest. Ante, at 248. Both cases involved transfers of prisoners between institutions located within the same State in which they were convicted, and the Court expressly phrased its holdings in terms of intrastate transfers.[2] Both decisions rested on the premise that no liberty interest is implicated by an initial decision to place a prisoner in one institution in the State rather than another. See Meachum, supra, at 224; Montanye, supra, at 243. On the basis of that premise, the Court concluded that the subsequent transfer of a prisoner to a different facility within the State likewise implicates no liberty interest. In this case, however, we cannot assume that a State\\'s initial placement of an individual in a prison far removed from his family and residence would raise no due process questions. None of our *254 prior decisions has indicated that such a decision would be immune from scrutiny under the Due Process Clause.\\nActual experience simply does not bear out the Court\\'s assumptions that interstate transfers are routine and that it is \"not unusual\" for a prisoner \"to serve practically his entire sentence in a State other than the one in which he was convicted and sentenced.\" Ante, at 247. In Hawaii less than three percent of the state prisoners were transferred to prisons in other jurisdictions in 1979, and on a nationwide basis less than one percent of the prisoners held in state institutions were transferred to other jurisdictions.[3] Moreover, the vast majority of state prisoners are held in facilities located less than 250 miles from their homes.[4] Measured against these norms, Wakinekona\\'s transfer to a California prison represents a punishment \"qualitively different from the punishment characteristically suffered by a person convicted of crime.\" Vitek v. Jones, supra, at 493.\\nI therefore cannot agree that a State may transfer its prisoners at will, to any place, for any reason, without ever implicating any interest in liberty protected by the Due Process Clause.\\n\\nII\\nNor can I agree with the majority\\'s conclusion that Hawaii\\'s prison regulations do not create a liberty interest. This Court\\'s prior decisions establish that a liberty interest *255 may be \"created\"[5] by state laws, prison rules, regulations, or practices. State laws that impose substantive criteria which limit or guide the discretion of officials have been held to create a protected liberty interest. See, e. g., Hewitt v. Helms, 459 U. S. 460 (1983); Wolff v. McDonnell, 418 U. S. 539 (1974); Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979); Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). By contrast, a liberty interest is not created by a law which \"imposes no conditions on [prison officials\\'] discretionary power,\" Montanye, supra, at 243, authorizes prison officials to act \"for whatever reason or for no reason at all,\" Meachum, supra, at 228, or accords officials \"unfettered discretion,\" Connecticut Board of Pardons v. Dumschat, 452 U. S. 458, 466 (1981).\\nThe Court misapplies these principles in concluding that Hawaii\\'s prison regulations leave prison officials with unfettered discretion to transfer inmates. Ante, at 249-250. Rule IV establishes a scheme under which inmates are classified upon initial placement in an institution, and must subsequently be reclassified before they can be transferred to another institution. Under the Rule the standard for classifying inmates is their \"optimum placement within the Corrections Division\" in light of the \"best interests of the individual, the State, and the community.\"[6] In classifying inmates, the Program *256 Committee may not consider punitive aims. It may consider only factors relevant to determining where the individual will be \"best situated,\" such as \"his history, his changing needs, the resources and facilities available to the Corrections Divisions, the other inmates/wards, the exigencies of the community, and any other relevant factors.\" Paragraph 3 of Rule IV establishes a detailed set of procedures applicable when, as in this case, the reclassification of a prisoner may lead to a transfer involving a \"grievous loss,\" a phrase contained in the Rule itself.[7] The procedural rules are cast in mandatory language, and cover such matters as notice, access to information, hearing, confrontation and cross-examination, and the basis on which the Committee is to make its recommendation to the facility administrator.\\nThe limitations imposed by Rule IV are at least as substantial as those found sufficient to create a liberty interest in Hewitt v. Helms, supra, decided earlier this Term. In Hewitt an inmate contended that his confinement in administrative custody implicated an interest in liberty protected by the Due Process Clause. State law provided that a prison official could place inmates in administrative custody \"upon his assessment of the situation and the need for control,\" or \"where it has been determined that there is a threat of a serious disturbance, or a serious threat to the individual or others,\" and mandated certain procedures such as notice and a *257 hearing.[8] This Court construed the phrases \" `the need for control,\\' or `the threat of a serious disturbance,\\' \" as \"substantive predicates\" which restricted official discretion. Id., at 472. These restrictions, in combination with the mandatory procedural safeguards, \"deman[ded] a conclusion that the State has created a protected liberty interest.\" Ibid.\\nRule IV is not distinguishable in any meaningful respect from the provisions at issue in Helms. The procedural requirements contained in Rule IV are, if anything, far more elaborate than those involved in Helms, and are likewise couched in \"language of an unmistakably mandatory character.\" Id., at 471. Moreover, Rule IV, to no less an extent than the state law at issue in Helms, imposes substantive criteria restricting official discretion. In Helms this Court held that a statutory phrase such as \"the need for control\" constituted a limitation on the discretion of prison officials to place inmates in administrative custody. In my view Rule IV, which states that transfers are intended to ensure an inmate\\'s \"optimum placement\" in accordance with considerations which include \"his changing needs [and] the resources and facilities available to the Corrections Division,\" also restricts official discretion in ordering transfers.[9]\\nThe Court suggests that, even if the Program Committee does not have unlimited discretion in making recommendations for classifications and transfers, this cannot give rise to a state-created liberty interest because the prison Administrator retains \"completely unfettered\" \"discretion to transfer *258 an inmate,\" ante, at 249. I disagree. Rule IV, ¶ 3(d)(3), provides for review by the prison Administrator of recommendations forwarded to him by the Program Committee.[10] Even if this provision must be construed as authorizing the Administrator to transfer a prisoner for wholly arbitrary reasons,[11] that mere possibility does not defeat the protectible expectation otherwise created by Hawaii\\'s reclassification and transfer scheme that transfers will take place only if required to ensure an inmate\\'s optimum placement. In Helms a prison regulation also left open the possibility that the Superintendent could decide, for any reason or no reason at all, whether an inmate should be confined in administrative custody.[12] This Court nevertheless held that the state scheme as a whole created an interest in liberty protected by the Due Process Clause. 459 U. S., at 471-472. Helms thus necessarily rejects the view that state laws which impose substantive *259 limitations and elaborate procedural requirements on official conduct create no liberty interest solely because there remains the possibility that an official will act in an arbitrary manner at the end of the process.[13]\\nFor the foregoing reasons, I dissent.\\nNOTES\\n[*]  Briefs of amici curiae urging reversal were filed for the State of Alaska et al. by Paul L. Douglas, Attorney General of Nebraska, J. Kirk Brown, Assistant Attorney General, Judith W. Rogers, Corporation Counsel of the District of Columbia, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William J. Guste, Jr., of Louisiana, William A. Allain of Mississippi, Michael T. Greely of Montana, Richard H. Bryan of Nevada, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Gerald L. Baliles of Virginia, Kenneth O. Eikenberry of Washington, Chauncey H. Browning of West Virginia, Bronson C. La Follette of Wisconsin, and Steven F. Freudenthal of Wyoming; and for the Commonwealth of Massachusetts et al. by Francis X. Bellotti, Attorney General of Massachusetts, Stephen R. Delinsky, Barbara A. H. Smith, and Leo J. Cushing, Assistant Attorneys General, Anthony Ching, Solicitor General of Arizona, and the Attorneys General for their respective jurisdictions as follows: Wilson L. Condon of Alaska, Aviata F. Fa\\'alevao of American Samoa, Robert K. Corbin of Arizona, Jim Smith of Florida, David H. Leroy of Idaho, William A. Allain of Mississippi, Michael T. Greely of Montana, Irwin I. Kimmelman of New Jersey, Jeff Bingaman of New Mexico, Rufus L. Edmisten of North Carolina, Robert O. Wefald of North Dakota, William J. Brown of Ohio, Dennis J. Roberts II of Rhode Island, Mark V. Meierhenry of South Dakota, William M. Leech, Jr., of Tennessee, John J. Easton of Vermont, Chauncey H. Browning of West Virginia, and Bronson C. La Follette of Wisconsin.\\n[1]  Paragraph 1 of Rule IV states:\\n\\n\"An inmate\\'s . . . classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates . . . , the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[2]  Petitioners concede, \"for purposes of the argument,\" that respondent suffered a \"grievous loss\" within the meaning of Rule IV when he was transferred from Hawaii to the mainland. Tr. of Oral Arg. 9, 25.\\n[3]  Rule V provides that an inmate may retain legal counsel if his hearing concerns a \"potential Interstate transfer.\" App. 25.\\n[4]  Respondent also had alleged that the transfer violated the Hawaii Constitution and state regulations and statutes. In light of its dismissal of respondent\\'s federal claims, the District Court declined to exercise pendent jurisdiction over these state-law claims. 459 F. Supp., at 476.\\n[5]  Several months before the Court of Appeals handed down its decision, the Supreme Court of Hawaii had held that because Hawaii\\'s prison regulations do not limit the Administrator\\'s discretion to transfer prisoners to the mainland, they do not create any liberty interest. Lono v. Ariyoshi, 63 Haw. 138, 621 P. 2d 976 (1981). In a petition for rehearing in the present case, petitioners directed the Ninth Circuit\\'s attention to the Lono decision. See 664 F. 2d, at 714. The Court of Appeals, however, concluded that the Hawaii court\\'s interpretation of the regulations was not different from its own; the Hawaii court merely had reached a different result on the \"federal question.\" The Court of Appeals thus adhered to its resolution of the case. Id., at 714-715.\\n[6]  Indeed, in Vitek itself the Court did not read Meachum and Montanye as stating a rule applicable only to intrastate transfers. The Court stated: \"In Meachum v. Fano . . . and Montanye v. Haymes . . . we held that the transfer of a prisoner from one prison to another does not infringe a protected liberty interest.\" 445 U. S., at 489 (emphasis added). The Court\\'s other cases describing Meachum and Montanye also have eschewed the narrow reading respondent now proposes. See Hewitt v. Helms, 459 U. S. 460, 467-468 (1983); Moody v. Daggett, 429 U. S. 78, 88, n. 9 (1976).\\n[7]  This statute has been invoked to transfer prisoners from Hawaii state facilities to federal prisons on the mainland. See Anthony v. Wilkinson, 637 F. 2d 1130 (CA7 1980), vacated and remanded sub nom. Hawaii v. Mederios, 453 U. S. 902 (1981).\\n[8]  After the decisions in Meachum and Montanye, courts almost uniformly have held that an inmate has no entitlement to remain in a prison in his home State. See Beshaw v. Fenton, 635 F. 2d 239, 246-247 (CA3 1980), cert. denied, 453 U. S. 912 (1981); Cofone v. Manson, 594 F. 2d 934, 937, n. 4 (CA2 1979); Sisbarro v. Warden, 592 F. 2d 1, 3 (CA1), cert. denied, 444 U. S. 849 (1979); Fletcher v. Warden, 467 F. Supp. 777, 779-780 (Kan. 1979); Curry-Bey v. Jackson, 422 F. Supp. 926, 931-933 (DC 1976); McDonnell v. United States Attorney General, 420 F. Supp. 217, 220 (ED Ill. 1976); Goodnow v. Perrin, 120 N. H. 669, 671, 421 A. 2d 1008, 1010 (1980); Girouard v. Hogan, 135 Vt. 448, 449-450, 378 A. 2d 105, 106-107 (1977); In re Young, 95 Wash. 2d 216, 227-228, 622 P. 2d 373, 379 (1980); cf. Fajeriak v. McGinnis, 493 F. 2d 468 (CA9 1974) (pre-Meachum transfers from Alaska to other States); Hillen v. Director of Department of Social Services, 455 F. 2d 510 (CA9), cert. denied, 409 U. S. 989 (1972) (pre-Meachum transfer from Hawaii to California). But see In re Young, 95 Wash. 2d, at 233, 622 P. 2d, at 382 (concurring opinion); State ex rel. Olson v. Maxwell, 259 N. W. 2d 621 (N. D. 1977); cf. Tai v. Thompson, 387 F. Supp. 912 (Haw. 1975) (pre-Meachum transfer).\\n[9]  Respondent\\'s argument to the contrary is unpersuasive. The Court in Montanye took note that among the hardships that may result from a prison transfer are separation of the inmate from home and family, separation from inmate friends, placement in a new and possibly hostile environment, difficulty in making contact with counsel, and interruption of educational and rehabilitative programs. 427 U. S., at 241, n. 4. These are the same hardships respondent faces as a result of his transfer from Hawaii to California.\\n\\nRespondent attempts to analogize his transfer to banishment in the English sense of \"beyond the seas,\" arguing that banishment surely is not within the range of confinement justified by his sentence. But respondent in no sense has been banished; his conviction, not the transfer, deprived him of his right freely to inhabit the State. The fact that his confinement takes place outside Hawaii is merely a fortuitous consequence of the fact that he must be confined, not an additional element of his punishment. See Girouard v. Hogan, 135 Vt., at 449-450, 378 A. 2d, at 106-107. Moreover, respondent has not been exiled; he remains within the United States.\\nIn essence, respondent\\'s banishment argument simply restates his claim that a transfer from Hawaii to the mainland is different in kind from other transfers. As has been shown in the text, however, respondent\\'s transfer was authorized by his conviction. A conviction, whether in Hawaii, Alaska, or one of the contiguous 48 States, empowers the State to confine the inmate in any penal institution in any State unless there is state law to the contrary or the reason for confining the inmate in a particular institution is itself constitutionally impermissible. See Montanye, 427 U. S., at 242; id., at 244 (dissenting opinion); Cruz v. Beto, 405 U. S. 319 (1972); Fajeriak v. McGinnis, 493 F. 2d, at 470.\\n[10]  In Hewitt v. Helms, 459 U. S. 460 (1983), unlike this case, state law limited the decisionmakers\\' discretion. To the extent the dissent doubts that the Administrator\\'s discretion under Rule IV is truly unfettered, post, at 258, and n. 11, it doubts the ability or authority of the Hawaii Supreme Court to construe state law.\\n[11]  In Meachum itself, the Court of Appeals had interpreted the applicable regulations as entitling inmates to a pretransfer hearing, see Fano v. Meachum, 520 F. 2d 374, 379-380 (CA1 1975), but this Court held that state law created no liberty interest.\\n[12]  Other courts agree that an expectation of receiving process is not, without more, a liberty interest protected by the Due Process Clause. See, e. g., United States v. Jiles, 658 F. 2d 194, 200 (CA3 1981), cert. denied, 455 U. S. 923 (1982); Bills v. Henderson, 631 F. 2d 1287, 1298-1299 (CA6 1980); Pugliese v. Nelson, 617 F. 2d 916, 924-925 (CA2 1980); Cofone v. Manson, 594 F. 2d, at 938; Lombardo v. Meachum, 548 F. 2d 13, 14-16 (CA1 1977); Adams v. Wainwright, 512 F. Supp. 948, 953 (ND Fla. 1981); Lono v. Ariyoshi, 63 Haw., at 144-145, 621 P. 2d, at 980-981.\\n[13]  Petitioners assert that the hearings required by Rule IV not only enable the officials to gather information and thereby to exercise their discretion intelligently, but also have a therapeutic purpose: inmate participation in the decisionmaking process, it is hoped, reduces tension in the prison. See Tr. of Oral Arg. 52-53.\\n[14]  In light of this conclusion, respondent\\'s claim of bias in the composition of the prison Program Committee becomes irrelevant.\\n[1]  4 J. Elliott, Debates on the Federal Constitution 555 (1836). Whether it is called banishment, exile, deportation, relegation, or transportation, compelling a person \"to quit a city, place, or country, for a specified period of time, or for life,\" has long been considered a unique and severe deprivation, and was specifically outlawed by \"[t]he twelfth section of the English Habeas Corpus Act, 31 Car. II, one of the three great muniments of English liberty.\" United States v. Ju Toy, 198 U. S. 253, 269-270 (1905) (Brewer, J., dissenting).\\n[2]  Thus in Meachum the Court stated that the State, by convicting the defendant, was \"empower[ed] to confine him in any of its prisons,\" 427 U. S., at 224 (emphasis deleted), that a \"transfer from one institution to another within the state prison system\" implicated no due process interest, id., at 225, and that \"[c]onfinement in any of the State\\'s institutions is within the normal limits or range of custody which the conviction has authorized the State to impose.\" Ibid. See also Montanye, 427 U. S., at 242 (\"We held in Meachum v. Fano, that no Due Process Clause liberty interest of a duly convicted prison inmate is infringed when he is transferred from one prison to another within the State\").\\n[3]  U. S. Dept. of Justice, Bureau of Justice Statistics, Sourcebook of Criminal Justice Statistics \\x97 1981, Table 6.27, pp. 478-479 (T. Flanagan, D. Van Alstyne, & M. Gottfredson eds. 1982). These figures reflect \"all inmates who were transferred from one State\\'s jurisdiction to another to continue sentences already in force,\" and \"[d]oes not include the release if [the] State does not relinquish jurisdiction.\" Id., at 590.\\n[4]  U. S. Dept. of Justice, Profile of State Prison Inmates: Sociodemographic Findings from the 1974 Survey of Inmates of State Correctional Facilities 1 (1979). Over 70 percent of state inmates are held in institutions located less than 250 miles from their homes.\\n[5]  But see Hewitt v. Helms, 459 U. S. 460, 488 (1983) (STEVENS, J., dissenting) (Prison regulations \"provide evidentiary support for the conclusion that the transfer affects a constitutionally protected interest in liberty,\" but they \"do not create that interest\" (emphasis in original)).\\n[6]  Paragraph 1 of Rule IV provides:\\n\\n\"An inmate\\'s/ward\\'s classification determines where he is best situated within the Corrections Division. Rather than being concerned with isolated aspects of the individual or punishment (as is the adjustment process), classification is a dynamic process which considers the individual, his history, his changing needs, the resources and facilities available to the Corrections Division, the other inmates/wards, the exigencies of the community, and any other relevant factors. It never inflicts punishment; on the contrary, even the imposition of a stricter classification is intended to be in the best interests of the individual, the State, and the community. In short, classification is a continuing evaluation of each individual to ensure that he is given the optimum placement within the Corrections Division.\" App. 20.\\n[7]  While the term \"grievous loss\" is not explicitly defined, the prison regulations treat a transfer to the mainland as a grievous loss entitling an inmate to the procedural rights established in Rule IV, ¶ 3. This is readily inferred from Rule IV, ¶ 3, which states that intrastate transfers do not involve a grievous loss, and Rule V, which permits inmates to retain counsel only in specified circumstances, one of which is a reclassification that may result in an interstate transfer. App. 25.\\n[8]  See 459 U. S., at 470-471, n. 6.\\n[9]  See also Wright v. Enomoto, 462 F. Supp. 397 (ND Cal. 1976), summarily aff\\'d, 434 U. S. 1052 (1978). In that case, the District Court held that the language of a prison policy statement, stating that \"[i]nmates may be segregated for medical, psychiatric, disciplinary, or administrative reasons,\" 462 F. Supp., at 403, was sufficient to create a protected expectation that an inmate would not be segregated for arbitrary reasons. See also Bills v. Henderson, 631 F. 2d 1287, 1293 (CA6 1980), cert. denied, 449 U. S. 1093 (1981); Winsett v. McGinnes, 617 F. 2d 996, 107 (CA3 1980) (en banc).\\n[10]  Rule IV, ¶ 3(d)(3), provides:\\n\\n\"The facility administrator will, within a reasonable period of time, review the Program Committee\\'s recommendation. He may, as the final decisionmaker:\\n\"(a) Affirm or reverse, in whole or in part, the recommendation; or\\n\"(b) hold in abeyance any action he believes jeopardizes the safety, security, or welfare of the staff, inmate/ward, other inmates/wards, institution, or community and refer the matter back to the Program Committee for further study and recommendation.\" App. 21.\\n[11]  I doubt that Rule IV would be construed to permit the Administrator to order a transfer for punitive reasons, since Rule IV expressly disallows punitive transfers.\\n[12]  That provision stated: \"All decisions of the Program Review Committee shall be reviewed by the Superintendent for his sustaining the decision or amending or reversing the decision in favor of the inmate.\" Pennsylvania Bureau of Correction Administrative Directive BC-ADM 801, Rule III(H)(7). App. to Brief for Respondent in Hewitt v. Helms, O. T. 1982, No. 81-638, p. 12a. Because an inmate could be confined in administrative custody only if the Program Review Committee determined that such confinement is and continues to be \"appropriate,\" id., at 18a, the Superintendent in Helms was the \"decisionmaker,\" ante, at 249-250, who determined whether inmates would be held in administrative custody.\\n[13]  This view was also implicitly rejected in Greenholtz v. Nebraska Penal Inmates, 442 U. S. 1 (1979). The Court held that the Nebraska statute governing the decision whether or not to grant parole created a \"protectible entitlement,\" id., at 12, even though the statute, which listed a number of factors to be considered in the parole decision, also authorized the Parole Board to deny parole on the basis of \"[a]ny other factors the board determines to be relevant.\" Id., at 18.\\n\\nTo the extent that Lono v. Ariyoshi, 63 Haw. 138, 144-145, 621 P. 2d 976, 980-981 (1981), on which the majority relies, ante, at 249, suggests that no liberty interest is created as state law has not entirely eliminated the possibility of arbitrary action, it is inconsistent with both Helms and Greenholtz.\\n'}]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "from datasets import interleave_datasets\n",
    "combined_dataset = interleave_datasets([pubmed_dataset_streamed, law_dataset_streamed])\n",
    "list(islice(combined_dataset, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5595271",
   "metadata": {},
   "source": [
    "Here we've used the `islice()` function from Python's `itertools` module to select the first two examples from the combined dataset, and we can see that they match the first examples from each of the two source datasets.\n",
    "\n",
    "Finally, if you want to stream the Pile in its 825 GB entirety, you can grab all the prepared files as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f8cb9095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d01fb3e479401da06a7ca850b66e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ad49e2168ced215d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playing on the web works, but you have to simulate multi-touch for table moving and that can be a bit confusing.\\n\\nThere’s a lot I’d like to talk about. I’ll go through every topic, insted of making the typical what went right/wrong list.\\n\\nConcept\\n\\nWorking over the theme was probably one of the hardest tasks I had to face.\\n\\nOriginally, I had an idea of what kind of game I wanted to develop, gameplay wise – something with lots of enemies/actors, simple graphics, maybe set in space, controlled from a top-down view. I was confident I could fit any theme around it.\\n\\nIn the end, the problem with a theme like “Evolution” in a game is that evolution is unassisted. It happens through several seemingly random mutations over time, with the most apt permutation surviving. This genetic car simulator is, in my opinion, a great example of actual evolution of a species facing a challenge. But is it a game?\\n\\nIn a game, you need to control something to reach an objective. That control goes against what evolution is supposed to be like. If you allow the user to pick how to evolve something, it’s not evolution anymore – it’s the equivalent of intelligent design, the fable invented by creationists to combat the very idea of evolution. Being agnostic and a Pastafarian, that’s not something that rubbed me the right way.\\n\\nHence, my biggest dillema when deciding what to create was not with what I wanted to create, but with what I did not. I didn’t want to create an “intelligent design” simulator and wrongly call it evolution.\\n\\nThis is a problem, of course, every other contestant also had to face. And judging by the entries submitted, not many managed to work around it. I’d say the only real solution was through the use of artificial selection, somehow. So far, I haven’t seen any entry using this at its core gameplay.\\n\\nAlas, this is just a fun competition and after a while I decided not to be as strict with the game idea, and allowed myself to pick whatever I thought would work out.\\n\\nMy initial idea was to create something where humanity tried to evolve to a next level but had some kind of foe trying to stop them from doing so. I kind of had this image of human souls flying in space towards a monolith or a space baby (all based in 2001: A Space Odyssey of course) but I couldn’t think of compelling (read: serious) mechanics for that.\\n\\nBorgs were my next inspiration, as their whole hypothesis fit pretty well into the evolution theme. But how to make it work? Are you the borg, or fighting the Borg?\\n\\nThe third and final idea came to me through my girlfriend, who somehow gave me the idea of making something about the evolution of Pasta. The more I thought about it the more it sounded like it would work, so I decided to go with it.\\n\\nConversations with my inspiring co-worker Roushey (who also created the “Mechanical Underdogs” signature logo for my intros) further matured the concept, as it involved into the idea of having individual pieces of pasta flying around and trying to evolve until they became all-powerful. A secondary idea here was that the game would work to explain how the Flying Spaghetti Monster came to exist – by evolving from a normal dinner table.\\n\\nSo the idea evolved more or less into this: you are sitting a table. You have your own plate, with is your “base”. There are 5 other guests at the table, each with their own plate.\\n\\nYour plate can spawn little pieces of pasta. You do so by “ordering” them through a menu. Some pastas are better than others; some are faster, some are stronger. They have varying costs, which are debited from your credits (you start with a number of credits).\\n\\nOnce spawned, your pastas start flying around. Their instinct is to fly to other plates, in order to conquer them (the objective of the game is having your pasta conquer all the plates on the table). But they are really autonomous, so after being spawned, you have no control over your pasta (think DotA or LoL creeps).\\n\\nYour pasta doesn’t like other people’s pasta, so if they meet, they shoot sauce at each other until one dies. You get credits for other pastas your own pasta kill.\\n\\nOnce a pasta is in the vicinity of a plate, it starts conquering it for its team. It takes around 10 seconds for a plate to be conquered; less if more pasta from the same team are around. If pasta from other team are around, though, they get locked down in their attempt, unable to conquer the plate, until one of them die (think Battlefield’s standard “Conquest” mode).\\n\\nYou get points every second for every plate you own.\\n\\nOver time, the concept also evolved to use an Italian bistro as its main scenario.\\n\\nCarlos, Carlos’ Bistro’s founder and owner\\n\\nSetup\\n\\nNo major changes were made from my work setup. I used FDT and Starling creating an Adobe AIR (ActionScript) project, all tools or frameworks I already had some knowledge with.\\n\\nOne big change for me was that I livestreamed my work through a twitch.tv account. This was a new thing for me. As recommended by Roushey, I used a program called XSplit and I got to say, it is pretty amazing. It made the livestream pretty effortless and the features are awesome, even for the free version. It was great to have some of my friends watch me, and then interact with them and random people through chat. It was also good knowing that I was also recording a local version of the files, so I could make a timelapse video later.\\n\\nKnowing the video was being recorded also made me a lot more self-conscious about my computer use, as if someone was watching over my shoulder. It made me realize that sometimes I spend too much time in seemingly inane tasks (I ended up wasting the longest time just to get some text alignment the way I wanted – it’ll probably drive someone crazy if they watch it) and that I do way too many typos where writing code. I pretty much spend half of the time writing a line and the other half fixing the crazy characters in it.\\n\\nMy own stream was probably boring to watch since I was coding for the most time. But livestreaming is one of the cool things to do as a spectator too. It was great seeing other people working – I had a few tabs opened on my second monitor all the time. It’s actually a bit sad, because if I could, I could have spent the whole weekend just watching other people working! But I had to do my own work, so I’d only do it once in a while, when resting for a bit.\\n\\nDesign\\n\\nAlthough I wanted some simple, low-fi, high-contrast kind of design, I ended up going with somewhat realistic (vector) art. I think it worked very well, fitting the mood of the game, but I also went overboard.\\n\\nFor example: to know the state of a plate (who owns it, who’s conquering it and how much time they have left before conquering it, which pasta units are in the queue, etc), you have to look at the plate’s bill.\\n\\nThe problem I realized when doing some tests is that people never look at the bill! They think it’s some kind of prop, so they never actually read its details.\\n\\nPlus, if you’re zoomed out too much, you can’t actually read it, so it’s hard to know what’s going on with the game until you zoom in to the area of a specific plate.\\n\\nOne other solution that didn’t turn out to be as perfect as I thought was how to indicate who a plate base belongs to. In the game, that’s indicated by the plate’s decoration – its color denotes the team owner. But it’s something that fits so well into the design that people never realized it, until they were told about it.\\n\\nIn the end, the idea of going with a full physical metaphor is one that should be done with care. Things that are very important risk becoming background noise, unless the player knows its importance.\\n\\nOriginally, I wanted to avoid any kind of heads-up display in my game. In the end, I ended up adding it at the bottom to indicate your credits and bases owned, as well as the hideous out-of-place-and-still-not-obvious “Call Waiter” button. But in hindsight, I should have gone with a simple HUD from the start, especially one that indicated each team’s colors and general state of the game without the need for zooming in and out.\\n\\nDevelopment\\n\\nDevelopment went fast. But not fast enough.\\n\\nEven though I worked around 32+ hours for this Ludum Dare, the biggest problem I had to face in the end was overscoping. I had too much planned, and couldn’t get it all done.\\n\\nContent-wise, I had several kinds of pasta planned (Wikipedia is just amazing in that regard), split into several different groups, from small Pastina to huge Pasta al forno. But because of time constraints, I ended up scratching most of them, and ended up with 5 different types of very small pasta – barely something to start when talking about the evolution of Pasta.\\n\\nPastas used in the game. Unfortunately, the macs where never used\\n\\nWhich is one of the saddest things about the project, really. It had the framework and the features to allow an endless number of elements in there, but I just didn’t have time to draw the rest of the assets needed (something I loved to do, by the way).\\n\\nOther non-obvious features had to be dropped, too. For example, when ordering some pasta, you were supposed to select what kind of sauce you’d like with your pasta, each with different attributes. Bolognese, for example, is very strong, but inaccurate; Pesto is very accurate and has great range, but it’s weaker; and my favorite, Vodka, would triggers 10% loss of speed on the pasta hit by it.\\n\\nThe code for that is mostly in there. But in the end, I didn’t have time to implement the sauce selection interface; all pasta ended up using bolognese sauce.\\n\\nTo-do list: lots of things were not done\\n\\nActual programming also took a toll in the development time. Having been programming for a while, I like to believe I got to a point where I know how to make things right, but at the expense of forgetting how to do things wrong in a seemingly good way. What I mean is that I had to take a lot of shortcuts in my code to save time (e.g. a lot of singletons references for cross-communication rather than events or observers, all-encompassing check loops, not fast enough) that left a very sour taste in my mouth. While I know I used to do those a few years ago and survive, I almost cannot accept the state my code is in right now.\\n\\nAt the same time, I do know it was the right thing to do given the timeframe.\\n\\nOne small thing that had some impact was using a somewhat new platform for me. That’s Starling, the accelerated graphics framework I used in Flash. I had tested it before and I knew how to use it well – the API is very similar to Flash itself. However, there were some small details that had some impact during development, making me feel somewhat uneasy the whole time I was writing the game. It was, again, the right thing to do, but I should have used Starling more deeply before (which is the conundrum: I used it for Ludum Dare just so I could learn more about it).\\n\\nArgument and user experience\\n\\nOne final aspect of the game that I learned is that making the game obvious for your players goes a long way into making it fun. If you have to spend the longest time explaining things, your game is doing something wrong.\\n\\nAnd that’s exactly the problem Survival of the Tastiest ultimately faced. It’s very hard for people to understand what’s going on with the game, why, and how. I did have some introductory text at the beginning, but that was a last-minute thing. More importantly, I should have had a better interface or simplified the whole concept so it would be easier for people to understand.\\n\\nThat doesn’t mean the game itself should be simple. It just means that the experience and interface should be approachable and understandable.\\n\\nConclusion\\n\\nI’m extremely happy with what I’ve done and, especially given that this was my first Ludum Dare. However, I feel like I’ve learned a lot of what not to do.\\n\\nThe biggest problem is overscoping. Like Eric Decker said, the biggest lesson we can learn with this is probably with scoping – deciding what to do beforehand in a way you can complete it without having to rush and do something half-assed.\\n\\nI’m sure I will do more Ludum Dares in the future. But if there are any lessons I can take of it, they are to make it simple, to use frameworks and platforms you already have some absolute experience with (otherwise you’ll spend too much time trying to solve easy questions), and to scope for a game that you can complete in one day only (that way, you can actually take two days and make it cool).\\n\\nThis entry was posted\\non Monday, August 27th, 2012 at 10:54 am and is filed under LD #24.\\nYou can follow any responses to this entry through the RSS 2.0 feed.\\nYou can skip to the end and leave a response. Pinging is currently not allowed.\\n\\n3 Responses to ““Survival of the Tastiest” Post-mortem”\\n\\ndarn it , knowing that I missed your livestream makes me a sad panda ;( but more to the point, the game is … well for a startup its original to say the least ;D it has some really neat ideas and more importantly its designed arround touch screens whitch by the looks of the submission is something rare ;o or that could be just me and my short memory -_-! awesum game, love et <3',\n",
       " 'meta': {'pile_set_name': 'Pile-CC'}}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://mystic.the-eye.eu/public/AI/pile/\"\n",
    "data_files = {\n",
    "    \"train\": [base_url + \"train/\" + f\"{idx:02d}.jsonl.zst\" for idx in range(30)],\n",
    "    \"validation\": base_url + \"val.jsonl.zst\",\n",
    "    \"test\": base_url + \"test.jsonl.zst\",\n",
    "}\n",
    "pile_dataset = load_dataset(\"json\", data_files=data_files, streaming=True)\n",
    "next(iter(pile_dataset[\"train\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f8ff9",
   "metadata": {},
   "source": [
    "> ✏️ Try it out! <font color=\"darkgreen\">Use one of the large Common Crawl corpora like [`mc4`](https://huggingface.co/datasets/mc4) or [`oscar`](https://huggingface.co/datasets/oscar) to create a streaming multilingual dataset that represents the spoken proportions of languages in a country of your choice. For example, the four national languages in Switzerland are German, French, Italian, and Romansh, so you could try creating a Swiss corpus by sampling the Oscar subsets according to their spoken proportion.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "29188709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration de+en+fr-81dec6f972abeec4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sample text 1:\n",
      "﻿ education Archives - muzmatch Blog education Archives - muzmatch Blog\n",
      "Marriage education is a must for single and engaged Muslims\n",
      "Being a spouse and a parent are among the most important jobs you’ll ever have. Marriage education, premarital advisement and counseling can help singles and engaged people obtain the knowledge and skills they need...\n",
      "\n",
      "sample text 2:\n",
      "Black Color Net Saree [VOL6-138] - USD $126.50 : Designer Sarees, Indian Saree Online, Wedding Bridal Lehenga Saris, Salwar Kameez, Buy Sarees Online Shopping\n",
      "Home :: Fancy Sarees :: Black Color Net Saree\n",
      "Model: VOL6-138 Price: USD $126.50\n",
      "Quantity: DescriptionItem Code-VOL6-138 .\n",
      "Color -Black .\n",
      "I received my saree yesterday. it is very nice exactly as on website. It is great to order from Sangini. The service was quick and the shipping was...-Orange brasso sareeHi vinaybhai\n",
      "\n",
      "sample text 3:\n",
      "Troxel Fallon Taylor Helmet - Vintage Cactus | HorseLoverZ\n",
      "> Troxel Fallon Taylor Helmet - Vintage Cactus\n",
      "Troxel Fallon Taylor Helmet - Vintage Cactus in stock and ready to ship. Allow additional time for delivery.\n",
      "The Troxel Fallon Taylor Candy Serape Helmet will let you take a ride on the wild side! This superb helmet has been designed and inspired by World Champion Barrel Racer, Fallon Taylor. The Vintage Cactus design features roses, cactus, and a skull for a southwestern vibe. This low profile helmet features the DialFit system for a custom fit, mesh-covered vents for breathability, along with a print, FlipFold removable and washable headliner. Matte Duratec Finish.\n",
      "Item # 200-625401\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "## https://huggingface.co/datasets/mc4#dataset-summary\n",
    "mc4_DeFrEn_train = load_dataset(\"mc4\", languages=[\"de\", \"en\", \"fr\"], split=\"train\", streaming=True)\n",
    "## https://huggingface.co/docs/datasets/stream#shuffle\n",
    "shuffled_mc4_DeFrEn_train = mc4_DeFrEn_train.shuffle(buffer_size=300, seed=42)\n",
    "i = 0\n",
    "for inst in iter(shuffled_mc4_DeFrEn_train):\n",
    "    if i==3:\n",
    "        break\n",
    "    print(\"\\nsample text {}:\\n{}\".format(i+1, inst[\"text\"]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb4ae5",
   "metadata": {},
   "source": [
    "You now have all the tools you need to load and process datasets of all shapes and sizes — but unless you're exceptionally lucky, there will come a point in your NLP journey where you'll have to actually create a dataset to solve the problem at hand. That's the topic of the next section!\n",
    "\n",
    "## [Creating your own dataset](https://huggingface.co/course/chapter5/5?fw=pt)\n",
    "\n",
    "Sometimes the dataset that you need to build an NLP application doesn't exist, so you'll need to create it yourself. In this section we'll show you how to create a corpus of [GitHub issues](https://github.com/features/issues/), which are commonly used to track bugs or features in GitHub repositories. This corpus could be used for various purposes, including:\n",
    "- Exploring how long it takes to close open issues or pull requests\n",
    "- Training a *multilabel classifier* that can tag issues with metadata based on the issue's description (e.g., \"bug\", \"enhancement\", or \"question\")\n",
    "- Creating a semantic search engine to find which issues match a user's query\n",
    "\n",
    "Here we'll focus on creating the corpus, and in the next section we'll tackle the semantic search application. To keep things meta, we'll use the GitHub issues associated with a popular open source project: 🤗 Datasets! Let's take a look at how to get the data and explore the information contained in these issues.\n",
    "\n",
    "### Getting the data\n",
    "\n",
    "You can find all the issues in 🤗 Datasets by navigating to the repository's [Issues tab](https://github.com/huggingface/datasets/issues). As shown in the following screenshot, at the time of writing there were 331 open issues and 668 closed ones.\n",
    "\n",
    "<img style=\"float=center;\" src=\"images/503a11cba6d2a53a2e1a1e6d8ff681cc2128fc8bd57f724252f72dc50fb04e9c.png\">\n",
    "\n",
    "If you click on one of these issues you'll find it contains a title, a description, and a set of labels that characterize the issue. An example is shown in the screenshot below.\n",
    "\n",
    "<img style=\"float=center;\" src=\"images/04d9715957f0c0073e90edca667cd90d9ba1b34340b51a72f20a7eeee1636a8a.png\">\n",
    "\n",
    "To download all the repository's issues, we'll use the [GitHub REST API](https://docs.github.com/en/rest) to poll the [`Issues` endpoint](https://docs.github.com/en/rest/reference/issues#list-repository-issues). This endpoint returns a list of JSON objects, with each object containing a large number of fields that include the title and description as well as metadata about the status of the issue and so on.\n",
    "\n",
    "A convenient way to download the issues is via the `requests` library, which is the standard way for making HTTP requests in Python. You can install the library by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126e1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following command needs to run only once\n",
    "#!conda install -c anaconda requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e50c8f",
   "metadata": {},
   "source": [
    "Once the library is installed, you can make GET requests to the `Issues` endpoint by invoking the `requests.get()` function. For example, you can run the following command to retrieve the first issue on the first page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eec6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2133d",
   "metadata": {},
   "source": [
    "The `response` object contains a lot of useful information about the request, including the HTTP status code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1300a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c70f7",
   "metadata": {},
   "source": [
    "where a `200` status means the request was successful (you can find a list of possible HTTP status codes [here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)). What we are really interested in, though, is the *payload*, which can be accessed in various formats like bytes, strings, or JSON. Since we know our issues are in JSON format, let's inspect the payload as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0ea1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/4376',\n",
       "  'repository_url': 'https://api.github.com/repos/huggingface/datasets',\n",
       "  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/4376/labels{/name}',\n",
       "  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/4376/comments',\n",
       "  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/4376/events',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/issues/4376',\n",
       "  'id': 1242218144,\n",
       "  'node_id': 'I_kwDODunzps5KCr6g',\n",
       "  'number': 4376,\n",
       "  'title': 'irc_disentagle viewer error',\n",
       "  'user': {'login': 'labouz',\n",
       "   'id': 25671683,\n",
       "   'node_id': 'MDQ6VXNlcjI1NjcxNjgz',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/25671683?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/labouz',\n",
       "   'html_url': 'https://github.com/labouz',\n",
       "   'followers_url': 'https://api.github.com/users/labouz/followers',\n",
       "   'following_url': 'https://api.github.com/users/labouz/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/labouz/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/labouz/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/labouz/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/labouz/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/labouz/repos',\n",
       "   'events_url': 'https://api.github.com/users/labouz/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/labouz/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'labels': [],\n",
       "  'state': 'open',\n",
       "  'locked': False,\n",
       "  'assignee': None,\n",
       "  'assignees': [],\n",
       "  'milestone': None,\n",
       "  'comments': 1,\n",
       "  'created_at': '2022-05-19T19:15:16Z',\n",
       "  'updated_at': '2022-05-19T19:17:39Z',\n",
       "  'closed_at': None,\n",
       "  'author_association': 'NONE',\n",
       "  'active_lock_reason': None,\n",
       "  'body': 'the dataviewer shows this message for \"ubuntu\" - \"train\", \"test\", and \"validation\" splits:\\r\\n```\\r\\nServer error\\r\\nStatus code:   400\\r\\nException:     ValueError\\r\\nMessage:       Cannot seek streaming HTTP file\\r\\n\\r\\n```\\r\\nit appears to give the same message for the \"channel_two\" data as well.\\r\\n\\r\\nI get a Checksums error when using `load_data()` with this dataset. Even with the `download_mode` and `ignore_verifications` options set. i referenced the issue here: https://github.com/huggingface/datasets/issues/3807 ',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/4376/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'timeline_url': 'https://api.github.com/repos/huggingface/datasets/issues/4376/timeline',\n",
       "  'performed_via_github_app': None}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e95da",
   "metadata": {},
   "source": [
    "Whoa, that's a lot of information! We can see useful fields like `title`, `body`, and `number` that describe the issue, as well as information about the GitHub user who opened the issue.\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">Click on a few of the URLs in the JSON payload above to get a feel for what type of information each GitHub issue is linked to.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f03af98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The top url (https://api.github.com/repos/huggingface/datasets/issues/4296) leads to a json object that seems to be\n",
      "identical with the one depicted above. Apparantly, this json object contains all the information or links (to links)\n",
      "to all the information that specify this issue (4296).\n",
      "\n",
      "The \"html_url\" (https://github.com/huggingface/datasets/pull/4296) leads to a conversation concerning a pull request\n",
      "(follow the link to see it).\n",
      "\n",
      "The \"avatar_url\" (https://avatars.githubusercontent.com/u/8515462?v=4) leads to the avatar / photo of the user who\n",
      "submitted the pull request.\n",
      "\n",
      "The \"timeline_url\" (https://api.github.com/repos/huggingface/datasets/issues/4296/timeline) leads to a list json\n",
      "objects that specify the timeline of this issue\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "try_str = \"\"\"\n",
    "The top url (https://api.github.com/repos/huggingface/datasets/issues/4296) leads to a json object that seems to be\n",
    "identical with the one depicted above. Apparantly, this json object contains all the information or links (to links)\n",
    "to all the information that specify this issue (4296).\n",
    "\n",
    "The \"html_url\" (https://github.com/huggingface/datasets/pull/4296) leads to a conversation concerning a pull request\n",
    "(follow the link to see it).\n",
    "\n",
    "The \"avatar_url\" (https://avatars.githubusercontent.com/u/8515462?v=4) leads to the avatar / photo of the user who\n",
    "submitted the pull request.\n",
    "\n",
    "The \"timeline_url\" (https://api.github.com/repos/huggingface/datasets/issues/4296/timeline) leads to a list json\n",
    "objects that specify the timeline of this issue\n",
    "\"\"\"\n",
    "print(try_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68d74e",
   "metadata": {},
   "source": [
    "As described in the GitHub [documentation](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting), unauthenticated requests are limited to 60 requests per hour. Although you can increase the `per_page` query parameter to reduce the number of requests you make, you will still hit the rate limit on any repository that has more than a few thousand issues. So instead, you should follow GitHub's [instructions](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) on creating a *personal access token* so that you can boost the rate limit to 5,000 requests per hour. Once you have your token, you can include it as part of the request header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a371c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = \"gh===p_2lfsxDUkHuwlUBXpSfV7gcZgDOuZph4aqicf\" # remove \"===\" (a new token might be required)\n",
    "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa65f7f",
   "metadata": {},
   "source": [
    "> <font color=\"darkred\">⚠️ Do not share a notebook with your `GITHUB_TOKEN` pasted in it. We recommend you delete the last cell once you have executed it to avoid leaking this information accidentally. Even better, store the token in a *.env* file and use the [`python-dotenv` library](https://github.com/theskumar/python-dotenv) to load it automatically for you as an environment variable</font>.\n",
    "\n",
    "Now that we have our access token, let's create a function that can download all the issues from a GitHub repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fadf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def fetch_issues(\n",
    "    owner=\"huggingface\",\n",
    "    repo=\"datasets\",\n",
    "    num_issues=10000,\n",
    "    rate_limit=5000,\n",
    "    issues_path=Path(\"./data\")\n",
    "):\n",
    "    if not issues_path.is_dir():\n",
    "        issues_path.mkdir(exist_ok=True)\n",
    "    batch = []\n",
    "    all_issues = []\n",
    "    per_page = 100  # Number of issues to return per page\n",
    "    num_pages = math.ceil(num_issues / per_page)\n",
    "    base_url = \"https://api.github.com/repos\"\n",
    "    for page in tqdm(range(num_pages)):\n",
    "        # Query with state=all to get both open and closed issues\n",
    "        query = f\"issues?page={page}&per_page={per_page}&state=all\"\n",
    "        issues = requests.get(f\"{base_url}/{owner}/{repo}/{query}\", headers=headers)\n",
    "        batch.extend(issues.json())\n",
    "        print(f\"page: {page}\\t batch length: {len(batch)}\\t query: {query}\", end=\"\\r\")\n",
    "        if len(batch) > rate_limit and len(all_issues) < num_issues:\n",
    "            all_issues.extend(batch)\n",
    "            batch = []  # Flush batch for next time period\n",
    "            print()\n",
    "            print(\"Reached GitHub rate limit. Sleeping for one hour ...\")\n",
    "            time.sleep(60 * 60 + 1)\n",
    "    all_issues.extend(batch)\n",
    "    df = pd.DataFrame.from_records(all_issues)\n",
    "    df.to_json(f\"{issues_path}/{repo}-issues.jsonl\", orient=\"records\", lines=True)\n",
    "    print()\n",
    "    print(f\"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9b121",
   "metadata": {},
   "source": [
    "Now when we call `fetch_issues()` it will download all the issues in batches to avoid exceeding GitHub's limit on the number of requests per hour; the result will be stored in a *repository_name-issues.jsonl* file, where each line is a JSON object the represents an issue. Let's use this function to grab all the issues from 🤗 Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17653bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on your internet connection, this can take several minutes to run...\n",
    "# The following line needs to run only once (run 'fetch_issues(repo=\"transformers\")' for \"Try it out\" further below)\n",
    "#fetch_issues()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd8e4e",
   "metadata": {},
   "source": [
    "Once the issues are downloaded we can load them locally using our newfound skills from [section 2](https://huggingface.co/course/chaper5/2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "489c8acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7a2b59943d24c3c3\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "issues_dataset = load_dataset(\"json\", data_files=\"data/datasets-issues.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e32c92",
   "metadata": {},
   "source": [
    "Great, we've created our first dataset from scratch! But why are there several thousand issues when the [Issues tab](https://github.com/huggingface/datasets/issues) of the 🤗 Datasets repository only shows around 1,000 issues in total 🤔? As described in the GitHub [documentation](https://docs.github.com/en/rest/reference/issues#list-issues-assigned-to-the-authenticated-user), that's because we've downloaded all the pull requests as well:\n",
    "\n",
    "> <i>\"GitHub's REST API v3 considers every pull request an issue, but not every *issue* is a pull request. For this reason, \"*Issues*\" endpoints may return both issues and pull requests in the response. You can identify pull requests by the `pull_request` key. Be aware that the `id` of a pull request returned from \"*Issues*\" endpoints will be an issue id.\"</i>\n",
    "\n",
    "Since the contents of issues and pull requests are quite different, let's do some minor preprocessing to enable us to distinguish between them.\n",
    "\n",
    "### Cleaning up the data\n",
    "\n",
    "The above snippet from GitHub's documentation tells us that the `pull_request` column can be used to differentiate between issues and pull requests. Let's look at a random sample to see what the difference is. As we did in [section 3](https://huggingface.co/course/chapter5/3), we'll chain `Dataset.shuffle()` and `Dataset.select()` to create a random sample and then zip the `html_url` and `pull_request` columns so we can compare the various URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c98c48be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'url': Value(dtype='string', id=None), 'repository_url': Value(dtype='string', id=None), 'labels_url': Value(dtype='string', id=None), 'comments_url': Value(dtype='string', id=None), 'events_url': Value(dtype='string', id=None), 'html_url': Value(dtype='string', id=None), 'id': Value(dtype='int64', id=None), 'node_id': Value(dtype='string', id=None), 'number': Value(dtype='int64', id=None), 'title': Value(dtype='string', id=None), 'user': {'login': Value(dtype='string', id=None), 'id': Value(dtype='int64', id=None), 'node_id': Value(dtype='string', id=None), 'avatar_url': Value(dtype='string', id=None), 'gravatar_id': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'html_url': Value(dtype='string', id=None), 'followers_url': Value(dtype='string', id=None), 'following_url': Value(dtype='string', id=None), 'gists_url': Value(dtype='string', id=None), 'starred_url': Value(dtype='string', id=None), 'subscriptions_url': Value(dtype='string', id=None), 'organizations_url': Value(dtype='string', id=None), 'repos_url': Value(dtype='string', id=None), 'events_url': Value(dtype='string', id=None), 'received_events_url': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'site_admin': Value(dtype='bool', id=None)}, 'labels': [{'id': Value(dtype='int64', id=None), 'node_id': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'name': Value(dtype='string', id=None), 'color': Value(dtype='string', id=None), 'default': Value(dtype='bool', id=None), 'description': Value(dtype='string', id=None)}], 'state': Value(dtype='string', id=None), 'locked': Value(dtype='bool', id=None), 'assignee': {'login': Value(dtype='string', id=None), 'id': Value(dtype='int64', id=None), 'node_id': Value(dtype='string', id=None), 'avatar_url': Value(dtype='string', id=None), 'gravatar_id': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'html_url': Value(dtype='string', id=None), 'followers_url': Value(dtype='string', id=None), 'following_url': Value(dtype='string', id=None), 'gists_url': Value(dtype='string', id=None), 'starred_url': Value(dtype='string', id=None), 'subscriptions_url': Value(dtype='string', id=None), 'organizations_url': Value(dtype='string', id=None), 'repos_url': Value(dtype='string', id=None), 'events_url': Value(dtype='string', id=None), 'received_events_url': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'site_admin': Value(dtype='bool', id=None)}, 'assignees': [{'login': Value(dtype='string', id=None), 'id': Value(dtype='int64', id=None), 'node_id': Value(dtype='string', id=None), 'avatar_url': Value(dtype='string', id=None), 'gravatar_id': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'html_url': Value(dtype='string', id=None), 'followers_url': Value(dtype='string', id=None), 'following_url': Value(dtype='string', id=None), 'gists_url': Value(dtype='string', id=None), 'starred_url': Value(dtype='string', id=None), 'subscriptions_url': Value(dtype='string', id=None), 'organizations_url': Value(dtype='string', id=None), 'repos_url': Value(dtype='string', id=None), 'events_url': Value(dtype='string', id=None), 'received_events_url': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'site_admin': Value(dtype='bool', id=None)}], 'milestone': {'url': Value(dtype='string', id=None), 'html_url': Value(dtype='string', id=None), 'labels_url': Value(dtype='string', id=None), 'id': Value(dtype='int64', id=None), 'node_id': Value(dtype='string', id=None), 'number': Value(dtype='int64', id=None), 'title': Value(dtype='string', id=None), 'description': Value(dtype='string', id=None), 'creator': {'login': Value(dtype='string', id=None), 'id': Value(dtype='int64', id=None), 'node_id': Value(dtype='string', id=None), 'avatar_url': Value(dtype='string', id=None), 'gravatar_id': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'html_url': Value(dtype='string', id=None), 'followers_url': Value(dtype='string', id=None), 'following_url': Value(dtype='string', id=None), 'gists_url': Value(dtype='string', id=None), 'starred_url': Value(dtype='string', id=None), 'subscriptions_url': Value(dtype='string', id=None), 'organizations_url': Value(dtype='string', id=None), 'repos_url': Value(dtype='string', id=None), 'events_url': Value(dtype='string', id=None), 'received_events_url': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'site_admin': Value(dtype='bool', id=None)}, 'open_issues': Value(dtype='int64', id=None), 'closed_issues': Value(dtype='int64', id=None), 'state': Value(dtype='string', id=None), 'created_at': Value(dtype='timestamp[s]', id=None), 'updated_at': Value(dtype='timestamp[s]', id=None), 'due_on': Value(dtype='timestamp[s]', id=None), 'closed_at': Value(dtype='timestamp[s]', id=None)}, 'comments': Value(dtype='int64', id=None), 'created_at': Value(dtype='timestamp[s]', id=None), 'updated_at': Value(dtype='timestamp[s]', id=None), 'closed_at': Value(dtype='timestamp[s]', id=None), 'author_association': Value(dtype='string', id=None), 'active_lock_reason': Value(dtype='null', id=None), 'draft': Value(dtype='bool', id=None), 'pull_request': {'url': Value(dtype='string', id=None), 'html_url': Value(dtype='string', id=None), 'diff_url': Value(dtype='string', id=None), 'patch_url': Value(dtype='string', id=None), 'merged_at': Value(dtype='timestamp[s]', id=None)}, 'body': Value(dtype='string', id=None), 'reactions': {'url': Value(dtype='string', id=None), 'total_count': Value(dtype='int64', id=None), '+1': Value(dtype='int64', id=None), '-1': Value(dtype='int64', id=None), 'laugh': Value(dtype='int64', id=None), 'hooray': Value(dtype='int64', id=None), 'confused': Value(dtype='int64', id=None), 'heart': Value(dtype='int64', id=None), 'rocket': Value(dtype='int64', id=None), 'eyes': Value(dtype='int64', id=None)}, 'timeline_url': Value(dtype='string', id=None), 'performed_via_github_app': Value(dtype='null', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='json', config_name='default', version=0.0.0, splits={'train': SplitInfo(name='train', num_bytes=12724810, num_examples=4387, dataset_name='json')}, download_checksums={'/Users/matthias/Desktop/Huggingface/Huggingface-course/data/datasets-issues.jsonl': {'num_bytes': 15940704, 'checksum': 'a1861bac72bd58b69060229c79a639caa45e2ed591a4959700b42d3dbdc891a1'}}, download_size=15940704, post_processing_size=None, dataset_size=12724810, size_in_bytes=28665514)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d63cba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-0e4efc3f6aff7381.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'draft', 'pull_request', 'body', 'reactions', 'timeline_url', 'performed_via_github_app'],\n",
      "    num_rows: 3\n",
      "})\n",
      ">> URL: https://github.com/huggingface/datasets/pull/978\n",
      ">> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/978', 'html_url': 'https://github.com/huggingface/datasets/pull/978', 'diff_url': 'https://github.com/huggingface/datasets/pull/978.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/978.patch', 'merged_at': None}\n",
      "\n",
      ">> URL: https://github.com/huggingface/datasets/pull/308\n",
      ">> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/308', 'html_url': 'https://github.com/huggingface/datasets/pull/308', 'diff_url': 'https://github.com/huggingface/datasets/pull/308.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/308.patch', 'merged_at': datetime.datetime(2020, 6, 25, 12, 16, 9)}\n",
      "\n",
      ">> URL: https://github.com/huggingface/datasets/pull/4034\n",
      ">> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/4034', 'html_url': 'https://github.com/huggingface/datasets/pull/4034', 'diff_url': 'https://github.com/huggingface/datasets/pull/4034.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/4034.patch', 'merged_at': datetime.datetime(2022, 3, 28, 8, 6, 14)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = issues_dataset.shuffle(seed=666).select(range(3))\n",
    "print(sample) # maybe remove this extra print statement\n",
    "# Print out the URL and pull request entries\n",
    "for url, pr in zip(sample[\"html_url\"], sample[\"pull_request\"]):\n",
    "    print(f\">> URL: {url}\")\n",
    "    print(f\">> Pull request: {pr}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5443356c",
   "metadata": {},
   "source": [
    "Here we can see that each pull request is associated with various URLs, while ordinary issues have a `None` entry. We can use this distinction to create a new `is_pull_request` column that checks whether the `pull_request` field is `None` or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b208319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-22cd926f1f95de72.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'draft', 'pull_request', 'body', 'reactions', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
       "    num_rows: 4387\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_dataset = issues_dataset.map(lambda x: {\"is_pull_request\": False if x[\"pull_request\"] is None else True})\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214dcc1",
   "metadata": {},
   "source": [
    "> ✏️ Try it out! <font color=\"darkgreen\">Calculate the average time it takes to close issues in 🤗 Datasets. You may find the `Dataset.filter()` function useful to filter out the pull requests and open issues, and you can use the `Dataset.set_format()` function to convert the dataset to a `DataFrame` so you can easily manipulate the `created_at` and `closed_at` timestamps. For bonus points, calculate the average time it takes to close pull requests.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3842f199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-5204adedd9e5bce1.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-de6ce268abc3869f.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-aeefa77fd0374a31.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total items:\t\t4387\n",
      "closed items:\t\t3802\n",
      "closed issues:\t\t1067\n",
      "closed pull requests:\t2735\n",
      "average duration until closing for GitHub issues:\t\t33d 22h:17m:51s\n",
      "average duration until closing for GitHub pull requests:\t5d 23h:52m:14s\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "import datetime\n",
    "## get closed issues and pull requests\n",
    "print(\"total items:\\t\\t{}\".format(issues_dataset.num_rows))\n",
    "closed_dataset = issues_dataset.filter(lambda x: x[\"closed_at\"] is not None)\n",
    "print(\"closed items:\\t\\t{}\".format(closed_dataset.num_rows))\n",
    "closed_issues_dataset = closed_dataset.filter(lambda x: x[\"pull_request\"] is None)\n",
    "print(\"closed issues:\\t\\t{}\".format(closed_issues_dataset.num_rows))\n",
    "closed_pullRequests_dataset = closed_dataset.filter(lambda x: x[\"pull_request\"] is not None)\n",
    "print(\"closed pull requests:\\t{}\".format(closed_pullRequests_dataset.num_rows))\n",
    "## define helper functions\n",
    "### format time\n",
    "def formatTime(tstr, value, unit, trail):\n",
    "    if tstr!=\"\" or value!=0:\n",
    "        tstr += \"{}{}{}\".format(int(value), unit, trail)\n",
    "    return tstr\n",
    "### turn seconds into time string\n",
    "def secs2DHMS(secs):\n",
    "    tstr=\"\"\n",
    "    days = secs // (24 * 3600)\n",
    "    secs %= 24 * 3600\n",
    "    tstr = formatTime(tstr, days, \"d\", \" \")\n",
    "    hours = secs // 3600\n",
    "    secs %= 3600\n",
    "    tstr = formatTime(tstr, hours, \"h\", \":\")\n",
    "    mins = secs // 60\n",
    "    secs %= 60\n",
    "    tstr = formatTime(tstr, mins, \"m\", \":\")\n",
    "    tstr = formatTime(tstr, secs, \"s\", \"\")\n",
    "    return tstr\n",
    "### get mean closing time (in seconds) of github issues or pull requests\n",
    "def get_mean_closing_time(github_dataset):\n",
    "    durations = []\n",
    "    for item in github_dataset:\n",
    "        start = str(item[\"created_at\"])\n",
    "        end = str(item[\"closed_at\"])\n",
    "        # https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
    "        start_seconds = time.mktime(datetime.datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\").timetuple())\n",
    "        end_seconds = time.mktime(datetime.datetime.strptime(end, \"%Y-%m-%d %H:%M:%S\").timetuple())\n",
    "        durations.append(end_seconds - start_seconds)\n",
    "    mean = sum(durations) / len(durations)\n",
    "    return secs2DHMS(mean)\n",
    "## produce output\n",
    "print(\"average duration until closing for GitHub issues:\\t\\t{}\".format(get_mean_closing_time(closed_issues_dataset)))\n",
    "print(\"average duration until closing for GitHub pull requests:\\t{}\".format(\n",
    "    get_mean_closing_time(closed_pullRequests_dataset)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e2d0c",
   "metadata": {},
   "source": [
    "Although we could proceed to further clean up the dataset by dropping or renaming some columns, it is generally a good practice to keep the dataset as \"raw\" as possible at this stage so that it can be easily used in multiple applications.\n",
    "\n",
    "Before we push our dataset to the Hugging Face Hub, let's deal with one thing that's missing from it: the comments associated with each issue and pull request. We'll add them next with — you guessed it — the GitHub REST API!\n",
    "\n",
    "### Augmenting the dataset\n",
    "\n",
    "As shown in the following screenshot, the comments associated with an issue or pull request provide a rich source of information, especially if we're interested in building a search engine to answer user queries about the library.\n",
    "\n",
    "<img style=\"float=center;\" src=\"images/9d275b8a98797d3d66002f688bca85b0c3002d1f758352e76c79d27ec21d31f5.png\">\n",
    "\n",
    "The GitHub REST API provides a [`Comments` endpoint](https://docs.github.com/en/rest/reference/issues#list-issue-comments) that returns all the comments associated with an issue number. Let's test the endpoint to see what it returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e754d2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128',\n",
       "  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',\n",
       "  'id': 897594128,\n",
       "  'node_id': 'IC_kwDODunzps41gDMQ',\n",
       "  'user': {'login': 'bhavitvyamalik',\n",
       "   'id': 19718818,\n",
       "   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/bhavitvyamalik',\n",
       "   'html_url': 'https://github.com/bhavitvyamalik',\n",
       "   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',\n",
       "   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',\n",
       "   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'created_at': '2021-08-12T12:21:52Z',\n",
       "  'updated_at': '2021-08-12T12:31:17Z',\n",
       "  'author_association': 'CONTRIBUTOR',\n",
       "  'body': \"@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?\",\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'performed_via_github_app': None},\n",
       " {'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/898644889',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-898644889',\n",
       "  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',\n",
       "  'id': 898644889,\n",
       "  'node_id': 'IC_kwDODunzps41kDuZ',\n",
       "  'user': {'login': 'bhavitvyamalik',\n",
       "   'id': 19718818,\n",
       "   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/bhavitvyamalik',\n",
       "   'html_url': 'https://github.com/bhavitvyamalik',\n",
       "   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',\n",
       "   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',\n",
       "   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'created_at': '2021-08-13T18:28:27Z',\n",
       "  'updated_at': '2021-08-13T18:28:27Z',\n",
       "  'author_association': 'CONTRIBUTOR',\n",
       "  'body': 'Thanks for the help, @albertvillanova! All tests are passing now.',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/898644889/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'performed_via_github_app': None}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_number = 2792\n",
    "url = f\"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments\"\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c763d2e3",
   "metadata": {},
   "source": [
    "We can see that the comment is stored in the `body` field, so let's write a simple function that returns all the comments associated with an issue by picking out the `body` contents for each element in `response.json()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49184b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?\",\n",
       " 'Thanks for the help, @albertvillanova! All tests are passing now.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_comments(issue_number):\n",
    "    url = f\"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return [r[\"body\"] for r in response.json()]\n",
    "# Test our function works as expected\n",
    "get_comments(2792)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce284901",
   "metadata": {},
   "source": [
    "This looks good, so let's use `Dataset.map()` to add a new `comments` column to each issue in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2c11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-8e204e7a8cb7643a.arrow\n"
     ]
    }
   ],
   "source": [
    "# Own edit: speed up the following processes by focussing on the first 300 issues\n",
    "issues_dataset_300 = issues_dataset.select(range(300))\n",
    "# Depending on your internet connection, this can take a few minutes...\n",
    "issues_with_comments_dataset_300 = issues_dataset_300.map(lambda x: {\"comments\": get_comments(x[\"number\"])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1394805",
   "metadata": {},
   "source": [
    "The final step is to save the augmented dataset alongside our raw data so we can push them both to the Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea17571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7c3bd590544975ab07f4487e3b01c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1284903"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_with_comments_dataset_300.to_json(\"data/issues-datasets-with-comments.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441f86f",
   "metadata": {},
   "source": [
    "### Uploading the dataset to the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dded6cc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HTML' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-957deafe8c2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/HaN6qCr_Afc\" allowfullscreen></iframe>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'HTML' is not defined"
     ]
    }
   ],
   "source": [
    "HTML('<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/HaN6qCr_Afc\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e11ca",
   "metadata": {},
   "source": [
    "Now that we have our augmented dataset, it's time to push it to the Hub so we can share it with the community! To upload the dataset we'll use the [🤗 Hub library](https://github.com/huggingface/huggingface_hub), which allows us to interact with the Hugging Face Hub through a Python API. 🤗 Hub comes preinstalled with 🤗 Transformers, so we can use it directly. For example, we can use the `list_datasets()` function to get information about all the public datasets currently hosted on the Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d23dabdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets on Hub: 4929\n",
      "Dataset Name: acronym_identification, Tags: ['arxiv:2010.14678', 'annotations_creators:expert-generated', 'language_creators:found', 'languages:en', 'licenses:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:token-classification-other-acronym-identification', 'pretty_name:Acronym Identification Dataset']\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets\n",
    "all_datasets = list_datasets()\n",
    "print(f\"Number of datasets on Hub: {len(all_datasets)}\")\n",
    "print(all_datasets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52063200",
   "metadata": {},
   "source": [
    "We can see that there are currently over 4,700 datasets on the Hub, and the `list_datasets()` function also provides some basic metadata about each dataset repository.\n",
    "\n",
    "For our purposes, the first thing we need to do is create a new dataset repository on the Hub. To do that we need an authentication token, which can be obtained by first logging into the Hugging Face Hub with the `notebook_login()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "408e548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /Users/matthias/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993583b4",
   "metadata": {},
   "source": [
    "This will create a widget where you can enter your username and password, and an API token will be saved in *~/.huggingface/token*. If you're running the code in a terminal, you can log in via the CLI instead:\n",
    "```\n",
    "huggingface-cli login\n",
    "```\n",
    "Once we've done this, we can create a new dataset repository with the `create_repo()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33d25212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/datasets/mdroth/github-issues'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo\n",
    "#repo_url = create_repo(name=\"github-issues\", repo_type=\"dataset\") # 1 run either this (create dataset repo)\n",
    "repo_url = \"https://huggingface.co/datasets/mdroth/github-issues\"  # 2 or run that (dataset repo url)\n",
    "repo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a1658",
   "metadata": {},
   "source": [
    "In this example, we've created an empty dataset repository called `github-issues` under the `mdroth` username (the username should be your Hub username when you're running this code!).\n",
    "\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">Use your Hugging Face Hub username and password to obtain a token and create an empty repository called `github-issues`. Remember to **never save your credentials** in Colab or any other repository, as this information can be exploited by bad actors.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "662792e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-6e9c1b47618f53de.arrow and /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-d20ac262fb2b6bbe.arrow\n",
      "Loading cached split indices for dataset at /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-69796d564f495533.arrow and /Users/matthias/.cache/huggingface/datasets/json/default-7a2b59943d24c3c3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-d9656842970cf3a6.arrow\n",
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'draft', 'pull_request', 'body', 'reactions', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
      "        num_rows: 192\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'draft', 'pull_request', 'body', 'reactions', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
      "        num_rows: 48\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'draft', 'pull_request', 'body', 'reactions', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
      "        num_rows: 60\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The repository already exists: the `private` keyword argument will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949f470aa09d4217a1da5fe8ca7477e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split valid to the Hub.\n",
      "The repository already exists: the `private` keyword argument will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251c6098dd684b69802b24df85c17141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n",
      "The repository already exists: the `private` keyword argument will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2369fd822024c6dab5b2747c0bfea84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trying it out\n",
    "## data splits: test (20%), validation (16%), training (64%)\n",
    "## current state: training = 100% => split off 16% for validation\n",
    "## https://discuss.huggingface.co/t/how-to-split-main-dataset-into-train-dev-test-as-datasetdict/1090/9\n",
    "from datasets import DatasetDict\n",
    "train_validTest = issues_with_comments_dataset_300.train_test_split(shuffle=True, seed=42, test_size=0.36)\n",
    "valid_test = train_validTest[\"test\"].train_test_split(shuffle=True, seed=42, test_size=5/9)\n",
    "issues_dataset_300 = DatasetDict({\n",
    "    \"train\": train_validTest[\"train\"],\n",
    "    \"valid\": valid_test[\"train\"],\n",
    "    \"test\": valid_test[\"test\"]\n",
    "})\n",
    "print(issues_dataset_300)\n",
    "## pushing to hub\n",
    "## https://discuss.huggingface.co/t/save-datasetdict-to-huggingface-hub/12075/4\n",
    "issues_dataset_300.push_to_hub(repo_id=\"github_issues_300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148e933",
   "metadata": {},
   "source": [
    "Next, let's clone the repository from the Hub to our local machine and copy our dataset file into it. 🤗 Hub provides a handy `Repository` class that wraps many of the common Git commands, so to clone the remote repository we simply need to provide the URL and local path we wish to clone to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5edf69ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthias/Desktop/Huggingface/Huggingface-course/github-issues is already a clone of https://huggingface.co/datasets/mdroth/github-issues. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/datasets/mdroth/github-issues'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository\n",
    "repo = Repository(local_dir=\"github-issues\", clone_from=repo_url)\n",
    "repo.git_pull()\n",
    "!cp data/issues-datasets-with-comments.jsonl github-issues/\n",
    "repo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0fc50",
   "metadata": {},
   "source": [
    "By default, various file extensions (such as *.bin*, *.gz*, and *.zip*) are tracked with Git LFS so that large files can be versioned within the same Git workflow. You can find a list of tracked file extensions inside the repository's *.gitattributes* file. To include the JSON Lines format in the list, we can run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5000aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.lfs_track(\"*.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dfed53",
   "metadata": {},
   "source": [
    "Then we can use `Repository.push_to_hub()` to push the dataset to the Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4320eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69b53b",
   "metadata": {},
   "source": [
    "If we navigate to the URL contained in `repo_url`, we should now see that our dataset file has been uploaded.\n",
    "\n",
    "<img style=\"float=center;\" src=\"images/github-issues.png\">\n",
    "\n",
    "From here, anyone can download the dataset by simply providing `load_dataset()` with the repository ID as the `path` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4c649ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration mdroth--github-issues-e6b7052b14b3688c\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/mdroth--github-issues-e6b7052b14b3688c/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'draft', 'pull_request', 'body', 'reactions', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_dataset = load_dataset(\"mdroth/github-issues\", split=\"train\")\n",
    "remote_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392828c",
   "metadata": {},
   "source": [
    "Cool, we've pushed our dataset to the Hub and it's available for others to use! There's just one important thing left to do: adding a *dataset card* that explains how the corpus was created and provides other useful information for the community.\n",
    "> <font color=\"darkgreen\">💡 You can also upload a dataset to the Hugging Face Hub directly from the terminal by using `huggingface-cli` and a bit of Git magic. See the [🤗 Datasets guide](https://huggingface.co/docs/datasets/share.html#add-a-community-dataset) for details on how to do this.</font>\n",
    "\n",
    "### Creating a dataset card\n",
    "\n",
    "Well-documented datasets are more likely to be useful to others (including your future self!), as they provide the context to enable users to decide whether the dataset is relevant to their task and to evaluate any potential biases in or risks associated with using the dataset.\n",
    "\n",
    "On the Hugging Face Hub, this information is stored in each dataset repository's *README.md* file. There are two main steps you should take before creating this file:\n",
    "\n",
    "1. Use the [`datasets-tagging` application](https://huggingface.co/datasets/tagging/) to create metadata tags in YAML format. These tags are used for a variety of search features on the Hugging Face Hub and ensure your dataset can be easily found by members of the community. Since we have created a custom dataset here, you'll need to clone the `datasets-tagging` repository and run the application locally. Here's what the interface looks like:\n",
    "<img style=\"float=center;\" width=\"900\" src=\"images/datasetCard.png\">\n",
    "1. Read the [🤗 Datasets guide](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) on creating informative dataset cards and use it as a template.\n",
    "\n",
    "You can create the *README.md* file directly on the Hub, and you can find a template dataset card in the `lewtun/github-issues` dataset repository. A screenshot of the filled-out dataset card is shown below.\n",
    "<img style=\"float=center;\" width=\"900\" src=\"images/d25674d363f79ac314b3c34cad8606c402178f53b435b80c688f1bcf4563a45f.png\">\n",
    "\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">Use the `dataset-tagging` application and [🤗 Datasets guide](https://github.com/huggingface/datasets/blob/master/templates/README_guide.md) to complete the *README.md* file for your GitHub issues dataset.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b90f46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procedure\n",
      "1. Read the above section on \"Creating a dataset card\".\n",
      "2. Create tags with the \"HuggingFace Dataset Tagger\" at https://huggingface.co/spaces/huggingface/datasets-tagging.\n",
      "3. Create a README.md file / dataset card with the \"card-creator\" at https://huggingface.co/datasets/card-creator.\n",
      "4. Upload the README.md file / dataset card to the model repo (in this case https://huggingface.co/datasets/mdroth/github_issues_300):\n",
      "=> \"Files and versions\" > \"Add file\" > \"Upload file\" => Upload the README.md file\n",
      "\n",
      "See https://huggingface.co/docs/datasets/v2.0.0/dataset_card for a guide and https://huggingface.co/datasets/mdroth/github_issues_300 for an example.\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "print(\"Procedure\")\n",
    "print('1. Read the above section on \"Creating a dataset card\".')\n",
    "print('2. Create tags with the \"HuggingFace Dataset Tagger\" at {}.'.format(\n",
    "    \"https://huggingface.co/spaces/huggingface/datasets-tagging\"\n",
    "))\n",
    "print('3. Create a README.md file / dataset card with the \"card-creator\" at {}.'.format(\n",
    "    \"https://huggingface.co/datasets/card-creator\"\n",
    "))\n",
    "print('4. Upload the README.md file / dataset card to the model repo (in this case {}):'.format(\n",
    "    \"https://huggingface.co/datasets/mdroth/github_issues_300\"\n",
    "))\n",
    "print('=> \"Files and versions\" > \"Add file\" > \"Upload file\" => Upload the README.md file')\n",
    "print('\\nSee {} for a guide and {} for an example.'.format(\n",
    "    \"https://huggingface.co/docs/datasets/v2.0.0/dataset_card\",\n",
    "    \"https://huggingface.co/datasets/mdroth/github_issues_300\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a97d5",
   "metadata": {},
   "source": [
    "That's it! We've seen in this section that creating a good dataset can be quite involved, but fortunately uploading it and sharing it with the community is not. In the next section we'll use our new dataset to create a semantic search engine with 🤗 Datasets that can match questions to the most relevant issues and comments.\n",
    "\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">Go through the steps we took in this section to create a dataset of GitHub issues for your favorite open source library (pick something other than 🤗 Datasets, of course!). For bonus points, fine-tune a multilabel classifier to predict the tags present in the `labels` field.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09fcb027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-141858a465b2fe0e\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/default-141858a465b2fe0e/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-141858a465b2fe0e/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-b05d5a409dd115cb.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-141858a465b2fe0e/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-5f7c0994dd04b4d9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'draft', 'pull_request', 'body', 'reactions', 'timeline_url', 'performed_via_github_app'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1673e78b5e3b47d68de5740e76b2e1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6f4f5ed1c04b509228bcf786e02613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering\n",
      "=> Empty labels for index 0:\t\t[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3931f0177606495d85e8d6f8e4e68ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering\n",
      "=> Non-empty labels for index 0:\t['bug']\n",
      "\n",
      "Dataset with num_labels:\n",
      "Dataset({\n",
      "    features: ['url', 'text', 'num_labels', 'arr_labels', 'labels'],\n",
      "    num_rows: 1385\n",
      "})\n",
      "\n",
      "### text #######################################################################\n",
      "\n",
      "TITLE\n",
      "[Kernel Fusion] Training benchmarks of Torchdynamo + AOTAutograd (many models)\n",
      "\n",
      "COMMENTS\n",
      "5\n",
      "\n",
      "REACTIONS\n",
      "+1: 0\n",
      "-1: 0\n",
      "laugh: 0\n",
      "hooray: 0\n",
      "heart: 1\n",
      "rocket: 0\n",
      "eyes: 0\n",
      "\n",
      "BODY\n",
      "Note to maintainers: We are using this PR to collaborate and there is no intention yet to merge anything, so please ignore unless you want to experiment with the latest auto-speedups.\r\n",
      "\r\n",
      "## What was the issue with the previous AOTAutograd integration?\r\n",
      "So, there was some investigation into applying AOTAutograd a couple months ago in this PR (https://github.com/huggingface/transformers/pull/15264). Although the performance results were quite promising, @stas00 and I found one major blocker - the potential for incorrect semantics. AOTAutograd is a tracing-based approach, and as such, it's fairly difficult for it to guarantee that its semantics are always correct. For example, data-dependent control flow, use of third-party libraries (like Numpy), or modification of global state all posed problems for integrating AOTAutograd into HuggingFace. Considering that HF has >100 models (and is adding more every day!), the burden of needing to ensure that AOTAutograd produces correct results would have been quite burdensome.\r\n",
      "\r\n",
      "## TorchDynamo to the rescue\r\n",
      "Luckily, now, there's another solution in the form of [Torchdynamo](https://dev-discuss.pytorch.org/t/torchdynamo-an-experiment-in-dynamic-python-bytecode-transformation/361) (from @jansel)! In contrast to tracing based approaches like `jit.trace` and AOTAutograd, Torchdynamo is *sound* - it should never produce incorrect results (modulo bugs). In comparison to approaches like `jit.script`, Torchdynamo is much more *complete* - it should allow any PyTorch code to be able to run, although it may not always speed things up.\r\n",
      "\r\n",
      "The central approach that TorchDynamo takes is that as opposed to trying to live at the AST level (i.e. `jit.script`) or the object-level (i.e. tracing like `jit.trace`), it lives at the Python bytecode level. This is similar to the approach that language JITs like Javascript's V8 or JVM's Hotspot take. By living at this level, it's able to ensure that it can support *all* Python, as it can always fall back to eager-mode execution. Let's take an example of some code that would have been very problematic previously.\r\n",
      "\r\n",
      "```\r\n",
      "def f(x):\r\n",
      "    a = x * 2\r\n",
      "    b = a + torch.from_numpy(np.randn(5))\r\n",
      "    if b.sum() > 0:\r\n",
      "        return d.sin().sin()\r\n",
      "    else:\r\n",
      "        return d.cos().cos()\r\n",
      "```\r\n",
      "Not only does this have data-dependent control flow - it also has calls to external libraries that aren't PyTorch! (numpy in this case). TorchDynamo (morally) would rewrite this code into something like this:\r\n",
      "```\r\n",
      "def block1(x, np_tensor):\r\n",
      "    a = x * 2\r\n",
      "    b = a + np_tensor\r\n",
      "    return b\r\n",
      "\r\n",
      "def block2(b):\r\n",
      "    return b.sin().sin()\r\n",
      "\r\n",
      "def block3(b):\r\n",
      "    return b.sin().sin()\r\n",
      "\r\n",
      "def f_dynamo(x):\r\n",
      "    b = block1(x, torch.from_numpy(np.randn(5))\r\n",
      "    if b.sum() > 0:\r\n",
      "        return block2(b)\r\n",
      "    else:\r\n",
      "        return block3(b)\r\n",
      "```\r\n",
      "\r\n",
      "Note that `block1`, `block2`, and `block3` are just simple straight line functions - exactly what AOTAutograd can handle! So, we can now apply AOTAutograd to each of those blocks.\r\n",
      "\r\n",
      "In this way, TorchDynamo and AOTAutograd complement each other - TorchDynamo resolves the dynamic/non-traceable behavior that AOTAutograd can't handle, and AOTAutograd then provides static compilation that handles things like PyTorch's autograd.\r\n",
      "\r\n",
      "So, what do you need to do to use AOTAutograd with Torchdynamo? Well, it's simple!\r\n",
      "```\r\n",
      "import torchdynamo\r\n",
      "from torchdynamo.optimizations.training import aot_autograd_speedup_strategy\r\n",
      "with torchdynamo.optimize(aot_autograd_speedup_strategy):\r\n",
      "    # run your model here!\r\n",
      "```\r\n",
      "\r\n",
      "## Results\r\n",
      "This script primarily comes from a great effort from @anijain2305. However, I want to note a couple of things.\r\n",
      "\r\n",
      "1. In contrast with the pure AOTAutograd integration, where our benchmark only covered 3.5 models (and had some tricky to debug correctness issues), it was fairly trivial to extend this benchmarking to 14 models (with correctness testing for all of them!) In fact, the main bottleneck to adding more is just figuring out how to run more models (I pretty much exhausted all of the AutoConfig ones I could run easily).\r\n",
      "2. For the most part, TorchDynamo + AOTAutograd improves both performance and memory usage. On some models, quite significantly (1.4x+ for MobileBert, FNet, and Albert), but it generally improves performance for nearly all models.\r\n",
      "3. For many of these models, we *can't* produce a single graph to compile, often due to Numpy usage. Here, it's crucial that torchdynamo passes multiple graphs to AOTAutograd.\r\n",
      "4. Currently, we feed the graphs produced by TorchDynamo and AOTAutograd into NVFuser. But, in the future, other backends should have no issues integrating into this as well (and in fact, we *have* some extra integrations, like TensorRT).\r\n",
      "\r\n",
      "Run on A100:\r\n",
      "```\r\n",
      "$ python hf_dynamo_aot.py --run-dynamo-aot-efficient --nvfuser\r\n",
      "```\r\n",
      "Results:\r\n",
      "\r\n",
      "| model                      | dtype          | name                 |   time (s) |   mem (GB) |   speedup |   mem comp ression |\r\n",
      "|:---------------------------|:---------------|---------------------|-----------:|-----------:|----------:|------------------:|\r\n",
      "| BertForMaskedLM            | float32  |eager                |      0.040 |      3.521 |     1.000 |             1.000 |\r\n",
      "| BertForMaskedLM            | float32  |dynamo_aot_efficient |      0.037 |      3.516 |     1.094 |             1.001 |\r\n",
      "| BertForMaskedLM            | float16  |eager                |      0.027 |      1.880 |     1.000 |             1.000 |\r\n",
      "| BertForMaskedLM            | float16  |dynamo_aot_efficient |      0.023 |      1.885 |     1.155 |             0.997 |\r\n",
      "| BertForMaskedLM            | bfloat16 |eager                |      0.027 |      1.874 |     1.000 |             1.000 |\r\n",
      "| BertForMaskedLM            | bfloat16 |dynamo_aot_efficient |      0.023 |      1.867 |     1.154 |             1.003 |\r\n",
      "| AlbertForMaskedLM          | float32  |eager                |      0.081 |      6.070 |     1.000 |             1.000 |\r\n",
      "| AlbertForMaskedLM          | float32  |dynamo_aot_efficient |      0.056 |      3.943 |     1.442 |             1.539 |\r\n",
      "| AlbertForMaskedLM          | float16  |eager                |      0.046 |      2.908 |     1.000 |             1.000 |\r\n",
      "| AlbertForMaskedLM          | float16  |dynamo_aot_efficient |      0.035 |      1.971 |     1.338 |             1.475 |\r\n",
      "| AlbertForMaskedLM          | bfloat16 |eager                |      0.048 |      2.866 |     1.000 |             1.000 |\r\n",
      "| AlbertForMaskedLM          | bfloat16 |dynamo_aot_efficient |      0.035 |      1.972 |     1.374 |             1.453 |\r\n",
      "| GPT2LMHeadModel            | float32  |eager                |      0.055 |      4.632 |     1.000 |             1.000 |\r\n",
      "| GPT2LMHeadModel            | float32  |dynamo_aot_efficient |      0.043 |      3.791 |     1.280 |             1.222 |\r\n",
      "| GPT2LMHeadModel            | float16  |eager                |      0.036 |      2.426 |     1.000 |             1.000 |\r\n",
      "| GPT2LMHeadModel            | float16  |dynamo_aot_efficient |      0.029 |      2.018 |     1.213 |             1.203 |\r\n",
      "| GPT2LMHeadModel            | bfloat16 |eager                |      0.036 |      2.425 |     1.000 |             1.000 |\r\n",
      "| GPT2LMHeadModel            | bfloat16 |dynamo_aot_efficient |      0.030 |      1.998 |     1.208 |             1.214 |\r\n",
      "| LongformerForMaskedLM      | float32  |eager                |      0.121 |      4.591 |     1.000 |             1.000 |\r\n",
      "| LongformerForMaskedLM      | float32  |dynamo_aot_efficient |      0.120 |      4.585 |     1.006 |             1.001 |\r\n",
      "| LongformerForMaskedLM      | float16  |eager                |      0.096 |      2.711 |     1.000 |             1.000 |\r\n",
      "| LongformerForMaskedLM      | float16  |dynamo_aot_efficient |      0.096 |      2.705 |     1.005 |             1.002 |\r\n",
      "| T5ForConditionalGeneration | float32  |eager                |      0.103 |      8.300 |     1.000 |             1.000 |\r\n",
      "| T5ForConditionalGeneration | float32  |dynamo_aot_efficient |      0.098 |      7.831 |     1.050 |             1.060 |\r\n",
      "| DistilBertForMaskedLM      | float32  |eager                |      0.045 |      3.492 |     1.000 |             1.000 |\r\n",
      "| DistilBertForMaskedLM      | float32  |dynamo_aot_efficient |      0.043 |      3.497 |     1.038 |             0.999 |\r\n",
      "| DistilBertForMaskedLM      | float16  |eager                |      0.026 |      1.870 |     1.000 |             1.000 |\r\n",
      "| DistilBertForMaskedLM      | float16  |dynamo_aot_efficient |      0.027 |      1.871 |     0.963 |             0.999 |\r\n",
      "| DistilBertForMaskedLM      | bfloat16 |eager                |      0.026 |      1.860 |     1.000 |             1.000 |\r\n",
      "| DistilBertForMaskedLM      | bfloat16 |dynamo_aot_efficient |      0.027 |      1.861 |     0.986 |             1.000 |\r\n",
      "| RobertaForMaskedLM         | float32  |eager                |      0.157 |     12.366 |     1.000 |             1.000 |\r\n",
      "| RobertaForMaskedLM         | float32  |dynamo_aot_efficient |      0.135 |     12.341 |     1.164 |             1.002 |\r\n",
      "| RobertaForMaskedLM         | float16  |eager                |      0.098 |      6.573 |     1.000 |             1.000 |\r\n",
      "| RobertaForMaskedLM         | float16  |dynamo_aot_efficient |      0.088 |      6.567 |     1.114 |             1.001 |\r\n",
      "| RobertaForMaskedLM         | bfloat16 |eager                |      0.101 |      6.579 |     1.000 |             1.000 |\r\n",
      "| RobertaForMaskedLM         | bfloat16 |dynamo_aot_efficient |      0.088 |      6.559 |     1.140 |             1.003 |\r\n",
      "| GPT2LMHeadModel            | float32  |eager                |      0.123 |      9.292 |     1.000 |             1.000 |\r\n",
      "| GPT2LMHeadModel            | float32  |dynamo_aot_efficient |      0.098 |      7.108 |     1.256 |             1.307 |\r\n",
      "| GPT2LMHeadModel            | float16  |eager                |      0.080 |      4.610 |     1.000 |             1.000 |\r\n",
      "| GPT2LMHeadModel            | float16  |dynamo_aot_efficient |      0.067 |      3.767 |     1.182 |             1.224 |\r\n",
      "| GPT2LMHeadModel            | bfloat16 |eager                |      0.081 |      4.779 |     1.000 |             1.000 |\r\n",
      "| GPT2LMHeadModel            | bfloat16 |dynamo_aot_efficient |      0.068 |      3.763 |     1.191 |             1.270 |\r\n",
      "| ElectraForMaskedLM         | float32  |eager                |      0.074 |      6.257 |     1.000 |             1.000 |\r\n",
      "| ElectraForMaskedLM         | float32  |dynamo_aot_efficient |      0.064 |      6.258 |     1.151 |             1.000 |\r\n",
      "| ElectraForMaskedLM         | float16  |eager                |      0.042 |      3.356 |     1.000 |             1.000 |\r\n",
      "| ElectraForMaskedLM         | float16  |dynamo_aot_efficient |      0.039 |      3.347 |     1.092 |             1.003 |\r\n",
      "| ElectraForMaskedLM         | bfloat16 |eager                |      0.044 |      3.367 |     1.000 |             1.000 |\r\n",
      "| ElectraForMaskedLM         | bfloat16 |dynamo_aot_efficient |      0.039 |      3.341 |     1.124 |             1.008 |\r\n",
      "| FNetForMaskedLM            | float32  |eager                |      0.055 |      4.974 |     1.000 |             1.000 |\r\n",
      "| FNetForMaskedLM            | float32  |dynamo_aot_efficient |      0.038 |      2.802 |     1.429 |             1.775 |\r\n",
      "| ConvBertForMaskedLM        | float32  |eager                |      0.090 |      5.809 |     1.000 |             1.000 |\r\n",
      "| ConvBertForMaskedLM        | float32  |dynamo_aot_efficient |      0.085 |      5.795 |     1.058 |             1.002 |\r\n",
      "| ConvBertForMaskedLM        | float16  |eager                |      0.064 |      3.021 |     1.000 |             1.000 |\r\n",
      "| ConvBertForMaskedLM        | float16  |dynamo_aot_efficient |      0.062 |      3.009 |     1.024 |             1.004 |\r\n",
      "| MobileBertForMaskedLM      | float32  |eager                |      0.104 |      2.474 |     1.000 |             1.000 |\r\n",
      "| MobileBertForMaskedLM      | float32  |dynamo_aot_efficient |      0.069 |      2.576 |     1.499 |             0.961 |\r\n",
      "| MobileBertForMaskedLM      | float16  |eager                |      0.101 |      1.329 |     1.000 |             1.000 |\r\n",
      "| MobileBertForMaskedLM      | float16  |dynamo_aot_efficient |      0.067 |      1.423 |     1.499 |             0.934 |\r\n",
      "| MobileBertForMaskedLM      | bfloat16 |eager                |      0.100 |      1.330 |     1.000 |             1.000 |\r\n",
      "| MobileBertForMaskedLM      | bfloat16 |dynamo_aot_efficient |      0.067 |      1.423 |     1.504 |             0.935 |\r\n",
      "| CamembertForMaskedLM       | float32  |eager                |      0.075 |      6.312 |     1.000 |             1.000 |\r\n",
      "| CamembertForMaskedLM       | float32  |dynamo_aot_efficient |      0.065 |      6.317 |     1.151 |             0.999 |\r\n",
      "| CamembertForMaskedLM       | float16  |eager                |      0.047 |      3.376 |     1.000 |             1.000 |\r\n",
      "| CamembertForMaskedLM       | float16  |dynamo_aot_efficient |      0.044 |      3.366 |     1.084 |             1.003 |\r\n",
      "| CamembertForMaskedLM       | bfloat16 |eager                |      0.049 |      3.390 |     1.000 |             1.000 |\r\n",
      "| CamembertForMaskedLM       | bfloat16 |dynamo_aot_efficient |      0.044 |      3.370 |     1.113 |             1.006 |\r\n",
      "| LayoutLMForMaskedLM        | float32  |eager                |      0.077 |      6.305 |     1.000 |             1.000 |\r\n",
      "| LayoutLMForMaskedLM        | float32  |dynamo_aot_efficient |      0.067 |      6.305 |     1.149 |             1.000 |\r\n",
      "| LayoutLMForMaskedLM        | float16  |eager                |      0.045 |      3.371 |     1.000 |             1.000 |\r\n",
      "| LayoutLMForMaskedLM        | float16  |dynamo_aot_efficient |      0.042 |      3.373 |     1.089 |             0.999 |\r\n",
      "| LayoutLMForMaskedLM        | bfloat16 |eager                |      0.047 |      3.389 |     1.000 |             1.000 |\r\n",
      "| LayoutLMForMaskedLM        | bfloat16 |dynamo_aot_efficient |      0.042 |      3.371 |     1.118 |             1.005 |\r\n",
      "\r\n",
      "\r\n",
      "Reading resources:\r\n",
      "AOTAutograd: https://docs.google.com/presentation/d/1rTt0BR2KChDQQTks2hHUtvHxtHQKwgQHVNrmbhj0byk/edit?usp=sharing\r\n",
      "TorchDynamo: https://dev-discuss.pytorch.org/t/torchdynamo-an-experiment-in-dynamic-python-bytecode-transformation/361\r\n",
      "Min-Cut rematerialization: https://dev-discuss.pytorch.org/t/min-cut-optimal-recomputation-i-e-activation-checkpointing-with-aotautograd/467/7\n",
      "\n",
      "### labels #####################################################################\n",
      "\n",
      "['Benchmarks', 'Performance']\n",
      "\n",
      "### num_labels #################################################################\n",
      "\n",
      "[6, 21]\n",
      "\n",
      "### arr_labels #################################################################\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "### url ########################################################################\n",
      "\n",
      "https://api.github.com/repos/huggingface/transformers/issues/17204\n",
      "\n",
      "################################################################################\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['url', 'text', 'num_labels', 'arr_labels', 'labels'],\n",
      "        num_rows: 883\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['url', 'text', 'num_labels', 'arr_labels', 'labels'],\n",
      "        num_rows: 220\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['url', 'text', 'num_labels', 'arr_labels', 'labels'],\n",
      "        num_rows: 277\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['url', 'text', 'num_labels', 'arr_labels', 'labels'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The repository already exists: the `private` keyword argument will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdee2be91e3c4ecb8e7df6a86768fcbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split valid to the Hub.\n",
      "The repository already exists: the `private` keyword argument will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3502977a18c4afa9b5f2dbad5b920fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n",
      "The repository already exists: the `private` keyword argument will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac35ed89e455475eb9fd27104c490995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split dev to the Hub.\n",
      "The repository already exists: the `private` keyword argument will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802768820355403396555dca715e70ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trying it out\n",
    "import json\n",
    "## load the file \"transformers-issues.jsonl\" that has been created by using 'fetch_issues(repo=\"transformers\")' ...\n",
    "## ... instead of 'fetch_issues()' just below the definition of the 'fetch_issues()' function further above\n",
    "transformers_issues_dataset = load_dataset(\"json\", data_files=\"data/transformers-issues.jsonl\", split=\"train\")\n",
    "## add columns \"text\" and \"num_labels\"\n",
    "print(transformers_issues_dataset)\n",
    "transformers_issues_text_dataset_1 = transformers_issues_dataset.rename_column(\n",
    "    original_column_name=\"repository_url\", new_column_name=\"text\"\n",
    ")\n",
    "transformers_issues_text_dataset_0 = transformers_issues_text_dataset_1.rename_column(\n",
    "    original_column_name=\"labels_url\", new_column_name=\"num_labels\"\n",
    ")\n",
    "transformers_issues_text_dataset = transformers_issues_text_dataset_0.rename_column(\n",
    "    original_column_name=\"comments_url\", new_column_name=\"arr_labels\"\n",
    ")\n",
    "del transformers_issues_dataset, transformers_issues_text_dataset_0, transformers_issues_text_dataset_1\n",
    "## combine the columns \"title\", \"comments\", \"reactions\", and \"body\" into a single string in the new \"text\" column\n",
    "feature_keys = [\"title\", \"comments\", \"reactions\", \"body\"]\n",
    "reaction_keys = [\"+1\", \"-1\", \"laugh\", \"hooray\", \"heart\", \"rocket\", \"eyes\"]\n",
    "def make_text(item):\n",
    "    text = \"\"\n",
    "    for fk_i in feature_keys:\n",
    "        if fk_i==\"reactions\":\n",
    "            text += f\"\\n\\n{fk_i.upper()}\"\n",
    "            reactions = item[fk_i]\n",
    "            reactions_json = json.loads(json.dumps(reactions, indent = 4))\n",
    "            for rk_i in reaction_keys:\n",
    "                rk_iCount = reactions_json[rk_i]\n",
    "                text += f\"\\n{rk_i}: {rk_iCount}\"\n",
    "        else:\n",
    "            text += f\"\\n\\n{fk_i.upper()}\\n{item[fk_i]}\"\n",
    "    item[\"text\"] = text\n",
    "    return item\n",
    "transformers_issues_text_dataset = transformers_issues_text_dataset.map(make_text)\n",
    "## build labels (list of strings)\n",
    "def make_labels(item):\n",
    "    labels = item[\"labels\"]\n",
    "    label_list = []\n",
    "    for label in labels:\n",
    "        label_json = json.loads(json.dumps(label, indent=4))\n",
    "        label_name = label_json[\"name\"]\n",
    "        label_list.append(label_name)\n",
    "    item[\"labels\"] = label_list\n",
    "    return item\n",
    "transformers_issues_text_dataset = transformers_issues_text_dataset.map(make_labels)\n",
    "## build num_labels (list of numbers) ...\n",
    "## ... see also https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-a-list-of-lists\n",
    "flat_label_list = [label for labels_i in transformers_issues_text_dataset[\"labels\"] for label in labels_i]\n",
    "unique_labels = list(set(flat_label_list))\n",
    "n_unique_labels = len(unique_labels)\n",
    "def make_num_labels(item):\n",
    "    label_list = item[\"labels\"]\n",
    "    num_label_list = []\n",
    "    for label in label_list:\n",
    "        num_label = unique_labels.index(label)\n",
    "        num_label_list.append(num_label)\n",
    "    item[\"num_labels\"] = num_label_list\n",
    "    return item\n",
    "transformers_issues_text_dataset = transformers_issues_text_dataset.map(make_num_labels)\n",
    "## build arr_labels (full list of 0s and 1s)\n",
    "def make_arr_labels(item):\n",
    "    num_labels = item[\"num_labels\"]\n",
    "    arr_label_list = [0 for _ in range(n_unique_labels)]\n",
    "    for num_label in num_labels:\n",
    "        arr_label_list[num_label] = 1\n",
    "    item[\"arr_labels\"] = arr_label_list\n",
    "    return item\n",
    "transformers_issues_text_dataset = transformers_issues_text_dataset.map(make_arr_labels)\n",
    "## filter for instances with labels!=[]\n",
    "idx = 0\n",
    "print(f'Before filtering\\n=> Empty labels for index {idx}:\\t\\t{transformers_issues_text_dataset[\"labels\"][idx]}')\n",
    "transformers_issues_text_dataset = transformers_issues_text_dataset.filter(lambda x: x[\"labels\"]!=[])\n",
    "print(f'After filtering\\n=> Non-empty labels for index {idx}:\\t{transformers_issues_text_dataset[\"labels\"][idx]}')\n",
    "## remove all columns but \"labels\", \"text\", and \"url\"\n",
    "keep_keys = [\"text\", \"labels\", \"num_labels\", \"arr_labels\", \"url\"]\n",
    "remove_keys = [key for key in list(transformers_issues_text_dataset.features.keys()) if key not in keep_keys]\n",
    "transformers_issues_text_dataset = transformers_issues_text_dataset.remove_columns(remove_keys)\n",
    "## show dataset\n",
    "print(f\"\\nDataset with num_labels:\\n{transformers_issues_text_dataset}\")\n",
    "idx = 5 # 5 or 13\n",
    "print(f'\\n{3*\"#\"+\" \"}text{\" \"+71*\"#\"}{transformers_issues_text_dataset[\"text\"][idx]}')\n",
    "print(f'\\n{3*\"#\"+\" \"}labels{\" \"+69*\"#\"}\\n\\n{transformers_issues_text_dataset[\"labels\"][idx]}')\n",
    "print(f'\\n{3*\"#\"+\" \"}num_labels{\" \"+65*\"#\"}\\n\\n{transformers_issues_text_dataset[\"num_labels\"][idx]}')\n",
    "print(f'\\n{3*\"#\"+\" \"}arr_labels{\" \"+65*\"#\"}\\n\\n{transformers_issues_text_dataset[\"arr_labels\"][idx]}')\n",
    "print(f'\\n{3*\"#\"+\" \"}url{\" \"+72*\"#\"}\\n\\n{transformers_issues_text_dataset[\"url\"][idx]}')\n",
    "print(f'\\n{80*\"#\"}\\n')\n",
    "## try to add class names\n",
    "#\n",
    "#https://discuss.huggingface.co/t/how-to-create-custom-classlabels/13650\n",
    "#from datasets import ClassLabel\n",
    "#features = transformers_issues_text_dataset.features.copy()\n",
    "#print(features)\n",
    "#features[\"arr_labels\"] = ClassLabel(names=unique_labels)\n",
    "#print(features)\n",
    "#transformers_issues_text_dataset = transformers_issues_text_dataset.map(\n",
    "#    lambda batch: batch, batched=False, features=features\n",
    "#)\n",
    "#\n",
    "## DatasetDict: make splits, build, print, and push to hub\n",
    "train_dev = transformers_issues_text_dataset.train_test_split(shuffle=True, seed=421, test_size=0.003)\n",
    "train_validTest = train_dev[\"train\"].train_test_split(shuffle=True, seed=42, test_size=0.36)\n",
    "valid_test = train_validTest[\"test\"].train_test_split(shuffle=True, seed=42, test_size=5/9)\n",
    "transformers_issues_text_dataset = DatasetDict({\n",
    "    \"train\": train_validTest[\"train\"],\n",
    "    \"valid\": valid_test[\"train\"],\n",
    "    \"test\": valid_test[\"test\"],\n",
    "    \"dev\": train_dev[\"test\"]\n",
    "})\n",
    "print(transformers_issues_text_dataset)\n",
    "transformers_issues_text_dataset.push_to_hub(repo_id=\"transformers_issues_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6fcdd148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /Users/matthias/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /Users/matthias/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Using custom data configuration mdroth--transformers_issues_labels-e1a55ed64424aafd\n",
      "Reusing dataset parquet (/Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbaad58b1d174bc28b936d10e8a635a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057d33e89d074e678c3d33f5286a2ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc9b13d23d0490894ecac6b2adca045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7755fd8b85461c9ee804bb3d2b5386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdbb87015ef42b897bc868b4cfbc689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['arr_labels', 'input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'arr_labels': torch.Size([3, 57]),\n",
       " 'input_ids': torch.Size([3, 512]),\n",
       " 'token_type_ids': torch.Size([3, 512]),\n",
       " 'attention_mask': torch.Size([3, 512])}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5\n",
    "checkpoint = \"bert-base-cased\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "transformers_datasets = load_dataset(\"mdroth/transformers_issues_labels\")\n",
    "transformers_dev = transformers_datasets[\"valid\"]\n",
    "def transformers_tokenize_function(item):                         # tokenization function for .map method\n",
    "    return tokenizer(item[\"text\"], truncation=True)\n",
    "tokenized_transformers_datasets = transformers_datasets.map(transformers_tokenize_function, batched=True)\n",
    "transformers_dev_samples = tokenized_transformers_datasets[\"dev\"][:3]\n",
    "# keys: 'url', 'text', 'num_labels', 'arr_labels', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'\n",
    "# keep: 'input_ids', 'token_type_ids', 'attention_mask', 'labels'\n",
    "drop_list = [\"url\", \"text\", \"num_labels\", \"labels\", \"labels\", \"num_labels\", \"num_labels\", \"num_labels\"]\n",
    "transformers_dev_purged = {k: v for k, v in transformers_dev_samples.items() if k not in drop_list}\n",
    "print(transformers_dev_purged.keys())\n",
    "transformers_dev_batch = data_collator(transformers_dev_purged)\n",
    "{k: v.shape for k, v in transformers_dev_batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fcfce9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /Users/matthias/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /Users/matthias/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/matthias/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Reusing dataset glue (/Users/matthias/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f6d31a2739477ebdb116115b73035c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-4c0157f618b9067d.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6da45ad754e4d1890de380b0d35dcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-50c7d36b9e5220b0.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([3, 15]),\n",
       " 'token_type_ids': torch.Size([3, 15]),\n",
       " 'attention_mask': torch.Size([3, 15]),\n",
       " 'labels': torch.Size([3])}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "sst2_raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
    "sst2_train = sst2_raw_datasets[\"train\"]\n",
    "def sst2_tokenize_function(item):                         # tokenization function for .map method\n",
    "    return tokenizer(item[\"sentence\"], truncation=True)\n",
    "tokenized_sst2_datasets = sst2_raw_datasets.map(sst2_tokenize_function, batched=True) # batch-tokenize all datasets\n",
    "sst2_train_samples = tokenized_sst2_datasets[\"train\"][:3] # get first 3 tokenized samples of the training set\n",
    "sst2_train_purged = {k: v for k, v in sst2_train_samples.items() if k not in [\"idx\", \"sentence\"]}\n",
    "# keep: input_ids', 'token_type_ids', 'attention_mask', 'labels'\n",
    "sst2_train_batch = data_collator(sst2_train_purged)       # use data_collator to turn samples into a batch\n",
    "{k: v.shape for k, v in sst2_train_batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e5190",
   "metadata": {},
   "source": [
    "Still trying it out...<br>\n",
    "Dataset complete - model, training, and inference next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "40febfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /Users/matthias/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /Users/matthias/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /Users/matthias/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /Users/matthias/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=tensor(3.8668, grad_fn=<NllLossBackward>), logits=tensor([[-0.1130,  0.2962, -0.7920, -0.4224, -0.5464, -0.1320, -0.4443,  0.0040,\n",
      "         -0.3799, -0.5812, -0.3424,  0.1943,  0.6863,  0.4740,  0.4720,  0.1674,\n",
      "         -0.3009,  0.5291, -0.3000, -0.2796,  0.5407, -0.1862, -0.1723, -0.0596,\n",
      "         -0.0424,  0.2617, -0.5475, -0.0855, -0.5546,  0.5824,  0.3372,  0.0988,\n",
      "          0.1305,  0.0407, -0.4151, -0.2011, -0.2987, -0.8742,  0.3055, -0.0754,\n",
      "         -0.5178, -1.0479,  0.5191,  1.4233,  0.7420,  0.6309, -0.3406,  0.0797,\n",
      "         -0.2000,  0.0123,  0.2187,  1.2506, -0.5081,  0.6031, -0.3315,  0.1463,\n",
      "         -0.1579]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n",
      "tensor([[0.0139, 0.0209, 0.0070, 0.0102, 0.0090, 0.0136, 0.0100, 0.0156, 0.0106,\n",
      "         0.0087, 0.0110, 0.0189, 0.0309, 0.0250, 0.0249, 0.0184, 0.0115, 0.0264,\n",
      "         0.0115, 0.0118, 0.0267, 0.0129, 0.0131, 0.0147, 0.0149, 0.0202, 0.0090,\n",
      "         0.0143, 0.0089, 0.0279, 0.0218, 0.0172, 0.0177, 0.0162, 0.0103, 0.0127,\n",
      "         0.0115, 0.0065, 0.0211, 0.0144, 0.0093, 0.0055, 0.0262, 0.0646, 0.0327,\n",
      "         0.0292, 0.0111, 0.0169, 0.0127, 0.0158, 0.0194, 0.0543, 0.0094, 0.0284,\n",
      "         0.0112, 0.0180, 0.0133]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DefaultDataCollator, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import torch\n",
    "num_labels = len(unique_labels)\n",
    "# instantiate model\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "#model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=num_labels)\n",
    "checkpoint = \"bert-base-cased\"\n",
    "transformers_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "transformers_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels)\n",
    "# produce model outputs (https://huggingface.co/docs/transformers/main_classes/output)\n",
    "inputs = transformers_tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = transformers_model(**inputs, labels=labels)\n",
    "# find examples on how to:\n",
    "# (check previous chapters)\n",
    "# > turn logits to predictions\n",
    "# > turn logits + labels to loss\n",
    "# > use loss for optimization\n",
    "# > ...?\n",
    "print(outputs)\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1071450d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration mdroth--transformers_issues_labels-e1a55ed64424aafd\n",
      "Reusing dataset parquet (/Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513ad40d841d4d46a18026d59fd9c661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f352c5d48f70480392da0b6f6d1b44cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ea5c06d948487ba345045e2bc9790f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1547675a471449cb03629d9220ae83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b312e6b92d67473998e460c533c300e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    valid: Dataset({\n",
       "        features: ['url', 'text', 'num_labels', 'labels', 'int_labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 220\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['url', 'text', 'num_labels', 'labels', 'int_labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['url', 'text', 'num_labels', 'labels', 'int_labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 277\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['url', 'text', 'num_labels', 'labels', 'int_labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 883\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect each line!\n",
    "## load dataset, tokenize, and apply datacollator\n",
    "transformers_dataset = load_dataset(\"mdroth/transformers_issues_labels\")\n",
    "#checkpoint = \"bert-base-cased\"\n",
    "#transformers_tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "def transformers_tokenize_function(item):                         # tokenization function for .map method\n",
    "    return transformers_tokenizer(item[\"text\"], padding=True, truncation=True)\n",
    "transformers_tokenized_datasets = transformers_dataset.map(transformers_tokenize_function, batched=True)\n",
    "# 'arr_labels', 'labels'\n",
    "# 'labels' -> \"int_labels\"\n",
    "# 'arr_labels' -> \"labels\"\n",
    "transformers_tokenized_datasets = transformers_tokenized_datasets.rename_column(\"labels\", \"int_labels\")\n",
    "transformers_tokenized_datasets = transformers_tokenized_datasets.rename_column(\"arr_labels\", \"labels\")\n",
    "transformers_tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21e7e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /Users/matthias/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /Users/matthias/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Using custom data configuration mdroth--transformers_issues_labels-e1a55ed64424aafd\n",
      "Reusing dataset parquet (/Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0990a71c5b48ce8f7b187849a30993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-6abb82432ea4f160.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-71378fd7107bbfbb.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-697e1bed1cdd157e.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-eb557e2d389372ac.arrow\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /Users/matthias/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 5\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (4) to match target batch_size (228).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-488f973a6e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[0;31m## train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 if (\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1578\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"single_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1048\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2384\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2385\u001b[0m             \u001b[0;34m\"Expected input batch_size ({}) to match target batch_size ({}).\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2386\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (4) to match target batch_size (228)."
     ]
    }
   ],
   "source": [
    "# inspect each line!\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "## load dataset, tokenize, adapt columns, and apply datacollator\n",
    "checkpoint = \"bert-base-cased\"\n",
    "transformers_tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "def transformers_tokenize_function(item):\n",
    "    return transformers_tokenizer(item[\"text\"], padding=True, truncation=True)\n",
    "transformers_tokenized_datasets = (\n",
    "    load_dataset(\"mdroth/transformers_issues_labels\")\n",
    "    .map(transformers_tokenize_function, batched=True)\n",
    "    .remove_columns(column_names=[\"url\", \"text\", \"num_labels\", \"labels\"])\n",
    "    .rename_column(\"arr_labels\", \"labels\") # https://discuss.huggingface.co/t/why-am-i-getting-keyerror-loss/6948\n",
    ")\n",
    "transformers_data_collator = DataCollatorWithPadding(tokenizer=transformers_tokenizer)\n",
    "## training arguments\n",
    "training_args = TrainingArguments(\n",
    "    # https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\n",
    "    \"5_try_transformers_dataset\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4\n",
    ")\n",
    "## model\n",
    "num_labels = 57#len(unique_labels) # =57\n",
    "transformers_model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels)\n",
    "## compute_metrics\n",
    "## trainer\n",
    "trainer = Trainer(\n",
    "    transformers_model,\n",
    "    training_args,\n",
    "    train_dataset=transformers_tokenized_datasets[\"dev\"],\n",
    "    eval_dataset=transformers_tokenized_datasets[\"dev\"],\n",
    "    data_collator=transformers_data_collator,\n",
    "    tokenizer=transformers_tokenizer,\n",
    "    #preprocess_logits_for_metrics=lambda x: torch.reshape(x, (-1, 57))\n",
    ")\n",
    "## train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f13a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60414bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 57])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 57]), torch.Size([228]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_logits_for_metrics(logits):\n",
    "    x = torch.reshape(logits, (-1, 57))\n",
    "    return x\n",
    "logits = torch.randn(228)\n",
    "preprocess_logits_for_metrics(logits).size(), logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c9829779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration mdroth--transformers_issues_labels-e1a55ed64424aafd\n",
      "Reusing dataset parquet (/Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862bbb18daec4800becad0cf874d3f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /Users/matthias/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /Users/matthias/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-6abb82432ea4f160.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-71378fd7107bbfbb.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-697e1bed1cdd157e.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/parquet/mdroth--transformers_issues_labels-e1a55ed64424aafd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-eb557e2d389372ac.arrow\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    valid: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 220\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 277\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 883\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/matthias/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /Users/matthias/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 5\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (4) to match target batch_size (228).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-5bd790880593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[0;31m## train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 if (\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1578\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"single_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1048\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2384\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2385\u001b[0m             \u001b[0;34m\"Expected input batch_size ({}) to match target batch_size ({}).\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2386\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (4) to match target batch_size (228)."
     ]
    }
   ],
   "source": [
    "# inspect each line!\n",
    "## load dataset, tokenize, and apply datacollator\n",
    "transformers_dataset = load_dataset(\"mdroth/transformers_issues_labels\")\n",
    "checkpoint = \"bert-base-cased\"\n",
    "transformers_tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "def transformers_tokenize_function(item):\n",
    "    return transformers_tokenizer(item[\"text\"], padding=True, truncation=True)\n",
    "transformers_tokenized_datasets = transformers_dataset.map(transformers_tokenize_function, batched=True)\n",
    "remove_columns = [\"url\", \"text\", \"num_labels\", \"labels\"]\n",
    "transformers_tokenized_datasets = transformers_tokenized_datasets.remove_columns(column_names=remove_columns)\n",
    "# https://discuss.huggingface.co/t/why-am-i-getting-keyerror-loss/6948\n",
    "transformers_tokenized_datasets = transformers_tokenized_datasets.rename_column(\"arr_labels\", \"labels\")\n",
    "transformers_data_collator = DataCollatorWithPadding(tokenizer=transformers_tokenizer)\n",
    "## training arguments\n",
    "training_args = TrainingArguments(\n",
    "    # https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\n",
    "    \"5_try_transformers_dataset\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4\n",
    ")\n",
    "## model\n",
    "num_labels = len(unique_labels)\n",
    "transformers_model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels)\n",
    "## compute_metrics\n",
    "# comput_metrics = ?\n",
    "## trainer\n",
    "trainer = Trainer(\n",
    "    transformers_model,\n",
    "    training_args,\n",
    "    train_dataset=transformers_tokenized_datasets[\"dev\"], # adapt\n",
    "    eval_dataset=transformers_tokenized_datasets[\"dev\"],  # adapt\n",
    "    data_collator=transformers_data_collator,\n",
    "    tokenizer=transformers_tokenizer\n",
    "    # comput_metrics = ?\n",
    ")\n",
    "## train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "85fc60cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=PreTrainedTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers_data_collator\n",
    "#--> 724                 raise ValueError(\n",
    "#    725                     \"Unable to create tensor, you should probably activate truncation and/or padding \"\n",
    "#    726                     \"with 'padding=True' 'truncation=True' to have batched tensors with the same length.\"\n",
    "#\n",
    "#ValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "efc18b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 5\n",
      "})\n",
      "[101, 157, 12150, 17516, 11359, 7249, 1104, 169, 10454, 168, 22559, 1116, 168, 1106, 168, 5101, 169, 1107, 2393, 7488, 22559, 17260, 119, 18732, 25290, 11680, 11365, 127, 155, 12420, 16647, 24805, 1708, 116, 122, 131, 121, 118, 122, 131, 121, 4046, 131, 121, 16358, 6533, 1183, 131, 121, 1762, 131, 121, 8964, 131, 121, 1257, 131, 121, 139, 15609, 3663, 8790, 117, 1103, 2393, 7488, 22559, 17260, 24935, 1103, 169, 10454, 168, 22559, 1116, 168, 1106, 168, 5101, 169, 3053, 131, 18630, 131, 120, 120, 176, 7088, 10354, 119, 3254, 120, 19558, 10931, 120, 11303, 1468, 120, 171, 2858, 1830, 120, 171, 1161, 1568, 1181, 11049, 2087, 18202, 19203, 2087, 1568, 1181, 1830, 1568, 1162, 1568, 1527, 1161, 18910, 1665, 13976, 1830, 1475, 2087, 1571, 1559, 2093, 1568, 1665, 1580, 1475, 1665, 15292, 1477, 120, 188, 19878, 120, 11303, 1468, 120, 3584, 120, 2393, 7488, 120, 22559, 2734, 168, 2393, 7488, 119, 185, 1183, 108, 149, 20581, 1477, 118, 149, 20581, 1495, 1799, 1103, 1260, 7488, 1161, 191, 1477, 1105, 1199, 1168, 22559, 17260, 1198, 13715, 1142, 1106, 1103, 5650, 9641, 22559, 17260, 131, 18630, 131, 120, 120, 176, 7088, 10354, 119, 3254, 120, 19558, 10931, 120, 11303, 1468, 120, 171, 2858, 1830, 120, 171, 1161, 1568, 1181, 11049, 2087, 18202, 19203, 2087, 1568, 1181, 1830, 1568, 1162, 1568, 1527, 1161, 18910, 1665, 13976, 1830, 1475, 2087, 1571, 1559, 2093, 1568, 1665, 1580, 1475, 1665, 15292, 1477, 120, 188, 19878, 120, 11303, 1468, 120, 3584, 120, 1260, 7488, 1161, 168, 191, 1477, 120, 22559, 2734, 168, 1260, 7488, 1161, 168, 191, 1477, 119, 185, 1183, 108, 149, 17175, 1545, 146, 20647, 1122, 1156, 1129, 1618, 1106, 1579, 13715, 1106, 1103, 5650, 9641, 22559, 17260, 119, 1327, 1202, 1128, 1341, 136, 108, 108, 12727, 131, 1789, 1167, 5136, 1303, 18630, 131, 120, 120, 176, 7088, 10354, 119, 3254, 120, 19558, 10931, 120, 11303, 1468, 120, 171, 2858, 1830, 120, 171, 1161, 1568, 1181, 11049, 2087, 18202, 19203, 2087, 1568, 1181, 1830, 1568, 1162, 1568, 1527, 1161, 18910, 1665, 13976, 1830, 1475, 2087, 1571, 1559, 2093, 1568, 1665, 1580, 1475, 1665, 15292, 1477, 120, 188, 19878, 120, 11303, 1468, 120, 3584, 120, 2927, 10681, 1584, 120, 22559, 2734, 168, 2927, 10681, 1584, 119, 185, 1183, 108, 149, 17600, 1475, 118, 149, 17600, 1477, 18630, 131, 120, 120, 176, 7088, 10354, 119, 3254, 120, 19558, 10931, 120, 11303, 1468, 120, 171, 2858, 1830, 120, 171, 1161, 1568, 1181, 11049, 2087, 18202, 19203, 2087, 1568, 1181, 1830, 1568, 1162, 1568, 1527, 1161, 18910, 1665, 13976, 1830, 1475, 2087, 1571, 1559, 2093, 1568, 1665, 1580, 1475, 1665, 15292, 1477, 120, 188, 19878, 120, 11303, 1468, 120, 3584, 120, 1338, 10615, 1204, 120, 22559, 2734, 168, 1338, 10615, 1204, 119, 185, 1183, 108, 149, 17600, 1475, 118, 149, 17600, 1477, 18630, 131, 120, 120, 176, 7088, 10354, 119, 3254, 120, 19558, 10931, 120, 11303, 1468, 120, 171, 2858, 1830, 120, 171, 1161, 1568, 1181, 11049, 2087, 18202, 19203, 2087, 1568, 1181, 1830, 1568, 1162, 1568, 1527, 1161, 18910, 1665, 13976, 1830, 1475, 2087, 1571, 1559, 2093, 102]\n",
      "\n",
      "[101, 157, 12150, 17516, 1339, 6470, 120, 1260, 18062, 118, 1231, 1116, 6097, 5964, 27023, 2515, 1155, 9468, 1179, 2860, 18732, 25290, 11680, 11365, 122, 155, 12420, 16647, 24805, 1708, 116, 122, 131, 121, 118, 122, 131, 121, 4046, 131, 121, 16358, 6533, 1183, 131, 121, 1762, 131, 121, 8964, 131, 121, 1257, 131, 121, 139, 15609, 3663, 108, 108, 108, 3910, 1130, 14467, 169, 169, 169, 5963, 158, 7925, 2227, 1358, 1406, 119, 5129, 118, 170, 1813, 1732, 22433, 153, 25669, 1766, 1732, 8812, 131, 122, 119, 1429, 119, 121, 113, 1121, 2674, 114, 25267, 131, 125, 119, 1407, 119, 121, 19928, 1732, 12959, 131, 121, 119, 1367, 119, 130, 113, 1121, 2674, 114, 6747, 131, 1339, 6470, 120, 1260, 18062, 118, 1231, 1116, 6097, 118, 1851, 169, 169, 169, 108, 108, 108, 2627, 1169, 1494, 136, 137, 27453, 5999, 2069, 8032, 2176, 108, 108, 108, 4219, 118, 164, 161, 166, 1109, 2078, 1859, 15690, 118, 164, 166, 1422, 1319, 5847, 15690, 108, 108, 108, 11513, 1116, 118, 164, 161, 166, 1760, 3184, 2726, 4579, 1107, 1103, 169, 5136, 169, 22073, 113, 1216, 1112, 144, 2162, 24846, 120, 156, 4880, 1358, 14569, 117, 119, 119, 119, 114, 118, 164, 166, 1422, 1319, 4579, 1137, 2233, 9388, 113, 1660, 4068, 2071, 114, 108, 108, 108, 20777, 13225, 18305, 146, 1868, 1103, 1378, 3463, 131, 169, 169, 169, 1121, 11303, 1468, 13757, 27524, 1197, 2271, 13448, 3313, 2036, 1775, 15017, 1766, 117, 27524, 1197, 2271, 1766, 2346, 24380, 2137, 16618, 5796, 1121, 153, 17656, 13757, 15065, 13757, 11458, 190, 17670, 134, 112, 8413, 131, 120, 120, 4351, 119, 1884, 2528, 27922, 9388, 119, 8916, 120, 191, 1348, 10973, 16770, 120, 1288, 7629, 7629, 24786, 1559, 1545, 1580, 119, 179, 1643, 1403, 112, 3077, 134, 15065, 119, 1501, 113, 11458, 119, 1243, 113, 190, 17670, 117, 5118, 134, 7817, 114, 119, 7158, 114, 2672, 168, 16143, 1766, 134, 27524, 1197, 2271, 13448, 3313, 2036, 1775, 15017, 1766, 119, 1121, 168, 3073, 4487, 9044, 113, 112, 1339, 6470, 120, 1260, 18062, 118, 1231, 1116, 6097, 118, 1851, 112, 114, 2235, 134, 27524, 1197, 2271, 1766, 2346, 24380, 2137, 16618, 5796, 119, 1121, 168, 3073, 4487, 9044, 113, 112, 1339, 6470, 120, 1260, 18062, 118, 1231, 1116, 6097, 118, 1851, 112, 114, 22743, 134, 2672, 168, 16143, 1766, 113, 4351, 134, 3077, 117, 1862, 168, 27023, 1116, 134, 107, 185, 1204, 107, 114, 5964, 1116, 134, 2235, 113, 115, 115, 22743, 114, 108, 2235, 17163, 1116, 4930, 1158, 8171, 1105, 7671, 18732, 15678, 3553, 9366, 6439, 134, 5964, 1116, 119, 9366, 6439, 171, 8757, 1279, 134, 5964, 1116, 119, 3073, 1181, 168, 8171, 169, 169, 169, 1121, 1142, 3674, 131, 18630, 131, 120, 120, 19558, 10931, 119, 1884, 120, 1339, 6470, 120, 1260, 18062, 118, 1231, 1116, 6097, 118, 1851, 1252, 1103, 5964, 27023, 1111, 1103, 4930, 1158, 8171, 1155, 2515, 9468, 1179, 4718, 131, 169, 169, 169, 27023, 113, 164, 164, 164, 9468, 1179, 117, 9468, 1179, 117, 9468, 1179, 117, 9468, 1179, 166, 117, 164, 9468, 1179, 117, 9468, 1179, 117, 9468, 1179, 102]\n",
      "\n",
      "[101, 157, 12150, 17516, 3725, 9216, 6741, 1859, 2452, 1106, 1260, 1643, 1874, 14520, 1104, 12983, 2107, 13040, 2924, 7088, 22074, 3048, 12393, 18732, 25290, 11680, 11365, 122, 155, 12420, 16647, 24805, 1708, 116, 122, 131, 121, 118, 122, 131, 121, 4046, 131, 121, 16358, 6533, 1183, 131, 121, 1762, 131, 121, 8964, 131, 121, 1257, 131, 121, 139, 15609, 3663, 112, 1109, 1705, 169, 12983, 2107, 13040, 1233, 2924, 7088, 22074, 3048, 12393, 169, 1110, 1260, 1643, 1874, 11603, 1105, 1209, 1129, 2856, 1107, 170, 2174, 1683, 119, 4203, 1329, 169, 12983, 2107, 13040, 1233, 2271, 1766, 1658, 25134, 1348, 22074, 169, 1111, 11019, 25034, 1846, 3584, 117, 169, 12983, 2107, 13040, 1233, 2271, 1766, 2107, 25611, 1174, 22074, 169, 1111, 19970, 1846, 3584, 1105, 169, 12983, 2107, 13040, 1233, 2271, 1766, 1708, 1162, 4426, 1477, 1708, 1162, 4426, 22074, 169, 1111, 4035, 13775, 1197, 118, 1260, 13775, 1197, 3584, 119, 112, 146, 1274, 1204, 1221, 1293, 1106, 1849, 1103, 112, 1731, 1106, 1329, 1142, 2235, 2626, 1121, 1103, 100, 120, 11303, 1468, 3340, 131, 112, 1226, 1290, 1122, 1110, 1136, 1226, 1104, 1103, 2235, 118, 2526, 108, 1327, 1674, 1142, 11629, 1202, 136, 17355, 1775, 1103, 2174, 1260, 1643, 1874, 14520, 1104, 169, 12983, 2107, 13040, 1233, 2924, 7088, 22074, 3048, 12393, 169, 133, 106, 118, 118, 16752, 25891, 106, 1192, 112, 1396, 1189, 1122, 1142, 1677, 106, 1192, 112, 1231, 1136, 2385, 1694, 1870, 1463, 119, 2857, 4564, 117, 1240, 11629, 1110, 1280, 1106, 2845, 1107, 1103, 1836, 3697, 1114, 1103, 1641, 1128, 1383, 117, 1177, 1294, 1612, 1122, 112, 188, 170, 1632, 1641, 1115, 3106, 11363, 1103, 6102, 1104, 1240, 14918, 6436, 119, 1599, 117, 4268, 4971, 1142, 1114, 170, 6136, 1104, 1103, 1849, 1105, 1134, 2486, 1110, 4275, 113, 1191, 13036, 114, 119, 4203, 1145, 1511, 7503, 15710, 1105, 5618, 119, 5619, 1251, 12864, 15672, 113, 1191, 1251, 114, 1115, 1132, 2320, 1111, 1142, 1849, 119, 2857, 1128, 112, 1231, 1694, 117, 1800, 1209, 3189, 1240, 11629, 3992, 113, 1267, 1103, 2237, 107, 2627, 1169, 3189, 136, 107, 2071, 1106, 9235, 1199, 3209, 19475, 114, 119, 1220, 1336, 5996, 2607, 1106, 1294, 1103, 3463, 1256, 1618, 119, 1409, 1185, 1141, 7815, 1240, 11629, 1170, 170, 1989, 1144, 2085, 117, 1274, 112, 189, 17467, 1106, 2112, 170, 1207, 7368, 137, 118, 20368, 1103, 1269, 4983, 118, 118, 118, 2121, 1136, 25583, 1243, 1575, 119, 118, 118, 135, 108, 108, 2577, 12295, 1916, 118, 164, 193, 166, 1188, 11629, 8239, 1279, 170, 189, 1183, 5674, 1137, 4607, 1116, 1103, 1202, 6063, 113, 1128, 1169, 12563, 14788, 1103, 1168, 15008, 1191, 1115, 112, 188, 1103, 1692, 114, 119, 118, 164, 193, 166, 2966, 1128, 2373, 1103, 164, 12708, 6388, 2568, 166, 113, 18630, 131, 120, 120, 176, 7088, 10354, 119, 3254, 120, 19558, 10931, 120, 11303, 1468, 120, 171, 2858, 1830, 120, 3283, 120, 18732, 15681, 20595, 2064, 16830, 15740, 119, 182, 1181, 108, 1838, 118, 7773, 118, 3373, 118, 11458, 114, 117, 153, 11781, 11336, 16437, 2237, 136, 118, 164, 166, 3982, 1142, 6352, 120, 4092, 2258, 170, 102]\n",
      "\n",
      "[101, 157, 12150, 17516, 169, 3177, 7488, 1161, 1942, 27443, 17260, 169, 1579, 27043, 22559, 2076, 10999, 121, 18732, 25290, 11680, 11365, 124, 155, 12420, 16647, 24805, 1708, 116, 122, 131, 121, 118, 122, 131, 121, 4046, 131, 121, 16358, 6533, 1183, 131, 121, 1762, 131, 121, 8964, 131, 121, 1257, 131, 121, 139, 15609, 3663, 108, 108, 9247, 23992, 118, 169, 11303, 1468, 169, 1683, 131, 125, 119, 1479, 119, 123, 118, 17742, 131, 11735, 118, 126, 119, 1405, 119, 1492, 118, 4991, 16337, 17668, 118, 13179, 118, 193, 22392, 168, 3324, 118, 1114, 118, 176, 2646, 1830, 1665, 1477, 119, 3236, 118, 23334, 1683, 131, 124, 119, 130, 119, 128, 118, 153, 1183, 1942, 1766, 1732, 1683, 113, 15175, 2591, 136, 114, 131, 122, 119, 130, 119, 121, 116, 16408, 14541, 1475, 113, 7817, 114, 118, 5157, 21484, 12712, 1683, 113, 15175, 2591, 136, 114, 131, 1136, 4631, 113, 151, 1592, 114, 118, 143, 22731, 1683, 113, 18701, 136, 120, 15175, 2591, 136, 120, 157, 2101, 2591, 136, 114, 131, 1136, 4631, 113, 151, 1592, 114, 118, 13612, 1683, 131, 1136, 4631, 118, 13612, 2162, 13292, 1683, 131, 1136, 4631, 118, 7993, 15175, 2591, 1107, 5444, 136, 131, 1185, 118, 7993, 4901, 1137, 5504, 1383, 118, 1146, 1107, 5444, 136, 131, 1185, 108, 108, 108, 2627, 1169, 1494, 137, 149, 6834, 5709, 1874, 4538, 4847, 108, 108, 4219, 6747, 146, 1821, 1606, 113, 15035, 117, 161, 2162, 25264, 119, 119, 119, 114, 131, 169, 17599, 7301, 4964, 120, 1260, 7488, 1161, 118, 1415, 169, 1109, 2463, 20251, 1165, 1606, 131, 115, 164, 166, 1103, 2078, 1859, 15690, 131, 113, 1660, 4068, 2071, 114, 115, 164, 193, 166, 1139, 1319, 5847, 15690, 131, 113, 1660, 4068, 2071, 114, 1109, 8249, 146, 1821, 1684, 1113, 1110, 131, 115, 164, 166, 1126, 2078, 144, 2162, 24846, 120, 156, 4880, 2591, 1161, 2137, 4579, 131, 113, 1660, 1103, 1271, 114, 115, 164, 193, 166, 1139, 1319, 4579, 1137, 2233, 9388, 131, 113, 1660, 4068, 2071, 114, 108, 108, 1706, 23577, 27913, 1106, 23577, 1103, 4658, 131, 6728, 1142, 3463, 131, 169, 169, 169, 185, 25669, 8613, 1121, 11303, 1468, 13757, 12983, 1942, 27443, 17260, 22559, 17260, 134, 12983, 1942, 27443, 17260, 119, 1121, 168, 3073, 4487, 9044, 113, 107, 17599, 7301, 4964, 120, 1260, 7488, 1161, 118, 1415, 107, 114, 5911, 113, 22559, 17260, 113, 107, 8667, 107, 117, 107, 1291, 107, 114, 114, 169, 169, 169, 1135, 5964, 1116, 131, 169, 169, 169, 196, 112, 7758, 168, 25021, 1116, 112, 131, 164, 122, 117, 1955, 25892, 1527, 117, 123, 117, 11523, 1604, 1604, 117, 123, 166, 117, 112, 22559, 168, 2076, 168, 25021, 1116, 112, 131, 164, 121, 117, 121, 117, 121, 117, 121, 117, 121, 166, 117, 112, 2209, 168, 7739, 112, 131, 164, 122, 117, 122, 117, 122, 117, 122, 117, 122, 166, 198, 169, 169, 169, 2431, 1463, 146, 1508, 1107, 1160, 10028, 117, 1155, 169, 22559, 168, 2076, 168, 25021, 1116, 169, 1132, 121, 119, 108, 108, 16409, 26426, 1174, 4658, 1109, 22559, 1116, 1121, 1103, 1248, 4954, 102]\n",
      "\n",
      "[101, 157, 12150, 17516, 3725, 9216, 155, 12420, 20002, 2036, 119, 182, 1181, 18732, 25290, 11680, 11365, 122, 155, 12420, 16647, 24805, 1708, 116, 122, 131, 121, 118, 122, 131, 121, 4046, 131, 121, 16358, 6533, 1183, 131, 121, 1762, 131, 121, 8964, 131, 121, 1257, 131, 121, 139, 15609, 3663, 8790, 117, 1198, 13808, 1103, 1859, 3463, 117, 5194, 123, 6743, 1105, 4275, 1199, 189, 1183, 5674, 1116, 108, 1327, 1674, 1142, 11629, 1202, 136, 133, 106, 118, 118, 16752, 25891, 106, 1192, 112, 1396, 1189, 1122, 1142, 1677, 106, 1192, 112, 1231, 1136, 2385, 1694, 1870, 1463, 119, 2857, 4564, 117, 1240, 11629, 1110, 1280, 1106, 2845, 1107, 1103, 1836, 3697, 1114, 1103, 1641, 1128, 1383, 117, 1177, 1294, 1612, 1122, 112, 188, 170, 1632, 1641, 1115, 3106, 11363, 1103, 6102, 1104, 1240, 14918, 6436, 119, 1599, 117, 4268, 4971, 1142, 1114, 170, 6136, 1104, 1103, 1849, 1105, 1134, 2486, 1110, 4275, 113, 1191, 13036, 114, 119, 4203, 1145, 1511, 7503, 15710, 1105, 5618, 119, 5619, 1251, 12864, 15672, 113, 1191, 1251, 114, 1115, 1132, 2320, 1111, 1142, 1849, 119, 2857, 1128, 112, 1231, 1694, 117, 1800, 1209, 3189, 1240, 11629, 3992, 113, 1267, 1103, 2237, 107, 2627, 1169, 3189, 136, 107, 2071, 1106, 9235, 1199, 3209, 19475, 114, 119, 1220, 1336, 5996, 2607, 1106, 1294, 1103, 3463, 1256, 1618, 119, 1409, 1185, 1141, 7815, 1240, 11629, 1170, 170, 1989, 1144, 2085, 117, 1274, 112, 189, 17467, 1106, 2112, 170, 1207, 7368, 137, 118, 20368, 1103, 1269, 4983, 118, 118, 118, 2121, 1136, 25583, 1243, 1575, 119, 118, 118, 135, 133, 106, 118, 118, 11336, 3702, 2707, 1191, 1136, 13036, 118, 118, 135, 17355, 21210, 108, 113, 2486, 114, 108, 108, 2577, 12295, 1916, 118, 164, 166, 1188, 11629, 8239, 1279, 170, 189, 1183, 5674, 1137, 4607, 1116, 1103, 1202, 6063, 113, 1128, 1169, 12563, 14788, 1103, 1168, 15008, 1191, 1115, 112, 188, 1103, 1692, 114, 119, 118, 164, 166, 2966, 1128, 2373, 1103, 164, 12708, 6388, 2568, 166, 113, 18630, 131, 120, 120, 176, 7088, 10354, 119, 3254, 120, 19558, 10931, 120, 11303, 1468, 120, 171, 2858, 1830, 120, 3283, 120, 18732, 15681, 20595, 2064, 16830, 15740, 119, 182, 1181, 108, 1838, 118, 7773, 118, 3373, 118, 11458, 114, 117, 153, 11781, 11336, 16437, 2237, 136, 118, 164, 166, 3982, 1142, 6352, 120, 4092, 2258, 170, 144, 7088, 10354, 2486, 1137, 1103, 164, 13912, 166, 113, 18630, 131, 120, 120, 6265, 119, 19558, 10931, 119, 1884, 120, 114, 136, 4203, 5194, 170, 5088, 1106, 1103, 1122, 1191, 1115, 112, 188, 1103, 1692, 119, 118, 164, 166, 2966, 1128, 1294, 1612, 1106, 11984, 1103, 14371, 1114, 1240, 2607, 136, 3446, 1132, 1103, 164, 14371, 13112, 166, 113, 18630, 131, 120, 120, 176, 7088, 10354, 119, 3254, 120, 19558, 10931, 120, 11303, 1468, 120, 2780, 120, 3283, 120, 1202, 6063, 114, 117, 1105, 164, 1303, 1132, 10538, 1113, 3536, 1916, 1202, 6063, 28108, 1116, 166, 113, 18630, 131, 120, 120, 176, 7088, 10354, 119, 3254, 120, 19558, 10931, 120, 11303, 1468, 120, 2780, 120, 3283, 120, 1202, 6063, 108, 2269, 102]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remove_cols = [\"url\", \"num_labels\", \"labels\"]\n",
    "transformers_tokenized_datasets_rem = transformers_tokenized_datasets.remove_columns(remove_cols)\n",
    "transformers_tokenized_datasets_rem = transformers_tokenized_datasets_rem.rename_column(\"arr_labels\", \"labels\")\n",
    "dataset_0 = transformers_tokenized_datasets_rem[\"dev\"] # \"dev\", \"valid\", \"test\", \"train\"\n",
    "print(dataset_0)\n",
    "for i in range(len(dataset_0)):\n",
    "    i_len = len(dataset_0[\"input_ids\"][i])\n",
    "    if i_len<512:\n",
    "        print(i)\n",
    "    print(dataset_0[\"input_ids\"][i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "43467830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fe0a85dfb20>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(\n",
    "    transformers_tokenized_datasets_rem[\"dev\"],\n",
    "    shuffle=True,\n",
    "    batch_size=4,\n",
    "    collate_fn=transformers_data_collator\n",
    ")\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1d15f72b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-d57e656e97c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         batch = self.tokenizer.pad(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2860\u001b[0m                 \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2862\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m     def create_token_type_ids_from_sequences(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    722\u001b[0m                         \u001b[0;34m\"Please see if a fast version of this tokenizer is available to have this feature available.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     )\n\u001b[0;32m--> 724\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    725\u001b[0m                     \u001b[0;34m\"Unable to create tensor, you should probably activate truncation and/or padding \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0;34m\"with 'padding=True' 'truncation=True' to have batched tensors with the same length.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cad769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583956d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataloader = DataLoader(tokenized_datasets[\"dev\"], shuffle=True, batch_size=8, collate_fn=data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc7ee3cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataCollatorWithPadding' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-c49a36bbaaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#transformers_data_collator = DataCollatorWithPadding(tokenizer=transformers_tokenizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtransformers_data_collator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransformers_data_collator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataCollatorWithPadding' object is not iterable"
     ]
    }
   ],
   "source": [
    "#transformers_data_collator = DataCollatorWithPadding(tokenizer=transformers_tokenizer)\n",
    "transformers_data_collator\n",
    "for batch in transformers_data_collator:\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "059f77e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['url', 'text', 'num_labels', 'arr_labels', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 220\n",
      "})\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n",
      "512 512 512\n"
     ]
    }
   ],
   "source": [
    "split = transformers_tokenized_datasets[\"valid\"]\n",
    "print(split)\n",
    "for i in range(split.num_rows):\n",
    "    print(len(split[\"input_ids\"][i]), len(split[\"token_type_ids\"][i]), len(split[\"attention_mask\"][i]))\n",
    "    #print(split[\"input_ids\"][i][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0ea5db88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'LABEL_0',\n",
       " 1: 'LABEL_1',\n",
       " 2: 'LABEL_2',\n",
       " 3: 'LABEL_3',\n",
       " 4: 'LABEL_4',\n",
       " 5: 'LABEL_5',\n",
       " 6: 'LABEL_6',\n",
       " 7: 'LABEL_7',\n",
       " 8: 'LABEL_8',\n",
       " 9: 'LABEL_9',\n",
       " 10: 'LABEL_10',\n",
       " 11: 'LABEL_11',\n",
       " 12: 'LABEL_12',\n",
       " 13: 'LABEL_13',\n",
       " 14: 'LABEL_14',\n",
       " 15: 'LABEL_15',\n",
       " 16: 'LABEL_16',\n",
       " 17: 'LABEL_17',\n",
       " 18: 'LABEL_18',\n",
       " 19: 'LABEL_19',\n",
       " 20: 'LABEL_20',\n",
       " 21: 'LABEL_21',\n",
       " 22: 'LABEL_22',\n",
       " 23: 'LABEL_23',\n",
       " 24: 'LABEL_24',\n",
       " 25: 'LABEL_25',\n",
       " 26: 'LABEL_26',\n",
       " 27: 'LABEL_27',\n",
       " 28: 'LABEL_28',\n",
       " 29: 'LABEL_29',\n",
       " 30: 'LABEL_30',\n",
       " 31: 'LABEL_31',\n",
       " 32: 'LABEL_32',\n",
       " 33: 'LABEL_33',\n",
       " 34: 'LABEL_34',\n",
       " 35: 'LABEL_35',\n",
       " 36: 'LABEL_36',\n",
       " 37: 'LABEL_37',\n",
       " 38: 'LABEL_38',\n",
       " 39: 'LABEL_39',\n",
       " 40: 'LABEL_40',\n",
       " 41: 'LABEL_41',\n",
       " 42: 'LABEL_42',\n",
       " 43: 'LABEL_43',\n",
       " 44: 'LABEL_44',\n",
       " 45: 'LABEL_45',\n",
       " 46: 'LABEL_46',\n",
       " 47: 'LABEL_47',\n",
       " 48: 'LABEL_48',\n",
       " 49: 'LABEL_49',\n",
       " 50: 'LABEL_50',\n",
       " 51: 'LABEL_51',\n",
       " 52: 'LABEL_52',\n",
       " 53: 'LABEL_53',\n",
       " 54: 'LABEL_54',\n",
       " 55: 'LABEL_55',\n",
       " 56: 'LABEL_56'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a3bd9cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb95c958c5b944ec881854eea273ad5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=57, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(unique_labels)\n",
    "# instantiate model\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=num_labels)\n",
    "print(model)\n",
    "# produce model outputs (https://huggingface.co/docs/transformers/main_classes/output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adc1eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.17.0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/main_classes/output#transformers.modeling_outputs.MultipleChoiceModelOutput\n",
    "# https://huggingface.co/docs/transformers/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "# https://huggingface.co/docs/transformers/main_classes/configuration\n",
    "# https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
    "# https://huggingface.co/docs/transformers/tasks/multiple_choice\n",
    "# https://huggingface.co/docs/transformers/training\n",
    "\n",
    "# look up classification in chapter 3\n",
    "# https://huggingface.co/transformers/v4.1.1/notebooks.html\n",
    "# https://huggingface.co/docs/transformers/main_classes/output (=> logits)\n",
    "# https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb#scrollTo=bRDimbGwQFrB\n",
    "# https://discuss.huggingface.co/t/fine-tune-for-multiclass-or-multilabel-multiclass/4035/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ef923",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validTest = transformers_issues_text_dataset.train_test_split(shuffle=True, seed=42, test_size=0.36)\n",
    "valid_test = train_validTest[\"test\"].train_test_split(shuffle=True, seed=42, test_size=5/9)\n",
    "\n",
    "transformers_issues_text_dataset = DatasetDict({\n",
    "    \"train\": train_validTest[\"train\"],\n",
    "    \"valid\": valid_test[\"train\"],\n",
    "    \"test\": valid_test[\"test\"]\n",
    "})\n",
    "print(transformers_issues_text_dataset)\n",
    "transformers_issues_text_dataset.push_to_hub(repo_id=\"transformers_issues_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c1a121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-141858a465b2fe0e\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/default-141858a465b2fe0e/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-141858a465b2fe0e/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-1ad8b64b4243b1d6.arrow\n",
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-141858a465b2fe0e/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-c55a828df18dcd38.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['url', 'labels', 'text'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "\n",
      "text:\n",
      "\n",
      "TITLE\n",
      "Fixed incorrect error message on missing weight file.\n",
      "\n",
      "COMMENTS\n",
      "1\n",
      "\n",
      "REACTIONS\n",
      "+1: 0\n",
      "-1: 0\n",
      "laugh: 0\n",
      "hooray: 0\n",
      "heart: 0\n",
      "rocket: 0\n",
      "eyes: 0\n",
      "\n",
      "BODY\n",
      "# What does this PR do?\r\n",
      "I just started using Hugging Face Transformers for the first time, and encountered this error.\r\n",
      "\r\n",
      "    OSError: Error no file named pytorch_model.bin found in directory (...) but there is a file for Flax weights. Use `from_flax=True` to load this model from those weights.\r\n",
      "\r\n",
      "Indeed, I forgot to download `pytorch_model.bin`, but the model I tried to use was not using Flax, so I dug a little bit to see which file was the library looking for.\r\n",
      "\r\n",
      "For me it seems that there was a simple mistake...\r\n",
      "\r\n",
      "## Before submitting\r\n",
      "- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n",
      "- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests), Pull Request section?\r\n",
      "- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n",
      "      to it if that's the case.\r\n",
      "- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n",
      "      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n",
      "      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n",
      "- [ ] Did you write any new necessary tests?\r\n",
      "\r\n",
      "\r\n",
      "## Who can review?\r\n",
      "\r\n",
      "Anyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\n",
      "members/contributors who may be interested in your PR.\r\n",
      "\r\n",
      "<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n",
      "\r\n",
      " If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n",
      " Please tag fewer than 3 people.\r\n",
      "\r\n",
      "Models:\r\n",
      "\r\n",
      "- albert, bert, xlm: @LysandreJik\r\n",
      "- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj\r\n",
      "- longformer, reformer, transfoxl, xlnet: @patrickvonplaten\r\n",
      "- fsmt: @stas00\r\n",
      "- funnel: @sgugger\r\n",
      "- gpt2: @patrickvonplaten, @LysandreJik\r\n",
      "- rag: @patrickvonplaten, @lhoestq\r\n",
      "- tensorflow: @LysandreJik\r\n",
      "\r\n",
      "Library:\r\n",
      "\r\n",
      "- benchmarks: @patrickvonplaten\r\n",
      "- deepspeed: @stas00\r\n",
      "- ray/raytune: @richardliaw, @amogkam\r\n",
      "- text generation: @patrickvonplaten\r\n",
      "- tokenizers: @n1t0, @LysandreJik\r\n",
      "- trainer: @sgugger\r\n",
      "- pipelines: @LysandreJik\r\n",
      "\r\n",
      "Documentation: @sgugger\r\n",
      "\r\n",
      "HF projects:\r\n",
      "\r\n",
      "- datasets: [different repo](https://github.com/huggingface/datasets)\r\n",
      "- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n",
      "\r\n",
      "Examples:\r\n",
      "\r\n",
      "- maintained examples (not research project or legacy): @sgugger, @patil-suraj\r\n",
      "- research_projects/bert-loses-patience: @JetRunner\r\n",
      "- research_projects/distillation: @VictorSanh\r\n",
      "\r\n",
      " -->\r\n",
      "\n",
      "\n",
      "labels:\n",
      "[]\n",
      "\n",
      "url:\n",
      "https://api.github.com/repos/huggingface/transformers/issues/17216\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "\n",
    "#####################\n",
    "#                   #\n",
    "#  copy and polish  #\n",
    "#                   #\n",
    "#####################\n",
    "\n",
    "## load the file \"transformers-issues.jsonl\" that has been created by using 'fetch_issues(repo=\"transformers\")' ...\n",
    "## ... instead of 'fetch_issues()' just below the definition of the 'fetch_issues()' function further above\n",
    "transformers_issues_dataset = load_dataset(\"json\", data_files=\"data/transformers-issues.jsonl\", split=\"train\")\n",
    "## add \"text\" column\n",
    "transformers_issues_text_dataset = transformers_issues_dataset.rename_column(\n",
    "    original_column_name=\"url\", new_column_name=\"text\"\n",
    ")\n",
    "## combine the columns \"title\", \"comments\", \"reactions\", and \"body\" into a single string and store that string ...\n",
    "## ... in the new \"text\" column\n",
    "feature_keys = [\"title\", \"comments\", \"reactions\", \"body\"]\n",
    "reaction_keys = [\"+1\", \"-1\", \"laugh\", \"hooray\", \"heart\", \"rocket\", \"eyes\"]\n",
    "def make_text(item):\n",
    "    text = \"\"\n",
    "    for fk_i in feature_keys:\n",
    "        if fk_i==\"reactions\":\n",
    "            text += f\"\\n\\n{fk_i.upper()}\"\n",
    "            reactions = item[fk_i]\n",
    "            reactions_json = json.loads(json.dumps(reactions, indent = 4))\n",
    "            for rk_i in reaction_keys:\n",
    "                rk_iCount = reactions_json[rk_i]\n",
    "                text += f\"\\n{rk_i}: {rk_iCount}\"\n",
    "        else:\n",
    "            text += f\"\\n\\n{fk_i.upper()}\\n{item[fk_i]}\"\n",
    "    item[\"text\"] = text\n",
    "    return item\n",
    "transformers_issues_text_dataset = transformers_issues_dataset.map(make_text)\n",
    "########################\n",
    "## define and apply make_labels => for each instance \"labels\" holds a list of label names ...\n",
    "## ... (e.g., [\"benchmark\", \"performance\"]) for the labels of the instance with index 13\n",
    "def make_labels(item):\n",
    "    labels = item[\"labels\"]\n",
    "    label_list = []\n",
    "    #\n",
    "    for label in labels:\n",
    "        label_json = json.loads(json.dumps(label, indent = 4))\n",
    "        label_name = label_json[\"name\"]\n",
    "        label_list.append(label_name)\n",
    "    #\n",
    "    item[\"labels\"] = label_list\n",
    "    return item\n",
    "transformers_issues_text_dataset = transformers_issues_text_dataset.map(make_labels)\n",
    "########################\n",
    "\n",
    "# optionally filter for instances with labels!=[]\n",
    "# make splits and build DatasetDict\n",
    "\n",
    "## remove all columns but \"labels\", \"text\", and \"url\"\n",
    "keep_keys = [\"text\", \"labels\", \"url\"]\n",
    "remove_keys = [key for key in list(transformers_issues_text_dataset.features.keys()) if key not in keep_keys]\n",
    "transformers_issues_text_dataset = transformers_issues_text_dataset.remove_columns(remove_keys)\n",
    "print(transformers_issues_text_dataset)\n",
    "idx = 1 # 13\n",
    "print(f'\\ntext:{transformers_issues_text_dataset[\"text\"][idx]}')\n",
    "print(f'\\nlabels:\\n{transformers_issues_text_dataset[\"labels\"][idx]}')\n",
    "print(f'\\nurl:\\n{transformers_issues_text_dataset[\"url\"][idx]}')\n",
    "########\n",
    "# [1] https://discuss.huggingface.co/t/how-to-add-a-new-column-to-a-dataset/6453\n",
    "# [2] https://huggingface.co/docs/datasets/v2.0.0/en/package_reference/main_classes\n",
    "# [3] https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.add_column\n",
    "# [4] https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.remove_columns\n",
    "# [5] https://huggingface.co/docs/datasets/v2.2.1/en/package_reference/main_classes#datasets.Dataset.map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba902505",
   "metadata": {},
   "source": [
    "**Restart the kernel in preparation for the next section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86952862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b49da0",
   "metadata": {},
   "source": [
    "## [Semantic search with FAISS](https://huggingface.co/course/chapter5/6?fw=pt)\n",
    "\n",
    "In [section 5](https://huggingface.co/course/chapter5/5), we created a dataset of GitHub issues and comments from the 🤗 Datasets repository. In this section we'll use this information to build a search engine that can help us find answers to our most pressing questions about the library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3f0e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthias/opt/anaconda3/envs/hf/lib/python3.8/site-packages/IPython/core/display.py:717: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/OATCgQtNX2o\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/OATCgQtNX2o\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3af87",
   "metadata": {},
   "source": [
    "### Using embeddings for semantic search\n",
    "As we saw in [Chapter 1](https://huggingface.co/course/chapter1), Transformer-based language models represent each token in a span of text as an *embedding vector*. It turns out that one can \"pool\" the individual embeddings to create a vector representation for whole sentences, paragraphs, or (in some cases) documents. These embeddings can then be used to find similar documents in the corpus by computing the dot-product similarity (or some other similarity metric) between each embedding and returning the documents with the greatest overlap.\n",
    "\n",
    "In this section we'll use embeddings to develop a semantic search engine. These search engines offer several advantages over conventional approaches that are based on matching keywords in a query with the documents.\n",
    "<img style=\"float=center;\" width=\"900\" src=\"images/semantic-search.svg\">\n",
    "### Loading and preparing the dataset\n",
    "The first thing we need to do is download our dataset of GitHub issues, so let's use the 🤗 Hub library to resolve the URL where our file is stored on the Hugging Face Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7acf9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_url\n",
    "data_files = hf_hub_url(\n",
    "    repo_id=\"lewtun/github-issues\",\n",
    "    filename=\"datasets-issues-with-comments.jsonl\",\n",
    "    repo_type=\"dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54712f0e",
   "metadata": {},
   "source": [
    "With the URL stored in data_files, we can then load the remote dataset using the method introduced in [section 2](https://huggingface.co/course/chapter5/2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8935994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6a579f365d89f2f1\n",
      "Reusing dataset json (/Users/matthias/.cache/huggingface/datasets/json/default-6a579f365d89f2f1/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
       "    num_rows: 3019\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "issues_dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217db437",
   "metadata": {},
   "source": [
    "Here we've specified the default train split in `load_dataset()`, so it returns a `Dataset` instead of a `DatasetDict`. The first order of business is to filter out the pull requests, as these tend to be rarely used for answering user queries and will introduce noise in our search engine. As should be familiar by now, we can use the `Dataset.filter()` function to exclude these rows in our dataset. While we're at it, let's also filter out rows with no comments, since these provide no answers to user queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "461b1ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/matthias/.cache/huggingface/datasets/json/default-6a579f365d89f2f1/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-7adeb9322eeeff4e.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
       "    num_rows: 808\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_dataset = issues_dataset.filter(lambda x: (x[\"is_pull_request\"]==False and len(x[\"comments\"]) > 0))\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deee34d",
   "metadata": {},
   "source": [
    "We can see that there are a lot of columns in our dataset, most of which we don't need to build our search engine. From a search perspective, the most informative columns are `title`, `body`, and `comments`, while `html_url` provides us with a link back to the source issue. Let's use the `Dataset.remove_columns()` function to drop the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b664cd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 808\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = issues_dataset.column_names\n",
    "columns_to_keep = [\"title\", \"body\", \"html_url\", \"comments\"]\n",
    "columns_to_remove = set(columns_to_keep).symmetric_difference(columns)\n",
    "issues_dataset = issues_dataset.remove_columns(columns_to_remove)\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052e3cf",
   "metadata": {},
   "source": [
    "To create our embeddings we'll augment each comment with the issue's title and body, since these fields often include useful contextual information. Because our comments column is currently a list of comments for each issue, we need to \"explode\" the column so that each row consists of an (`html_url`, `title`, `body`, `comment`) tuple. In Pandas, we can do this with the [`DataFrame.explode()` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.explode.html), which creates a new row for each element in a list-like column, while replicating all the other column values. To see this in action, let's first switch to the Pandas `DataFrame` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cdd3a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>[Cool, I think we can do both :), @lhoestq now...</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>[Hi ! I guess the caching mechanism should hav...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>OSCAR unshuffled_original_ko: NonMatchingSplit...</td>\n",
       "      <td>[I tried `unshuffled_original_da` and it is al...</td>\n",
       "      <td>## Describe the bug\\r\\n\\r\\nCannot download OSC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>load_dataset using default cache on Windows ca...</td>\n",
       "      <td>[Hi @daqieq, thanks for reporting.\\r\\n\\r\\nUnfo...</td>\n",
       "      <td>## Describe the bug\\r\\nStandard process to dow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>to_tf_dataset keeps a reference to the open da...</td>\n",
       "      <td>[I did some investigation and, as it seems, th...</td>\n",
       "      <td>To reproduce:\\r\\n```python\\r\\nimport datasets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/6</td>\n",
       "      <td>Error when citation is not given in the Datase...</td>\n",
       "      <td>[Yes looks good to me.\\r\\nNote that we may ref...</td>\n",
       "      <td>The following error is raised when the `citati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/5</td>\n",
       "      <td>ValueError when a split is empty</td>\n",
       "      <td>[To fix this I propose to modify only the file...</td>\n",
       "      <td>When a split is empty either TEST, VALIDATION ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/4</td>\n",
       "      <td>[Feature] Keep the list of labels of a dataset...</td>\n",
       "      <td>[Yes! I see mostly two options for this:\\r\\n- ...</td>\n",
       "      <td>It would be useful to keep the list of the lab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/3</td>\n",
       "      <td>[Feature] More dataset outputs</td>\n",
       "      <td>[Yes!\\r\\n- pandas will be a one-liner in `arro...</td>\n",
       "      <td>Add the following dataset outputs:\\r\\n\\r\\n- Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2</td>\n",
       "      <td>Issue to read a local dataset</td>\n",
       "      <td>[My first bug report ❤️\\r\\nLooking into this r...</td>\n",
       "      <td>Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              html_url  \\\n",
       "0    https://github.com/huggingface/datasets/issues...   \n",
       "1    https://github.com/huggingface/datasets/issues...   \n",
       "2    https://github.com/huggingface/datasets/issues...   \n",
       "3    https://github.com/huggingface/datasets/issues...   \n",
       "4    https://github.com/huggingface/datasets/issues...   \n",
       "..                                                 ...   \n",
       "803   https://github.com/huggingface/datasets/issues/6   \n",
       "804   https://github.com/huggingface/datasets/issues/5   \n",
       "805   https://github.com/huggingface/datasets/issues/4   \n",
       "806   https://github.com/huggingface/datasets/issues/3   \n",
       "807   https://github.com/huggingface/datasets/issues/2   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                Protect master branch   \n",
       "1    Backwards compatibility broken for cached data...   \n",
       "2    OSCAR unshuffled_original_ko: NonMatchingSplit...   \n",
       "3    load_dataset using default cache on Windows ca...   \n",
       "4    to_tf_dataset keeps a reference to the open da...   \n",
       "..                                                 ...   \n",
       "803  Error when citation is not given in the Datase...   \n",
       "804                   ValueError when a split is empty   \n",
       "805  [Feature] Keep the list of labels of a dataset...   \n",
       "806                     [Feature] More dataset outputs   \n",
       "807                      Issue to read a local dataset   \n",
       "\n",
       "                                              comments  \\\n",
       "0    [Cool, I think we can do both :), @lhoestq now...   \n",
       "1    [Hi ! I guess the caching mechanism should hav...   \n",
       "2    [I tried `unshuffled_original_da` and it is al...   \n",
       "3    [Hi @daqieq, thanks for reporting.\\r\\n\\r\\nUnfo...   \n",
       "4    [I did some investigation and, as it seems, th...   \n",
       "..                                                 ...   \n",
       "803  [Yes looks good to me.\\r\\nNote that we may ref...   \n",
       "804  [To fix this I propose to modify only the file...   \n",
       "805  [Yes! I see mostly two options for this:\\r\\n- ...   \n",
       "806  [Yes!\\r\\n- pandas will be a one-liner in `arro...   \n",
       "807  [My first bug report ❤️\\r\\nLooking into this r...   \n",
       "\n",
       "                                                  body  \n",
       "0    After accidental merge commit (91c55355b634d0d...  \n",
       "1    ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "2    ## Describe the bug\\r\\n\\r\\nCannot download OSC...  \n",
       "3    ## Describe the bug\\r\\nStandard process to dow...  \n",
       "4    To reproduce:\\r\\n```python\\r\\nimport datasets ...  \n",
       "..                                                 ...  \n",
       "803  The following error is raised when the `citati...  \n",
       "804  When a split is empty either TEST, VALIDATION ...  \n",
       "805  It would be useful to keep the list of the lab...  \n",
       "806  Add the following dataset outputs:\\r\\n\\r\\n- Sp...  \n",
       "807  Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...  \n",
       "\n",
       "[808 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_dataset.set_format(\"pandas\")\n",
    "df = issues_dataset[:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f04dd",
   "metadata": {},
   "source": [
    "If we inspect the first row in this `DataFrame` we can see there are two comments associated with this issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3120c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cool, I think we can do both :)', '@lhoestq now the 2 are implemented.\\r\\n\\r\\nPlease note that for the the second protection, finally I have chosen to protect the master branch only from **merge commits** (see update comment above), so no need to disable/re-enable the protection on each release (direct commits, different from merge commits, can be pushed to the remote master branch; and eventually reverted without messing up the repo history).']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"comments\"][0].tolist())\n",
    "len(df[\"comments\"][0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a186a68d",
   "metadata": {},
   "source": [
    "When we explode `df`, we expect to get one row for each of these comments. Let's check if that's the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a29229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>Cool, I think we can do both :)</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>@lhoestq now the 2 are implemented.\\r\\n\\r\\nPle...</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>Hi ! I guess the caching mechanism should have...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>If it's easy enough to implement, then yes ple...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>Well it can cause issue with anyone that updat...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>I just merged a fix, let me know if you're sti...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>Definitely works on several manual cases with ...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>Fixed by #2947.</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>OSCAR unshuffled_original_ko: NonMatchingSplit...</td>\n",
       "      <td>I tried `unshuffled_original_da` and it is als...</td>\n",
       "      <td>## Describe the bug\\r\\n\\r\\nCannot download OSC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            html_url  \\\n",
       "0  https://github.com/huggingface/datasets/issues...   \n",
       "1  https://github.com/huggingface/datasets/issues...   \n",
       "2  https://github.com/huggingface/datasets/issues...   \n",
       "3  https://github.com/huggingface/datasets/issues...   \n",
       "4  https://github.com/huggingface/datasets/issues...   \n",
       "5  https://github.com/huggingface/datasets/issues...   \n",
       "6  https://github.com/huggingface/datasets/issues...   \n",
       "7  https://github.com/huggingface/datasets/issues...   \n",
       "8  https://github.com/huggingface/datasets/issues...   \n",
       "\n",
       "                                               title  \\\n",
       "0                              Protect master branch   \n",
       "1                              Protect master branch   \n",
       "2  Backwards compatibility broken for cached data...   \n",
       "3  Backwards compatibility broken for cached data...   \n",
       "4  Backwards compatibility broken for cached data...   \n",
       "5  Backwards compatibility broken for cached data...   \n",
       "6  Backwards compatibility broken for cached data...   \n",
       "7  Backwards compatibility broken for cached data...   \n",
       "8  OSCAR unshuffled_original_ko: NonMatchingSplit...   \n",
       "\n",
       "                                            comments  \\\n",
       "0                    Cool, I think we can do both :)   \n",
       "1  @lhoestq now the 2 are implemented.\\r\\n\\r\\nPle...   \n",
       "2  Hi ! I guess the caching mechanism should have...   \n",
       "3  If it's easy enough to implement, then yes ple...   \n",
       "4  Well it can cause issue with anyone that updat...   \n",
       "5  I just merged a fix, let me know if you're sti...   \n",
       "6  Definitely works on several manual cases with ...   \n",
       "7                                    Fixed by #2947.   \n",
       "8  I tried `unshuffled_original_da` and it is als...   \n",
       "\n",
       "                                                body  \n",
       "0  After accidental merge commit (91c55355b634d0d...  \n",
       "1  After accidental merge commit (91c55355b634d0d...  \n",
       "2  ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "3  ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "4  ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "5  ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "6  ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "7  ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "8  ## Describe the bug\\r\\n\\r\\nCannot download OSC...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = df.explode(\"comments\", ignore_index=True)\n",
    "comments_df.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98d8f6",
   "metadata": {},
   "source": [
    "Great, we can see the rows have been replicated, with the `comments` column containing the individual comments! Now that we're finished with Pandas, we can quickly switch back to a `Dataset` by loading the `DataFrame` in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9434fe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 2964\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "comments_dataset = Dataset.from_pandas(comments_df)\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b56c40",
   "metadata": {},
   "source": [
    "Okay, this has given us a few thousand comments to work with!\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">See if you can use `Dataset.map()` to explode the `comments` column of `issues_dataset` *without* resorting to the use of Pandas. This is a little tricky; you might find the [\"Batch mapping\"](https://huggingface.co/docs/datasets/v2.0.0/about_map_batch?batch-mapping#batch-mapping) section of the 🤗 Datasets documentation useful for this task.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa3df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015d7db2b0c84b7e90296584668a486e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try_issues_dataset_exploded_comments\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>Cool, I think we can do both :)</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Protect master branch</td>\n",
       "      <td>@lhoestq now the 2 are implemented.\\r\\n\\r\\nPle...</td>\n",
       "      <td>After accidental merge commit (91c55355b634d0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>Hi ! I guess the caching mechanism should have...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>If it's easy enough to implement, then yes ple...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Backwards compatibility broken for cached data...</td>\n",
       "      <td>Well it can cause issue with anyone that updat...</td>\n",
       "      <td>## Describe the bug\\r\\nAfter upgrading to data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2</td>\n",
       "      <td>Issue to read a local dataset</td>\n",
       "      <td>My first bug report ❤️\\r\\nLooking into this ri...</td>\n",
       "      <td>Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2</td>\n",
       "      <td>Issue to read a local dataset</td>\n",
       "      <td>Ok, there are some news, most good than bad :l...</td>\n",
       "      <td>Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2</td>\n",
       "      <td>Issue to read a local dataset</td>\n",
       "      <td>Ok great, so as discussed today, let's:\\r\\n- h...</td>\n",
       "      <td>Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2</td>\n",
       "      <td>Issue to read a local dataset</td>\n",
       "      <td>Good plan!\\r\\n\\r\\nYes I do use `builder_kwargs...</td>\n",
       "      <td>Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues/2</td>\n",
       "      <td>Issue to read a local dataset</td>\n",
       "      <td>Done!</td>\n",
       "      <td>Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               html_url  \\\n",
       "0     https://github.com/huggingface/datasets/issues...   \n",
       "1     https://github.com/huggingface/datasets/issues...   \n",
       "2     https://github.com/huggingface/datasets/issues...   \n",
       "3     https://github.com/huggingface/datasets/issues...   \n",
       "4     https://github.com/huggingface/datasets/issues...   \n",
       "...                                                 ...   \n",
       "2959   https://github.com/huggingface/datasets/issues/2   \n",
       "2960   https://github.com/huggingface/datasets/issues/2   \n",
       "2961   https://github.com/huggingface/datasets/issues/2   \n",
       "2962   https://github.com/huggingface/datasets/issues/2   \n",
       "2963   https://github.com/huggingface/datasets/issues/2   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                 Protect master branch   \n",
       "1                                 Protect master branch   \n",
       "2     Backwards compatibility broken for cached data...   \n",
       "3     Backwards compatibility broken for cached data...   \n",
       "4     Backwards compatibility broken for cached data...   \n",
       "...                                                 ...   \n",
       "2959                      Issue to read a local dataset   \n",
       "2960                      Issue to read a local dataset   \n",
       "2961                      Issue to read a local dataset   \n",
       "2962                      Issue to read a local dataset   \n",
       "2963                      Issue to read a local dataset   \n",
       "\n",
       "                                                comment  \\\n",
       "0                       Cool, I think we can do both :)   \n",
       "1     @lhoestq now the 2 are implemented.\\r\\n\\r\\nPle...   \n",
       "2     Hi ! I guess the caching mechanism should have...   \n",
       "3     If it's easy enough to implement, then yes ple...   \n",
       "4     Well it can cause issue with anyone that updat...   \n",
       "...                                                 ...   \n",
       "2959  My first bug report ❤️\\r\\nLooking into this ri...   \n",
       "2960  Ok, there are some news, most good than bad :l...   \n",
       "2961  Ok great, so as discussed today, let's:\\r\\n- h...   \n",
       "2962  Good plan!\\r\\n\\r\\nYes I do use `builder_kwargs...   \n",
       "2963                                              Done!   \n",
       "\n",
       "                                                   body  \n",
       "0     After accidental merge commit (91c55355b634d0d...  \n",
       "1     After accidental merge commit (91c55355b634d0d...  \n",
       "2     ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "3     ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "4     ## Describe the bug\\r\\nAfter upgrading to data...  \n",
       "...                                                 ...  \n",
       "2959  Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...  \n",
       "2960  Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...  \n",
       "2961  Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...  \n",
       "2962  Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...  \n",
       "2963  Hello,\\r\\n\\r\\nAs proposed by @thomwolf, I open...  \n",
       "\n",
       "[2964 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying it out\n",
    "def explode_comments(items):\n",
    "    # initialize empty arrays \"html_url_arr = []\", \"title_arr = []\", \"comments_arr = []\", and \"body_arr = []\"\n",
    "    # loop over items\n",
    "    # for each item:\n",
    "    ## get the values for \"html_url\", \"title\", and \"body\"\n",
    "    ## get \"n_i\" = the number of copies that need to be made (length of this item's \"comments_arr\" array)\n",
    "    ## loop index \"ii\" over \"range(n_i)\"\n",
    "    ### in step ii of the loop, get the ii-th value (= i-th comment) of the current item's \"comments_arr\" array\n",
    "    ### append all current values (html_url, title, comment, body) to their corresponding arrays\n",
    "    # build the dictionary and return it\n",
    "    html_url_arr = []\n",
    "    title_arr = []\n",
    "    comments_arr = [] # only nested array\n",
    "    body_arr = []\n",
    "    n_items = len(items[\"html_url\"])\n",
    "    for i in range(n_items):\n",
    "        html_url = items[\"html_url\"][i]\n",
    "        title = items[\"title\"][i]\n",
    "        body = items[\"body\"][i]\n",
    "        n_i = len(items[\"comments\"][i])\n",
    "        for ii in range(n_i):\n",
    "            comment = items[\"comments\"][i][ii]\n",
    "            html_url_arr.append(html_url)\n",
    "            title_arr.append(title)\n",
    "            comments_arr.append(comment)\n",
    "            body_arr.append(body)\n",
    "    return {\"html_url\": html_url_arr, \"title\": title_arr, \"comments\": comments_arr, \"body\": body_arr}\n",
    "# https://huggingface.co/docs/datasets/v2.0.0/about_map_batch?batch-mapping#batch-mapping\n",
    "try_issues_dataset_exploded_comments = issues_dataset.map(explode_comments, batched=True)\n",
    "# https://discuss.huggingface.co/t/how-do-you-rename-a-column-in-a-dataset/15121\n",
    "try_issues_dataset_exploded_comments = try_issues_dataset_exploded_comments.rename_column(\"comments\", \"comment\")\n",
    "print(\"try_issues_dataset_exploded_comments\")\n",
    "try_issues_dataset_exploded_comments.set_format(\"pandas\")\n",
    "try_issues_dataset_exploded_comments[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb52fec",
   "metadata": {},
   "source": [
    "Now that we have one comment per row, let's create a new `comments_length` column that contains the number of words per comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03defdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b199e74cbc6484b91c9133b5aecb269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2964 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments_dataset = comments_dataset.map(lambda x: {\"comment_length\": len(x[\"comments\"].split())})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e05f526",
   "metadata": {},
   "source": [
    "We can use this new column to filter out short comments, which typically include things like \"cc @lewtun\" or \"Thanks!\" that are not relevant for our search engine. There's no precise number to select for the filter, but around 15 words seems like a good start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35fc825f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545d3d64ab3541e3a5801bb58f3a35fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body', 'comment_length'],\n",
       "    num_rows: 2175\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_dataset = comments_dataset.filter(lambda x: x[\"comment_length\"] > 15)\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0bd3c",
   "metadata": {},
   "source": [
    "Having cleaned up our dataset a bit, let's concatenate the issue title, description, and comments together in a new `text` column. As usual, we'll write a simple function that we can pass to `Dataset.map()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91728015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8270ab9a10a4ec7aa80b21602834286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2175 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def concatenate_text(examples):\n",
    "    return {\"text\": examples[\"title\"] + \" \\n \" + examples[\"body\"] + \" \\n \" + examples[\"comments\"]}\n",
    "comments_dataset = comments_dataset.map(concatenate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf4949",
   "metadata": {},
   "source": [
    "We're finally ready to create some embeddings! Let's take a look.\n",
    "\n",
    "### Creating text embeddings\n",
    "We saw in [Chapter 2](https://huggingface.co/course/chapter2) that we can obtain token embeddings by using the `AutoModel` class. All we need to do is pick a suitable checkpoint to load the model from. Fortunately, there's a library called `sentence-transformers` that is dedicated to creating embeddings. As described in the library's [documentation](https://www.sbert.net/examples/applications/semantic-search/README.html#symmetric-vs-asymmetric-semantic-search), our use case is an example of *asymmetric semantic search* because we have a short query whose answer we'd like to find in a longer document, like a an issue comment. The handy [model overview table](https://www.sbert.net/docs/pretrained_models.html#model-overview) in the documentation indicates that the `multi-qa-mpnet-base-dot-v1` checkpoint has the best performance for semantic search, so we'll use that for our application. We'll also load the tokenizer using the same checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfb954c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7d8d2",
   "metadata": {},
   "source": [
    "To speed up the embedding process, it helps to place the model and inputs on a GPU device, so let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9604cc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu if possible, else cpu\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a686efe",
   "metadata": {},
   "source": [
    "As we mentioned earlier, we'd like to represent each entry in our GitHub issues corpus as a single vector, so we need to \"pool\" or average our token embeddings in some way. One popular approach is to perform *CLS pooling* on our model's outputs, where we simply collect the last hidden state for the special `[CLS]` token. The following function does the trick for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ed5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d716bf",
   "metadata": {},
   "source": [
    "Next, we'll create a helper function that will tokenize a list of documents, place the tensors on the GPU, feed them to the model, and finally apply CLS pooling to the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35eb48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(text_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98717f",
   "metadata": {},
   "source": [
    "We can test the function works by feeding it the first text entry in our corpus and inspecting the output shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0b8ac64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = get_embeddings(comments_dataset[\"text\"][0])\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3ca94",
   "metadata": {},
   "source": [
    "Great, we've converted the first entry in our corpus into a 768-dimensional vector! We can use `Dataset.map()` to apply our `get_embeddings()` function to each row in our corpus, so let's create a new `embeddings` column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c094fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450afba85e214ba5b9e774d3a05954b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2175 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_dataset = comments_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"text\"]).detach().cpu().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32c231",
   "metadata": {},
   "source": [
    "Notice that we've converted the embeddings to NumPy arrays — that's because 🤗 Datasets requires this format when we try to index them with FAISS, which we'll do next.\n",
    "\n",
    "### Using FAISS for efficient similarity search\n",
    "Now that we have a dataset of embeddings, we need some way to search over them. To do this, we'll use a special data structure in 🤗 Datasets called a *FAISS index*. [FAISS](https://faiss.ai/) (short for Facebook AI Similarity Search) is a library that provides efficient algorithms to quickly search and cluster embedding vectors.\n",
    "\n",
    "The basic idea behind FAISS is to create a special data structure called an *index* that allows one to find which embeddings are similar to an input embedding. Creating a FAISS index in 🤗 Datasets is simple — we use the `Dataset.add_faiss_index()` function and specify which column of our dataset we'd like to index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4448daf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa62bab2ca6443a9ecb988eeb83d761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body', 'comment_length', 'text', 'embeddings'],\n",
       "    num_rows: 2175\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143bc024",
   "metadata": {},
   "source": [
    "We can now perform queries on this index by doing a nearest neighbor lookup with the `Dataset.get_nearest_examples()` function. Let's test this out by first embedding a question as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56a72c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How can I load a dataset offline?\"\n",
    "question_embedding = get_embeddings([question]).cpu().detach().numpy()\n",
    "question_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9c96a7",
   "metadata": {},
   "source": [
    "Just like with the documents, we now have a 768-dimensional vector representing the query, which we can compare against the whole corpus to find the most similar embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92189c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, samples = embeddings_dataset.get_nearest_examples(\"embeddings\", question_embedding, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34e5ce",
   "metadata": {},
   "source": [
    "The `Dataset.get_nearest_examples()` function returns a tuple of scores that rank the overlap between the query and the document, and a corresponding set of samples (here, the 5 best matches). Let's collect these in a `pandas.DataFrame` so we can easily sort them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b201f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce493e24",
   "metadata": {},
   "source": [
    "Now we can iterate over the first few rows to see how well our query matched the available comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf7fe097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMENT: Requiring online connection is a deal breaker in some cases unfortunately so it'd be great if offline mode is added similar to how `transformers` loads models offline fine.\r\n",
      "\r\n",
      "@mandubian's second bullet point suggests that there's a workaround allowing you to use your offline (custom?) dataset with `datasets`. Could you please elaborate on how that should look like?\n",
      "SCORE: 25.50501251220703\n",
      "TITLE: Discussion using datasets in offline mode\n",
      "URL: https://github.com/huggingface/datasets/issues/824\n",
      "==================================================\n",
      "\n",
      "COMMENT: The local dataset builders (csv, text , json and pandas) are now part of the `datasets` package since #1726 :)\r\n",
      "You can now use them offline\r\n",
      "```python\r\n",
      "datasets = load_dataset('text', data_files=data_files)\r\n",
      "```\r\n",
      "\r\n",
      "We'll do a new release soon\n",
      "SCORE: 24.555553436279297\n",
      "TITLE: Discussion using datasets in offline mode\n",
      "URL: https://github.com/huggingface/datasets/issues/824\n",
      "==================================================\n",
      "\n",
      "COMMENT: I opened a PR that allows to reload modules that have already been loaded once even if there's no internet.\r\n",
      "\r\n",
      "Let me know if you know other ways that can make the offline mode experience better. I'd be happy to add them :) \r\n",
      "\r\n",
      "I already note the \"freeze\" modules option, to prevent local modules updates. It would be a cool feature.\r\n",
      "\r\n",
      "----------\r\n",
      "\r\n",
      "> @mandubian's second bullet point suggests that there's a workaround allowing you to use your offline (custom?) dataset with `datasets`. Could you please elaborate on how that should look like?\r\n",
      "\r\n",
      "Indeed `load_dataset` allows to load remote dataset script (squad, glue, etc.) but also you own local ones.\r\n",
      "For example if you have a dataset script at `./my_dataset/my_dataset.py` then you can do\r\n",
      "```python\r\n",
      "load_dataset(\"./my_dataset\")\r\n",
      "```\r\n",
      "and the dataset script will generate your dataset once and for all.\r\n",
      "\r\n",
      "----------\r\n",
      "\r\n",
      "About I'm looking into having `csv`, `json`, `text`, `pandas` dataset builders already included in the `datasets` package, so that they are available offline by default, as opposed to the other datasets that require the script to be downloaded.\r\n",
      "cf #1724 \n",
      "SCORE: 24.148975372314453\n",
      "TITLE: Discussion using datasets in offline mode\n",
      "URL: https://github.com/huggingface/datasets/issues/824\n",
      "==================================================\n",
      "\n",
      "COMMENT: > here is my way to load a dataset offline, but it **requires** an online machine\n",
      "> \n",
      "> 1. (online machine)\n",
      "> \n",
      "> ```\n",
      "> \n",
      "> import datasets\n",
      "> \n",
      "> data = datasets.load_dataset(...)\n",
      "> \n",
      "> data.save_to_disk(/YOUR/DATASET/DIR)\n",
      "> \n",
      "> ```\n",
      "> \n",
      "> 2. copy the dir from online to the offline machine\n",
      "> \n",
      "> 3. (offline machine)\n",
      "> \n",
      "> ```\n",
      "> \n",
      "> import datasets\n",
      "> \n",
      "> data = datasets.load_from_disk(/SAVED/DATA/DIR)\n",
      "> \n",
      "> ```\n",
      "> \n",
      "> \n",
      "> \n",
      "> HTH.\n",
      "\n",
      "\n",
      "SCORE: 22.894001007080078\n",
      "TITLE: Discussion using datasets in offline mode\n",
      "URL: https://github.com/huggingface/datasets/issues/824\n",
      "==================================================\n",
      "\n",
      "COMMENT: here is my way to load a dataset offline, but it **requires** an online machine\r\n",
      "1. (online machine)\r\n",
      "```\r\n",
      "import datasets\r\n",
      "data = datasets.load_dataset(...)\r\n",
      "data.save_to_disk(/YOUR/DATASET/DIR)\r\n",
      "```\r\n",
      "2. copy the dir from online to the offline machine\r\n",
      "3. (offline machine)\r\n",
      "```\r\n",
      "import datasets\r\n",
      "data = datasets.load_from_disk(/SAVED/DATA/DIR)\r\n",
      "```\r\n",
      "\r\n",
      "HTH.\n",
      "SCORE: 22.40665626525879\n",
      "TITLE: Discussion using datasets in offline mode\n",
      "URL: https://github.com/huggingface/datasets/issues/824\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"COMMENT: {row.comments}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"TITLE: {row.title}\")\n",
    "    print(f\"URL: {row.html_url}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e51f09",
   "metadata": {},
   "source": [
    "Not bad! Our second hit seems to match the query.\n",
    "> ✏️ Try it out! <font color=\"darkgreen\">Create your own query and see whether you can find an answer in the retrieved documents. You might have to increase the `k` parameter in `Dataset.get_nearest_examples()` to broaden the search.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7bae684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n",
      "COMMENT: Hi ! Thanks for reporting. Indeed it looks like type inference makes it fail. We should probably just ignore this step until a non-empty batch is passed.\n",
      "SCORE: 45.637550354003906\n",
      "TITLE: Batched `map` not allowed to return 0 items\n",
      "URL: https://github.com/huggingface/datasets/issues/2644\n",
      "==================================================\n",
      "\n",
      "COMMENT: Sure if you're interested feel free to open a PR :)\r\n",
      "\r\n",
      "You can also ping me anytime if you have questions or if I can help !\n",
      "SCORE: 45.637550354003906\n",
      "TITLE: Batched `map` not allowed to return 0 items\n",
      "URL: https://github.com/huggingface/datasets/issues/2644\n",
      "==================================================\n",
      "\n",
      "COMMENT: I fixed a bug that could cause this issue earlier today. Could you pull the latest version and try again ?\n",
      "SCORE: 45.54084014892578\n",
      "TITLE: Indices incorrect with multiprocessing\n",
      "URL: https://github.com/huggingface/datasets/issues/597\n",
      "==================================================\n",
      "\n",
      "COMMENT: Hi @albertvillanova, thanks for the reply. I just tried the new version and the problem still persists. \r\n",
      "\r\n",
      "Do I need to rebuild the saved dataset (which I load from disk) with the 1.6.0 version of datasets? My script loads this dataset and creates new datasets from it. I tried it without rebuilding.\r\n",
      "\r\n",
      "See this short video of what happens. It does not create all processes at the same time:\r\n",
      "\r\n",
      "https://user-images.githubusercontent.com/2743060/115720139-0da3a500-a37d-11eb-833a-9bbacc70868d.mp4\r\n",
      "\r\n",
      "\n",
      "SCORE: 44.92795944213867\n",
      "TITLE: Map is slow and processes batches one after another\n",
      "URL: https://github.com/huggingface/datasets/issues/2243\n",
      "==================================================\n",
      "\n",
      "COMMENT: There can be a bit of delay between the creations of the processes but this delay should be the same for both your `map` calls. We should look into this.\r\n",
      "Also if you hav some code that reproduces this issue on google colab that'd be really useful !\r\n",
      "\r\n",
      "Regarding the speed differences:\r\n",
      "This looks like a similar issue as https://github.com/huggingface/datasets/issues/1992 who is experiencing the same speed differences between processes.\r\n",
      "This is a known bug that we are investigating. As of now I've never managed to reproduce it on my machine so it's pretty hard for me to find where this issue comes from.\r\n",
      "\n",
      "SCORE: 44.6375732421875\n",
      "TITLE: Map is slow and processes batches one after another\n",
      "URL: https://github.com/huggingface/datasets/issues/2243\n",
      "==================================================\n",
      "\n",
      "COMMENT: Hi,\r\n",
      "\r\n",
      "set `keep_in_memory` to False when loading a dataset (`sst = load_dataset(\"sst\", keep_in_memory=False)`) to prevent it from loading in-memory. Currently, in-memory datasets fail to find cached files due to this check (always False for them):\r\n",
      "\r\n",
      "https://github.com/huggingface/datasets/blob/241a0b4a3a868778ee91e767ad406f9da7610df2/src/datasets/arrow_dataset.py#L1718\r\n",
      "\r\n",
      "@albertvillanova It seems like this behavior was overlooked in #2182.\r\n",
      "\r\n",
      "\n",
      "SCORE: 44.50442123413086\n",
      "TITLE: Calls to map are not cached.\n",
      "URL: https://github.com/huggingface/datasets/issues/2322\n",
      "==================================================\n",
      "\n",
      "COMMENT: I tried upgrading to `datasets==1.6.2` and downgrading to `1.6.0`. Both versions produce the same output.\r\n",
      "\r\n",
      "Downgrading to `1.5.0` works and produces the following output for me:\r\n",
      "\r\n",
      "```bash\r\n",
      "Downloading: 9.20kB [00:00, 3.94MB/s]                   \r\n",
      "Downloading: 5.99kB [00:00, 3.29MB/s]                   \r\n",
      "No config specified, defaulting to: sst/default\r\n",
      "Downloading and preparing dataset sst/default (download: 6.83 MiB, generated: 3.73 MiB, post-processed: Unknown size, total: 10.56 MiB) to /home/johannes/.cache/huggingface/datasets/sst/default/1.0.0/a16a45566b63b2c3179e6c1d0f8edadde56e45570ee8cf99394fbb738491d34b...\r\n",
      "                                    Dataset sst downloaded and prepared to /home/johannes/.cache/huggingface/datasets/sst/default/1.0.0/a16a45566b63b2c3179e6c1d0f8edadde56e45570ee8cf99394fbb738491d34b. Subsequent calls will reuse this data.\r\n",
      "executed [0, 1]\r\n",
      "#0:   0%|          | 0/5 [00:00<?, ?ba/s]\r\n",
      "#1:   0%|          | 0/5 [00:00<?, ?ba/s]\r\n",
      "executed [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\r\n",
      "executed [4272, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281]\r\n",
      "executed [1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009]\r\n",
      "executed [5272, 5273, 5274, 5275, 5276, 5277, 5278, 5279, 5280, 5281]\r\n",
      "executed [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009]\r\n",
      "executed [6272, 6273, 6274, 6275, 6276, 6277, 6278, 6279, 6280, 6281]\r\n",
      "executed [3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009]\r\n",
      "executed [7272, 7273, 7274, 7275, 7276, 7277, 7278, 7279, 7280, 7281]\r\n",
      "executed [4000, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009]\r\n",
      "#0: 100%|██████████| 5/5 [00:00<00:00, 94.83ba/s]\r\n",
      "executed [8272, 8273, 8274, 8275, 8276, 8277, 8278, 8279, 8280, 8281]\r\n",
      "#1: 100%|██████████| 5/5 [00:00<00:00, 92.75ba/s]\r\n",
      "executed [0, 1]\r\n",
      "#0:   0%|          | 0/1 [00:00<?, ?ba/s]\r\n",
      "#1:   0%|          | 0/1 [00:00<?, ?ba/s]\r\n",
      "executed [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\r\n",
      "executed [551, 552, 553, 554, 555, 556, 557, 558, 559, 560]\r\n",
      "#0: 100%|██████████| 1/1 [00:00<00:00, 118.81ba/s]\r\n",
      "#1: 100%|██████████| 1/1 [00:00<00:00, 123.06ba/s]\r\n",
      "executed [0, 1]\r\n",
      "#0:   0%|          | 0/2 [00:00<?, ?ba/s]\r\n",
      "#1:   0%|          | 0/2 [00:00<?, ?ba/s]\r\n",
      "executed [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\r\n",
      "executed [1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114]\r\n",
      "executed [1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009]\r\n",
      "#0: 100%|██████████| 2/2 [00:00<00:00, 119.42ba/s]\r\n",
      "executed [2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114]\r\n",
      "#1: 100%|██████████| 2/2 [00:00<00:00, 123.33ba/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      " ############################## \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "executed [0, 1]\r\n",
      "Loading cached processed dataset at /home/johannes/.cache/huggingface/datasets/sst/default/1.0.0/a16a45566b63b2c3179e6c1d0f8edadde56e45570ee8cf99394fbb738491d34b/cache-6079777aa097c8f8.arrow\r\n",
      "Loading cached processed dataset at /home/johannes/.cache/huggingface/datasets/sst/default/1.0.0/a16a45566b63b2c3179e6c1d0f8edadde56e45570ee8cf99394fbb738491d34b/cache-2dc05c46f68eda6e.arrow\r\n",
      "executed [0, 1]\r\n",
      "Loading cached processed dataset at /home/johannes/.cache/huggingface/datasets/sst/default/1.0.0/a16a45566b63b2c3179e6c1d0f8edadde56e45570ee8cf99394fbb738491d34b/cache-1ca347e7430b98f1.arrow\r\n",
      "Loading cached processed dataset at /home/johannes/.cache/huggingface/datasets/sst/default/1.0.0/a16a45566b63b2c3179e6c1d0f8edadde56e45570ee8cf99394fbb738491d34b/cache-c0f1a73ce3ba40cd.arrow\r\n",
      "executed [0, 1]\r\n",
      "Loading cached processed dataset at /home/johannes/.cache/huggingface/datasets/sst/default/1.0.0/a16a45566b63b2c3179e6c1d0f8edadde56e45570ee8cf99394fbb738491d34b/cache-832a1407bf1ac5b7.arrow\r\n",
      "Loading cached processed dataset at /home/johannes/.cache/huggingface/datasets/sst/default/1.0.0/a16a45566b63b2c3179e6c1d0f8edadde56e45570ee8cf99394fbb738491d34b/cache-036316a259b773c4.arrow\r\n",
      "- Datasets: 1.5.0\r\n",
      "- Python: 3.8.3 (default, May 19 2020, 18:47:26) \r\n",
      "[GCC 7.3.0]\r\n",
      "- Platform: Linux-5.4.0-72-generic-x86_64-with-glibc2.10\r\n",
      "```\n",
      "SCORE: 44.50442123413086\n",
      "TITLE: Calls to map are not cached.\n",
      "URL: https://github.com/huggingface/datasets/issues/2322\n",
      "==================================================\n",
      "\n",
      "COMMENT: Hi ! Currently a dataset that is in memory doesn't know doesn't know in which directory it has to read/write cache files.\r\n",
      "On the other hand, a dataset that loaded from the disk (via memory mapping) uses the directory from which the dataset is located to read/write cache files.\r\n",
      "\r\n",
      "Because of that, currently in-memory datasets simply don't use caching.\r\n",
      "\r\n",
      "Maybe a Dataset object could have a `cache_dir` that is set to the directory where the arrow files are created during `load_dataset` ?\n",
      "SCORE: 44.50442123413086\n",
      "TITLE: Calls to map are not cached.\n",
      "URL: https://github.com/huggingface/datasets/issues/2322\n",
      "==================================================\n",
      "\n",
      "COMMENT: Hi @villmow, thanks for reporting. \r\n",
      "\r\n",
      "As @mariosasko has pointed out, we did not consider this case when introducing the feature of automatic in-memory for small datasets. This needs to be fixed.\n",
      "SCORE: 44.50442123413086\n",
      "TITLE: Calls to map are not cached.\n",
      "URL: https://github.com/huggingface/datasets/issues/2322\n",
      "==================================================\n",
      "\n",
      "COMMENT: Hi @villmow, thanks for reporting.\r\n",
      "\r\n",
      "Could you please try with the Datasets version 1.6? We released it yesterday and it fixes some issues about the processing speed. You can see the fix implemented by @lhoestq here: #2122.\r\n",
      "\r\n",
      "Once you update Datasets, please confirm if the problem persists.\n",
      "SCORE: 44.34314727783203\n",
      "TITLE: Map is slow and processes batches one after another\n",
      "URL: https://github.com/huggingface/datasets/issues/2243\n",
      "==================================================\n",
      "\n",
      "COMMENT: Nice ! I'm glad this works now.\r\n",
      "Closing for now, but feel free to re-open if you experience this issue again.\n",
      "SCORE: 44.0081787109375\n",
      "TITLE: Map is slow and processes batches one after another\n",
      "URL: https://github.com/huggingface/datasets/issues/2243\n",
      "==================================================\n",
      "\n",
      "COMMENT: Yes the forum is perfect for that. You can post in the `datasets` section.\r\n",
      "Thanks a lot!\n",
      "SCORE: 43.179351806640625\n",
      "TITLE: how processing in batch works in datasets \n",
      "URL: https://github.com/huggingface/datasets/issues/823\n",
      "==================================================\n",
      "\n",
      "COMMENT: Hi Thomas,\n",
      "what I do not get from documentation is that why when you set batched=True,\n",
      "this is processed in batch, while data is not divided to batched\n",
      "beforehand, basically this is a question on the documentation and I do not\n",
      "get the batched=True, but sure, if you think this is more appropriate in\n",
      "forum I will post it there.\n",
      "thanks\n",
      "Best\n",
      "Rabeeh\n",
      "\n",
      "On Tue, Nov 10, 2020 at 12:21 PM Thomas Wolf <notifications@github.com>\n",
      "wrote:\n",
      "\n",
      "> Hi I don’t think this is a request for a dataset like you labeled it.\n",
      ">\n",
      "> I also think this would be better suited for the forum at\n",
      "> https://discuss.huggingface.co. we try to keep the issue for the repo for\n",
      "> bug reports and new features/dataset requests and have usage questions\n",
      "> discussed on the forum. Thanks.\n",
      ">\n",
      "> —\n",
      "> You are receiving this because you authored the thread.\n",
      "> Reply to this email directly, view it on GitHub\n",
      "> <https://github.com/huggingface/datasets/issues/823#issuecomment-724639476>,\n",
      "> or unsubscribe\n",
      "> <https://github.com/notifications/unsubscribe-auth/ARPXHH4FIPFHVVUHANAE4F3SPEO2JANCNFSM4TQQVEXQ>\n",
      "> .\n",
      ">\n",
      "\n",
      "SCORE: 43.179351806640625\n",
      "TITLE: how processing in batch works in datasets \n",
      "URL: https://github.com/huggingface/datasets/issues/823\n",
      "==================================================\n",
      "\n",
      "COMMENT: Hi I don’t think this is a request for a dataset like you labeled it.\r\n",
      "\r\n",
      "I also think this would be better suited for the forum at https://discuss.huggingface.co. we try to keep the issue for the repo for bug reports and new features/dataset requests and have usage questions discussed on the forum. Thanks.\n",
      "SCORE: 43.179351806640625\n",
      "TITLE: how processing in batch works in datasets \n",
      "URL: https://github.com/huggingface/datasets/issues/823\n",
      "==================================================\n",
      "\n",
      "COMMENT: Still the case on master.\r\n",
      "I guess we should have an offset in the multi-procs indeed (hopefully it's enough).\r\n",
      "\r\n",
      "Also, side note is that we should add some logging before the \"test\" to say we are testing the function otherwise its confusing for the user to see two outputs I think. Proposal (see the \"Testing the mapped function outputs:\" lines):\r\n",
      "```\r\n",
      ">>> d.select(range(10)).map(fn, with_indices=True, batched=True, num_proc=2)\r\n",
      "Done writing 10 indices in 80 bytes .\r\n",
      "Done writing 5 indices in 41 bytes .\r\n",
      "Done writing 5 indices in 41 bytes .\r\n",
      "Spawning 2 processes\r\n",
      "Testing the mapped function outputs:\r\n",
      "inds: [0, 1]\r\n",
      "inds: [0, 1]\r\n",
      "Testing finished, running the mapped function on the dataset:\r\n",
      "#0:   0%|                                                                                                                                                                    | 0/1 [00:00<?, ?ba/s]\r\n",
      "inds: [0, 1, 2, 3, 4]                                                                                                                                                                             inds: [0, 1, 2, 3, 4]                                                                                                                                                         | 0/1 [00:00<?, ?ba/s]\r\n",
      "#0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1321.04ba/s]\r\n",
      "#1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1841.22ba/s]\r\n",
      "Concatenating 2 shards from multiprocessing\r\n",
      "Dataset(features: {'text': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=2, names=['neg', 'pos'], names_file=None, id=None)}, num_rows: 10)\r\n",
      "```\n",
      "SCORE: 43.0487174987793\n",
      "TITLE: Indices incorrect with multiprocessing\n",
      "URL: https://github.com/huggingface/datasets/issues/597\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying it out\n",
    "## query and embeddings\n",
    "query = \"How does batch mapping work?\" # custom query\n",
    "query_embedding = get_embeddings([query]).cpu().detach().numpy()\n",
    "print(query_embedding.shape)\n",
    "## sample the k nearest instances as well as their score (wrt the query)\n",
    "scores, samples = embeddings_dataset.get_nearest_examples(\"embeddings\", query_embedding, k=15) # maybe adapt k\n",
    "## turn samples into a pandas dataframe, add the scores as a column, and sort the rows by their scores\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)\n",
    "## print the results sample by sample\n",
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"COMMENT: {row.comments}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"TITLE: {row.title}\")\n",
    "    print(f\"URL: {row.html_url}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b78c4",
   "metadata": {},
   "source": [
    "## [🤗 Datasets, check!](https://huggingface.co/course/chapter5/7?fw=pt)\n",
    "Well, that was quite a tour through the 🤗 Datasets library — congratulations on making it this far! With the knowledge that you've gained from this chapter, you should be able to:\n",
    "- Load datasets from anywhere, be it the Hugging Face Hub, your laptop, or a remote server at your company.\n",
    "- Wrangle your data using a mix of the `Dataset.map()` and `Dataset.filter()` functions.\n",
    "- Quickly switch between data formats like Pandas and NumPy using `Dataset.set_format()`.\n",
    "- Create your very own dataset and push it to the Hugging Face Hub.\n",
    "- Embed your documents using a Transformer model and build a semantic search engine using FAISS.\n",
    "\n",
    "In [Chapter 7](https://huggingface.co/course/chapter7), we'll put all of this to good use as we take a deep dive into the core NLP tasks that Transformer models are great for. Before jumping ahead, though, put your knowledge of 🤗 Datasets to the test with a quick quiz!\n",
    "\n",
    "## [End-of-chapter quiz](https://huggingface.co/course/chapter5/8?fw=pt)\n",
    "This chapter covered a lot of ground! Don't worry if you didn't grasp all the details; the next chapters will help you understand how things work under the hood.\n",
    "\n",
    "Before moving on, though, let's test what you learned in this chapter.\n",
    "\n",
    "**1. The `load_dataset()` function in 🤗 Datasets allows you to load a dataset from which of the following locations?**<br>\n",
    "⚫️ Locally, e.g. on your laptop\n",
    "> **Correct!** Correct! You can pass the paths of local files to the `data_files` argument of `load_dataset()` to load local datasets.\n",
    "\n",
    "⚫️ The Hugging Face Hub\n",
    "> **Correct!** Correct! You can load datasets on the Hub by providing the dataset ID, e.g. `load_dataset('emotion')`.\n",
    "\n",
    "⚫️ A remote server\n",
    "> **Correct!** Correct! You can pass URLs to the `data_files` argument of `load_dataset()` to load remote files.\n",
    "\n",
    "**2. Suppose you load one of the GLUE tasks as follows:**\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"glue\", \"mrpc\", split=\"train\")\n",
    "```\n",
    "Which of the following commands will produce a random sample of 50 elements from dataset?<br>\n",
    "⚪️ `dataset.sample(50)`<br>\n",
    "⚫️ `dataset.shuffle().select(range(50))`\n",
    "> **Correct!** Correct! As you saw in this chapter, you first shuffle the dataset and then select the samples from it.\n",
    "\n",
    "⚪️ `dataset.select(range(50)).shuffle()`\n",
    "\n",
    "**3. Suppose you have a dataset about household pets called `pets_dataset`, which has a `name` column that denotes the name of each pet. Which of the following approaches would allow you to filter the dataset for all pets whose names start with the letter \"L\"?**<br>\n",
    "⚫️ `pets_dataset.filter(lambda x : x['name'].startswith('L'))`\n",
    "> **Correct!** Correct! Using a Python lambda function for these quick filters is a great idea. Can you think of another solution?\n",
    "\n",
    "⚪️ `pets_dataset.filter(lambda x['name'].startswith('L'))`<br>\n",
    "⚫️ Create a function like `def filter_names(x): return x['name'].startswith('L')` and run `pets_dataset.filter(filter_names)`.\n",
    "> **Correct!** Correct! Just like with `Dataset.map()`, you can pass explicit functions to `Dataset.filter()`. This is useful when you have some complex logic that isn't suitable for a short lambda function. Which of the other solutions would work?\n",
    "\n",
    "**4. What is memory mapping?**<br>\n",
    "⚪️ A mapping between CPU and GPU RAM<br>\n",
    "⚫️ A mapping between RAM and filesystem storage\n",
    "> **Correct!** Correct! 🤗 Datasets treats each dataset as a memory-mapped file. This allows the library to access and operate on elements of the dataset without needing to fully load it into memory.\n",
    "\n",
    "⚪️ A mapping between two files in the 🤗 Datasets cache\n",
    "\n",
    "**5. Which of the following are the main benefits of memory mapping?**<br>\n",
    "⚫️ Accessing memory-mapped files is faster than reading from or writing to disk.\n",
    "> **Correct!** Correct! This allows 🤗 Datasets to be blazing fast. That's not the only benefit, though.\n",
    "\n",
    "⚫️ Applications can access segments of data in an extremely large file without having to read the whole file into RAM first.\n",
    "> **Correct!** Correct! This allows 🤗 Datasets to load multi-gigabyte datasets on your laptop without blowing up your CPU. What other advantage does memory mapping offer?\n",
    "\n",
    "⚪️ It consumes less energy, so your battery lasts longer.\n",
    "\n",
    "**6. Why does the following code fail?**\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"allocine\", streaming=True, split=\"train\")\n",
    "dataset[0]\n",
    "```\n",
    "<br>\n",
    "⚪️ It tries to stream a dataset that's too large to fit in RAM.<br>\n",
    "⚫️ It tries to access an `IterableDataset`.\n",
    "> **Correct!** Correct! An `IterableDataset` is a generator, not a container, so you should access its elements using `next(iter(dataset))`.\n",
    "\n",
    "⚪️ The `allocine` dataset doesn't have a `train` split.\n",
    "\n",
    "**7. Which of the following are the main benefits of creating a dataset card?**<br>\n",
    "⚫️ It provides information about the intended use and supported tasks of the dataset so others in the community can make an informed decision about using it.\n",
    "> **Correct!** Undocumented datasets may be used to train models that may not reflect the intentions of the dataset creators, or may produce models whose legal status is murky if they're trained on data that violates privacy or licensing restrictions. This isn't the only benefit, though!\n",
    "\n",
    "⚫️ It helps draw attention to the biases that are present in a corpus.\n",
    "> **Correct!** Correct! Almost all datasets have some form of bias, which can produce negative consequences downstream. Being aware of them helps model builders understand how to address the inherent biases. What else do dataset cards help with?\n",
    "\n",
    "⚫️ It improves the chances that others in the community will use my dataset.\n",
    "> **Correct!** Correct! A well-written dataset card will tend to lead to higher usage of your precious dataset. What other benefits does it offer?\n",
    "\n",
    "**8. What is semantic search?**<br>\n",
    "⚪️ A way to search for exact matches between the words in a query and the documents in a corpus<br>\n",
    "⚫️ A way to search for matching documents by understanding the contextual meaning of a query\n",
    "> **Correct!** Correct! Semantic search uses embedding vectors to represent queries and documents, and uses a similarity metric to measure the amount of overlap between them. How else might you describe it?\n",
    "\n",
    "⚫️ A way to improve search accuracy<br>\n",
    "> **Correct!** Correct! Semantic search engines can capture the intent of a query much better than keyword matching and typically retrieve documents with higher precision. But this isn't the only right answer - what else does semantic search provide?\n",
    "\n",
    "**9. For asymmetric semantic search, you usually have:**<br>\n",
    "⚫️ A short query and a longer paragraph that answers the query\n",
    "> **Correct!** Correct!\n",
    "\n",
    "⚪️ Queries and paragraphs that are of about the same length<br>\n",
    "⚪️ A long query and a shorter paragraph that answers the query\n",
    "\n",
    "\n",
    "**10. Can I use 🤗 Datasets to load data for use in other domains, like speech processing?**<br>\n",
    "⚪️ No<br>\n",
    "⚫️ Yes\n",
    "> **Correct!** Correct! Check out the exciting developments with speech and vision in the 🤗 Transformers library to see how 🤗 Datasets is used in these domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
