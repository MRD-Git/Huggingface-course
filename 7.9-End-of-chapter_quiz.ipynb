{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec179236",
   "metadata": {},
   "source": [
    "## [End-of-chapter quiz](https://huggingface.co/course/chapter7/9?fw=pt)\n",
    "Let's test what you learned in this chapter!\n",
    "\n",
    "**1. Which of the following tasks can be framed as a token classification problem?**<br>\n",
    "⚫️ Find the grammatical components in a sentence.\n",
    "> **Correct!** Correct! We can then label each word as a noun, verb, etc.\n",
    "\n",
    "⚪️ Find whether a sentence is grammatically correct or not.<br>\n",
    "⚫️ Find the persons mentioned in a sentence.\n",
    "> **Correct!** Correct! We can label each word as person or not person.\n",
    "\n",
    "⚪️ Find the chunk of words in a sentence that answers a question.\n",
    "\n",
    "**2. What part of the preprocessing for token classification differs from the other preprocessing pipelines?**<br>\n",
    "⚪️ There is no need to do anything; the texts are already tokenized.<br>\n",
    "⚫️ Find the persons mentioned in a sentence.\n",
    "> **Correct!** Correct! This is different from the usual preprocessing, where we need to apply the full tokenization pipeline. Can you think of another difference?\n",
    "\n",
    "⚪️ We use `-100` to label the special tokens.<br>\n",
    "⚫️ We need to make sure to truncate or pad the labels to the same size as the inputs, when applying truncation/padding.\n",
    "> **Correct!** Indeed! That's not the only difference, though.\n",
    "\n",
    "**3. What problem arises when we tokenize the words in a token classification problem and want to label the tokens?**<br>\n",
    "⚪️ The tokenizer adds special tokens and we have no labels for them.<br>\n",
    "⚫️ Each word can produce several tokens, so we end up with more tokens than we have labels.\n",
    "> **Correct!** That is the main problem, and we need to align the original labels with the tokens.\n",
    "\n",
    "⚪️ The added tokens have no labels, so there is no problem.\n",
    "\n",
    "**4. What does \"domain adaptation\" mean?**<br>\n",
    "⚪️ It's when we run a model on a dataset and get the predictions for each sample in that dataset.<br>\n",
    "⚪️ It's when we train a model on a dataset.<br>\n",
    "⚫️ It's when we fine-tune a pretrained model on a new dataset, and it gives predictions that are more adapted to that dataset.\n",
    "> **Correct!** Correct! The model adapted its knowledge to the new dataset.\n",
    "\n",
    "⚪️ It's when we add misclassified samples to a dataset to make our model more robust.\n",
    "\n",
    "**5. What does \"domain adaptation\" mean?**<br>\n",
    "\n",
    "**6. Which of these tasks can be seen as a sequence-to-sequence problem?**<br>\n",
    "⚫️ Writing short reviews of long documents\n",
    "> **Correct!** Yes, that's a summarization problem. Try another answer!\n",
    "\n",
    "⚫️ Answering questions about a document\n",
    "> **Correct!** This can be framed as a sequence-to-sequence problem. It's not the only right answer, though.\n",
    "\n",
    "⚫️ Translating a text in Chinese into English\n",
    "> **Correct!** That's definitely a sequence-to-sequence problem. Can you spot another one?\n",
    "\n",
    "⚫️ Fixing the messages sent by my nephew/friend so they're in proper English\n",
    "> **Correct!** That's a kind of translation problem, so definitely a sequence-to-sequence task. This isn't the only right answer, though!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6710d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
